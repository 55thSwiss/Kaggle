{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.activations import *\n",
    "from keras.layers import *\n",
    "from keras.losses import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import talos as ta\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r'C:\\Users\\MacalusoC\\Desktop\\test.csv')\n",
    "\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# scale the data\n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate np array into feature and label data\n",
    "scaled_features = scaled_data[:, [3, 4]]\n",
    "scaled_labels = scaled_data[:, [0, 1, 2]]\n",
    "\n",
    "# split the data into train and test groups\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    scaled_features, scaled_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron': [8, 12, 24],\n",
    "    'second_neuron': [36, 48, 62, 84],\n",
    "    'third_neuron': [36, 48, 62, 84],\n",
    "    'fourth_neuron': [8, 12, 24],\n",
    "    'batch_size': [10, 20, 30],\n",
    "    'activation': [relu, \n",
    "                   softmax,\n",
    "                   selu,\n",
    "                   softplus,\n",
    "                   softsign,\n",
    "                   tanh,\n",
    "                   sigmoid,\n",
    "                   hard_sigmoid,\n",
    "                   exponential,\n",
    "                   linear],\n",
    "    'optimizer' : ['SGD',\n",
    "                   'RMSprop',\n",
    "                   'Adagrad',\n",
    "                   'Adadelta',\n",
    "                   'Adam',\n",
    "                   'Adamax',\n",
    "                   'Nadam',],\n",
    "    'loss' : [mean_squared_error, \n",
    "              mean_absolute_error, \n",
    "              mean_absolute_percentage_error, \n",
    "              mean_squared_logarithmic_error,\n",
    "              squared_hinge,hinge,\n",
    "              categorical_hinge,\n",
    "              logcosh,],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(train_features, train_labels, test_features, test_labels, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=2, activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['third_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['fourth_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(3, activation=params['activation']))\n",
    "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(train_features, train_labels,\n",
    "                    epochs=100,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    # validation_split=.3,\n",
    "                    verbose=0,\n",
    "                    validation_data=[test_features, test_labels])\n",
    "    \n",
    "    # modify the output model\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/2419 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|██████▍                                                                        | 199/2419 [03:49<49:20,  1.33s/it]"
     ]
    }
   ],
   "source": [
    "# run the Talos experiment\n",
    "t = ta.Scan(scaled_features, scaled_labels, \n",
    "            params=p, \n",
    "            model=ann,\n",
    "            grid_downsample=.01,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the results data frame\n",
    "t.data.head()\n",
    "\n",
    "# accessing epoch entropy values for each round\n",
    "t.peak_epochs_df\n",
    "\n",
    "# access the summary details\n",
    "t.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Scan object as input\n",
    "r = ta.Reporting(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of rounds in the Scan\n",
    "r.rounds()\n",
    "\n",
    "# get the highest result ('val_acc' by default)\n",
    "r.high()\n",
    "\n",
    "# get the highest result for any metric\n",
    "r.high('accuracy')\n",
    "\n",
    "# get the round with the best result\n",
    "r.rounds2high()\n",
    "\n",
    "# get the best paramaters\n",
    "r.best_params()\n",
    "\n",
    "# get correlation for hyperparameters against a metric\n",
    "r.correlate('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a regression plot for two dimensions \n",
    "r.plot_regs()\n",
    "\n",
    "# line plot\n",
    "r.plot_line()\n",
    "\n",
    "# up to two dimensional kernel density estimator\n",
    "r.plot_kde('accuracy')\n",
    "\n",
    "# a simple histogram\n",
    "r.plot_hist(bins=50)\n",
    "\n",
    "# heatmap correlation\n",
    "r.plot_corr()\n",
    "\n",
    "# a four dimensional bar grid\n",
    "r.plot_bars('batch_size', 'accuracy', 'first_neuron', 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ta.Evaluate(t)\n",
    "e.evaluate(scaled_features, scaled_labels, folds=10, average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
