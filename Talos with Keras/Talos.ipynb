{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.activations import *\n",
    "from keras.layers import *\n",
    "from keras.losses import *\n",
    "from keras.optimizers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import talos as ta\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = (r'C:\\Users\\MacalusoC\\Desktop\\test.csv')\n",
    "\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data between 0 and 1\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# scale the data\n",
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate np array into feature and label data\n",
    "scaled_features = scaled_data[:, [3, 4]]\n",
    "scaled_labels = scaled_data[:, [0, 1, 2]]\n",
    "\n",
    "# split the data into train and test groups\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    scaled_features, scaled_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron': [8, 12, 24],\n",
    "    'second_neuron': [36, 48, 62, 84],\n",
    "    'third_neuron': [36, 48, 62, 84],\n",
    "    'fourth_neuron': [8, 12, 24],\n",
    "    'batch_size': [10, 20, 30],\n",
    "    'activation': [relu, \n",
    "                   softmax,\n",
    "                   selu,\n",
    "                   softplus,\n",
    "                   softsign,\n",
    "                   tanh,\n",
    "                   sigmoid,\n",
    "                   hard_sigmoid,\n",
    "                   exponential,\n",
    "                   linear],\n",
    "    'optimizer' : ['SGD',\n",
    "                   'RMSprop',\n",
    "                   'Adagrad',\n",
    "                   'Adadelta',\n",
    "                   'Adam',\n",
    "                   'Adamax',\n",
    "                   'Nadam',],\n",
    "    'loss' : [mean_squared_error, \n",
    "              mean_absolute_error, \n",
    "              mean_absolute_percentage_error, \n",
    "              mean_squared_logarithmic_error,\n",
    "              squared_hinge,hinge,\n",
    "              categorical_hinge,\n",
    "              logcosh,],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(train_features, train_labels, test_features, test_labels, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=2, activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['third_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['fourth_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(3, activation=params['activation']))\n",
    "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(train_features, train_labels,\n",
    "                    epochs=100,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    # validation_split=.3,\n",
    "                    verbose=0,\n",
    "                    validation_data=[test_features, test_labels])\n",
    "    \n",
    "    # modify the output model\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/2419 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2419/2419 [46:39<00:00,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# run the Talos experiment\n",
    "t = ta.Scan(scaled_features, scaled_labels, \n",
    "            params=p, \n",
    "            model=ann,\n",
    "            grid_downsample=.01,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_method          uniform_mersenne\n",
       "reduction_method                   None\n",
       "reduction_interval                   50\n",
       "reduction_window                     20\n",
       "grid_downsample                    0.01\n",
       "reduction_threshold                 0.2\n",
       "reduction_metric                val_acc\n",
       "reduce_loss                       False\n",
       "experiment_name           031919145539_\n",
       "complete_time            03/19/19/15:42\n",
       "x_shape                         (18, 2)\n",
       "y_shape                         (18, 3)\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accessing the results data frame\n",
    "t.data.head()\n",
    "\n",
    "# accessing epoch entropy values for each round\n",
    "t.peak_epochs_df\n",
    "\n",
    "# access the summary details\n",
    "t.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Scan object as input\n",
    "r = ta.Reporting(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2419"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the number of rounds in the Scan\n",
    "r.rounds()\n",
    "\n",
    "# get correlation for hyperparameters against a metric\n",
    "#r.correlate('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['24', '30', '12', 'Adamax', '48',\n",
       "        '<function linear at 0x0000019FEBABE510>', '36', 0],\n",
       "       ['24', '20', '12', 'RMSprop', '84',\n",
       "        '<function selu at 0x0000019FEBABE0D0>', '84', 1],\n",
       "       ['8', '20', '24', 'SGD', '62',\n",
       "        '<function tanh at 0x0000019FEBABE2F0>', '84', 2],\n",
       "       ['24', '30', '12', 'Adam', '62',\n",
       "        '<function linear at 0x0000019FEBABE510>', '84', 3],\n",
       "       ['8', '10', '24', 'Adamax', '62',\n",
       "        '<function selu at 0x0000019FEBABE0D0>', '84', 4],\n",
       "       ['12', '10', '8', 'SGD', '48',\n",
       "        '<function linear at 0x0000019FEBABE510>', '36', 5],\n",
       "       ['8', '10', '8', 'Adadelta', '62',\n",
       "        '<function tanh at 0x0000019FEBABE2F0>', '36', 6],\n",
       "       ['24', '10', '24', 'Adam', '48',\n",
       "        '<function linear at 0x0000019FEBABE510>', '62', 7],\n",
       "       ['24', '30', '24', 'Adagrad', '84',\n",
       "        '<function tanh at 0x0000019FEBABE2F0>', '84', 8],\n",
       "       ['12', '10', '24', 'Adadelta', '62',\n",
       "        '<function tanh at 0x0000019FEBABE2F0>', '84', 9]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best paramaters\n",
    "r.best_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the round with the best result\n",
    "r.rounds2high()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the highest result ('val_acc' by default)\n",
    "r.high('val_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8333333432674408'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the highest result for any metric\n",
    "r.high('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = ta.Evaluate(t)\n",
    "e.evaluate(scaled_features, scaled_labels, folds=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
