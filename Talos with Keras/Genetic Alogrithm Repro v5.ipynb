{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Reproducing Genetic Alogrithm Generated CNC Cutting Parameters with a Neural Network\n",
    "\n",
    "### Introducton\n",
    "\n",
    "This notebook aims to reproduce the output data of *Multi-Objective Optimization of Turning Process during Machining of AlMg1SiCu (Aluminum) Using Non-Dominated Sorted Genetic Algorithm* by Rahul Dhabalea, VijayKumar S. Jattib, and T.P.Singhc. The study used a genetic algorithm (GA) to generate novel cutting parameters, and predict material removal rate & surface roughness. The study can be found [here](https://www.sciencedirect.com/science/article/pii/S2211812814005318) for further reading but some explanation will follow, mainly concerning the differences between goals and the methodology used in creating the artificial neural network (ANN).\n",
    "\n",
    "### Background\n",
    "\n",
    "The GA used twenty seven rows of input data that are a series of test cuts where a CNC machine tool was set to turn a constant diameter with a range of spindle speeds (rpm), feed rates (mm/rev), and depths of cut(mm). The results of each test cut take the form of a calculated material remove rate (mm$^3$/min) and surface roughness (Î¼m) measurement. Their goal was to have the GA produce cutting conditions and results which maximized material removal rate and minimized surface roughness. These two outcomes are conflicting in nature and so result in one ideal output for each scenario. In total the GA generated and ranked sixteen suggestions. Five of the sixteen results were chosen for validation of the GA results and tested on the CNC mahcine. The results had an average of less than five percent error from the forcast. \n",
    "\n",
    "### This Notebook\n",
    "\n",
    "The major difference between the study and this notebook, besides the algorithm used, is in the prediction method. The ANN will be designed to accept a desired material removal rate and surface roughness as inputs, and generate the spindle speed, feed rate, and depth of cut as outputs. The initial twenty seven rows will be used as training data, while the five rows used for validation in the study will be split into four rows of testing data and one row for validation. The single row kept for validation will have the lowest surface roughness value in the entire dataset. This makes for a more realistic test of the ANN because an end user would be requesting results that are better than the initial dataset and this input data will be outside anything the ANN has been trained on which makes for a more difficult prediction. \n",
    "\n",
    "### Details\n",
    "\n",
    "Usually a dataset's features very widely between magnitude, units, and range. For this reason it's important to scale the data because most machine learning models recognize patterns using Eucledian distance between any two points. There are many ways to scale data but in this notebook two of the more common methods in the Scikit-Learn library will be applied separetly. Both scaled data sets will then be used with Talos to tune the hyperparameters of the neural network and the best results of each will be applied to the Keras model for final results on the validation data.\n",
    "\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This notebook was made to show the feasability in using a neaural network made with common open source tools to facilitate process improvements in manufacturing by replicating the successful results of a GA and adjusting the input and output parameters to create a tool useful for the shop floor.\n",
    "\n",
    "Test cuts of this nature will likely produce a very samll amounts of data as seen in the study. Generally in machine learning a large amount of data is required for a robust model to be created, but it appears an acceptable level of accuracy is achievable with a limited dataset.\n",
    "\n",
    "Other cutting or result data would likely need to be used to fit a real business model, for instance replacing material removal rate with some measure of process stability like tool life or \"time since adjustment\", but due to the proprietary nature of manufacturing the available data to develop tests with is limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency Version:\n",
      "\n",
      "Keras 2.2.4\n",
      "Numpy 1.15.0\n",
      "Pandas 0.25.0\n",
      "Seaborn 0.9.0\n",
      "Sklearn 0.20.1\n",
      "Talos 0.6.3\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.activations import *\n",
    "from keras.layers import *\n",
    "from keras.losses import *\n",
    "from keras.optimizers import *\n",
    "from keras.layers import advanced_activations\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import talos as ta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# establish fixed seeding for reproducability\n",
    "seed_value= 0\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# suppress NumPy arrays scientific notation and round decimals to three places\n",
    "np.set_printoptions(suppress=True)\n",
    "np.printoptions(precision=3, suppress=True)\n",
    "\n",
    "# print the version of each library being used\n",
    "print('Dependency Version:\\n')\n",
    "print('Keras', keras.__version__)\n",
    "print('Numpy', np.__version__)\n",
    "print('Pandas', pd.__version__)\n",
    "print('Seaborn', seaborn.__version__)\n",
    "print('Sklearn', sklearn.__version__)\n",
    "print('Talos', ta.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('data.txt', delim_whitespace=True, encoding='ISO-8859-1')\n",
    "# drop the index number of the tests\n",
    "data.drop(columns=['Sr._No.', 'MRR(mm3/min)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a look at the overall correlation of each feature in the raw data\n",
    "heat_data = data\n",
    "plt.figure(figsize=(16, 12))\n",
    "corr = heat_data.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True,\n",
    "    annot=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=90,\n",
    "    horizontalalignment='right'\n",
    ");\n",
    "plt.savefig('heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the dataframe into a NumPy array\n",
    "np_data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms features by scaling each feature to a given range, -1 and 1 in this case\n",
    "MinMax_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "np_data_MinMax = MinMax_scaler.fit_transform(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "Standard_scaler = StandardScaler()\n",
    "np_data_Standard = Standard_scaler.fit_transform(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the scaled MinMax data into training, testing, and validation sets\n",
    "train_features_MinMax = np_data_MinMax[0:27 , 3:4]\n",
    "test_features_MinMax = np_data_MinMax[28:32, 3:4]\n",
    "validation_features_MinMax = np_data_MinMax[27, 3:4]\n",
    "train_labels_MinMax = np_data_MinMax[0:27, 0:3]\n",
    "test_labels_MinMax = np_data_MinMax[28:32, 0:3]\n",
    "validation_labels_MinMax = np_data_MinMax[27, 0:3]\n",
    "\n",
    "# reshape the validation data because it's only one row\n",
    "validation_features_MinMax = validation_features_MinMax.reshape(1, -1)\n",
    "validation_labels_MinMax = validation_labels_MinMax.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the scaled Standard data into training, testing, and validation sets\n",
    "train_features_Standard = np_data_Standard[0:27 , 3:4]\n",
    "test_features_Standard = np_data_Standard[28:32, 3:4]\n",
    "validation_features_Standard = np_data_Standard[27, 3:4]\n",
    "train_labels_Standard = np_data_Standard[0:27, 0:3]\n",
    "test_labels_Standard = np_data_Standard[28:32, 0:3]\n",
    "validation_labels_Standard = np_data_Standard[27, 0:3]\n",
    "\n",
    "# reshape the validation data because it's only one row\n",
    "validation_features_Standard = validation_features_Standard.reshape(1, -1)\n",
    "validation_labels_Standard = validation_labels_Standard.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1100.  ,    0.05,    0.69,    0.29],\n",
       "       [1095.  ,    0.15,    1.2 ,    1.87],\n",
       "       [1097.  ,    0.13,    1.14,    1.54],\n",
       "       [1094.  ,    0.12,    1.15,    1.45]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining original the testing group to compare against rescaled groups below\n",
    "np_test_data = np.concatenate([np_data[28:32, 0:3], np_data[28:32, 3:4]], axis=1)\n",
    "np_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1100.  ,    0.05,    0.69,    0.29],\n",
       "       [1095.  ,    0.15,    1.2 ,    1.87],\n",
       "       [1097.  ,    0.13,    1.14,    1.54],\n",
       "       [1094.  ,    0.12,    1.15,    1.45]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the MinMax testing group and rescale\n",
    "test_data_MinMax = np.concatenate([test_labels_MinMax, test_features_MinMax], axis=1)\n",
    "MinMax_scaler.inverse_transform(test_data_MinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1100.  ,    0.05,    0.69,    0.29],\n",
       "       [1095.  ,    0.15,    1.2 ,    1.87],\n",
       "       [1097.  ,    0.13,    1.14,    1.54],\n",
       "       [1094.  ,    0.12,    1.15,    1.45]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the Standard testing group and rescale\n",
    "test_data_Standard = np.concatenate([test_labels_Standard, test_features_Standard], axis=1)\n",
    "Standard_scaler.inverse_transform(test_data_Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters to try during Talos optimization\n",
    "\n",
    "p = {\n",
    "    'first_neuron': [8],\n",
    "    'second_neuron': [64],\n",
    "    'third_neuron': [64],\n",
    "    'fourth_neuron': [56],\n",
    "    'fifth_neuron': [48],\n",
    "    'sixth_neuron': [40],\n",
    "    'seventh_neuron': [32, 40],\n",
    "    'eighth_neuron': [24],\n",
    "    'nineth_neuron': [16],\n",
    "    'tenth_neuron': [8],\n",
    "    'batch_size': [10, 20, 30],\n",
    "    'activation': [relu,\n",
    "                   softsign,\n",
    "                   elu,\n",
    "                   linear],\n",
    "    'optimizer' : ['Adam'],\n",
    "    'epochs': [100, 1000, 10000],\n",
    "    'loss' : [mean_absolute_error, poisson] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model for MinMax scaled data to use with Talos\n",
    "def MinMax_ann(train_features, train_labels, test_features, test_labels, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=2, activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['third_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['fourth_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['fifth_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['sixth_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['seventh_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['eighth_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['nineth_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['tenth_neuron'], activation='relu'))\n",
    "    model.add(Dense(3, activation='linear'))\n",
    "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(train_features_MinMax, train_labels_MinMax,\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[test_features_MinMax, test_labels_MinMax])\n",
    "    \n",
    "    # model output\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model for Standard scaled data to use with Talos\n",
    "def Standard_ann(train_features, train_labels, test_features, test_labels, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=2, activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['third_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['fourth_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['fifth_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['sixth_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['seventh_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['eighth_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['nineth_neuron'], activation='relu'))\n",
    "    model.add(Dense(params['tenth_neuron'], activation='relu'))\n",
    "    model.add(Dense(3, activation='linear'))\n",
    "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(train_features_Standard, train_labels_Standard,\n",
    "                    epochs=params['epochs'],\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[test_features_Standard, test_labels_Standard])\n",
    "    \n",
    "    # model output\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine MinMax training and test features, and training and test labels for Talos experiment\n",
    "features_MinMax = np.concatenate((train_features_MinMax, test_features_MinMax), axis=0)\n",
    "labels_MinMax = np.concatenate((train_labels_MinMax, test_labels_MinMax), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine Standard training and test features, and training and test labels for Talos experiment\n",
    "features_Standard = np.concatenate((train_features_Standard, test_features_Standard), axis=0)\n",
    "labels_Standard = np.concatenate((train_labels_Standard, test_labels_Standard), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://rdrr.io/cran/kerasR/man/Initalizers.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the Talos experiment on MinMax data and model\n",
    "MinMax_t = ta.Scan(features_MinMax, labels_MinMax, \n",
    "            params=p, \n",
    "            model=MinMax_ann,\n",
    "            experiment_name='MinMax',\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the Talos experiment on Standard data and model\n",
    "Standard_t = ta.Scan(features_Standard, labels_Standard, \n",
    "            params=p, \n",
    "            model=Standard_ann,\n",
    "            experiment_name='Standard'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results data\n",
    "MinMax_reporting = pd.read_csv('MinMax\\\\082519080201.csv')\n",
    "Standard_reporting = pd.read_csv('Standard\\\\082519092035.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>eighth_neuron</th>\n",
       "      <th>epochs</th>\n",
       "      <th>fifth_neuron</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>fourth_neuron</th>\n",
       "      <th>loss.1</th>\n",
       "      <th>nineth_neuron</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>second_neuron</th>\n",
       "      <th>seventh_neuron</th>\n",
       "      <th>sixth_neuron</th>\n",
       "      <th>tenth_neuron</th>\n",
       "      <th>third_neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.181324</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25004</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>&lt;function linear at 0x00000000100513A8&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>1000</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>&lt;function mean_absolute_error at 0x00000000100...</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_epochs  val_loss  val_acc     loss       acc  \\\n",
       "124          1000  0.181324      0.5  0.25004  0.703704   \n",
       "\n",
       "                                  activation  batch_size  eighth_neuron  \\\n",
       "124  <function linear at 0x00000000100513A8>          20             24   \n",
       "\n",
       "     epochs  fifth_neuron  first_neuron  fourth_neuron  \\\n",
       "124    1000            48             8             56   \n",
       "\n",
       "                                                loss.1  nineth_neuron  \\\n",
       "124  <function mean_absolute_error at 0x00000000100...             16   \n",
       "\n",
       "    optimizer  second_neuron  seventh_neuron  sixth_neuron  tenth_neuron  \\\n",
       "124      Adam             64              32            40             8   \n",
       "\n",
       "     third_neuron  \n",
       "124            64  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by validation loss and accuracy and show to best result\n",
    "MinMax_reporting.sort_values(['val_loss', 'val_acc'], ascending=[True, False], inplace=True)\n",
    "MinMax_reporting.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>eighth_neuron</th>\n",
       "      <th>epochs</th>\n",
       "      <th>fifth_neuron</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>fourth_neuron</th>\n",
       "      <th>loss.1</th>\n",
       "      <th>nineth_neuron</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>second_neuron</th>\n",
       "      <th>seventh_neuron</th>\n",
       "      <th>sixth_neuron</th>\n",
       "      <th>tenth_neuron</th>\n",
       "      <th>third_neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.180523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;function softsign at 0x0000000010051048&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>10000</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>&lt;function mean_absolute_error at 0x00000000100...</td>\n",
       "      <td>16</td>\n",
       "      <td>Adam</td>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    round_epochs  val_loss  val_acc      loss  acc  \\\n",
       "57         10000  0.180523      1.0  0.036529  1.0   \n",
       "\n",
       "                                   activation  batch_size  eighth_neuron  \\\n",
       "57  <function softsign at 0x0000000010051048>          20             24   \n",
       "\n",
       "    epochs  fifth_neuron  first_neuron  fourth_neuron  \\\n",
       "57   10000            48             8             56   \n",
       "\n",
       "                                               loss.1  nineth_neuron  \\\n",
       "57  <function mean_absolute_error at 0x00000000100...             16   \n",
       "\n",
       "   optimizer  second_neuron  seventh_neuron  sixth_neuron  tenth_neuron  \\\n",
       "57      Adam             64              40            40             8   \n",
       "\n",
       "    third_neuron  \n",
       "57            64  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by validation loss and accuracy and show the best result\n",
    "Standard_reporting.sort_values(['val_loss', 'val_acc'], ascending=[True, False], inplace=True)\n",
    "Standard_reporting.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the MinMax model using the top performing parameters from Talos\n",
    "MinMax_model = Sequential()\n",
    "MinMax_model.add(Dense(8, input_dim=1, activation='relu'))\n",
    "MinMax_model.add(Dense(64, activation='relu'))\n",
    "MinMax_model.add(Dense(64, activation='relu'))\n",
    "MinMax_model.add(Dense(56, activation='relu'))\n",
    "MinMax_model.add(Dense(48, activation='relu'))\n",
    "MinMax_model.add(Dense(40, activation='relu'))\n",
    "MinMax_model.add(Dense(32, activation='relu'))\n",
    "MinMax_model.add(Dense(24, activation='relu'))\n",
    "MinMax_model.add(Dense(16, activation='relu'))\n",
    "MinMax_model.add(Dense(8, activation='relu'))\n",
    "MinMax_model.add(Dense(3, activation='relu'))\n",
    "MinMax_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "MinMax_model.fit(train_features_MinMax,\n",
    "                 train_labels_MinMax,\n",
    "                 validation_data=(test_features_MinMax, test_labels_MinMax),\n",
    "                 batch_size=20,\n",
    "                 epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weights_list = MinMax_model.get_weights()\n",
    "weights_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS THE BEST SO FAR, DO NOT DELETE!\n",
    "\n",
    "# Define the Standard model using the top performing parameters from Talos\n",
    "Standard_model = Sequential()\n",
    "Standard_model.add(Dense(8, input_dim=2, activation='relu'))\n",
    "Standard_model.add(Dense(64, activation='relu'))\n",
    "Standard_model.add(Dense(64, activation='relu'))\n",
    "Standard_model.add(Dense(56, activation='relu'))\n",
    "Standard_model.add(Dense(48, activation='relu'))\n",
    "Standard_model.add(Dense(40, activation='relu'))\n",
    "Standard_model.add(Dense(32, activation='relu'))\n",
    "Standard_model.add(Dense(24, activation='relu'))\n",
    "Standard_model.add(Dense(16, activation='relu'))\n",
    "Standard_model.add(Dense(8, activation='relu'))\n",
    "Standard_model.add(Dense(3, activation='linear'))\n",
    "Standard_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "Standard_model.fit(train_features_Standard,\n",
    "                 train_labels_Standard,\n",
    "                 validation_data=(test_features_Standard, test_labels_Standard),\n",
    "                 batch_size=20,\n",
    "                 epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 4 samples\n",
      "Epoch 1/1000\n",
      "27/27 [==============================] - 4s 164ms/step - loss: 0.8368 - acc: 0.4074 - val_loss: 0.9119 - val_acc: 0.2500\n",
      "Epoch 2/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8351 - acc: 0.5185 - val_loss: 0.9120 - val_acc: 0.2500\n",
      "Epoch 3/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8332 - acc: 0.5185 - val_loss: 0.9117 - val_acc: 0.2500\n",
      "Epoch 4/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8316 - acc: 0.5185 - val_loss: 0.9118 - val_acc: 0.2500\n",
      "Epoch 5/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.8295 - acc: 0.5185 - val_loss: 0.9122 - val_acc: 0.2500\n",
      "Epoch 6/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8273 - acc: 0.5185 - val_loss: 0.9121 - val_acc: 0.2500\n",
      "Epoch 7/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8246 - acc: 0.5185 - val_loss: 0.9122 - val_acc: 0.2500\n",
      "Epoch 8/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8212 - acc: 0.5185 - val_loss: 0.9119 - val_acc: 0.2500\n",
      "Epoch 9/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.8170 - acc: 0.5185 - val_loss: 0.9113 - val_acc: 0.5000\n",
      "Epoch 10/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8114 - acc: 0.5926 - val_loss: 0.9103 - val_acc: 0.5000\n",
      "Epoch 11/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.8043 - acc: 0.5926 - val_loss: 0.9084 - val_acc: 0.5000\n",
      "Epoch 12/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7983 - acc: 0.5926 - val_loss: 0.9050 - val_acc: 0.5000\n",
      "Epoch 13/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7907 - acc: 0.5926 - val_loss: 0.9007 - val_acc: 0.5000\n",
      "Epoch 14/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7813 - acc: 0.5926 - val_loss: 0.8957 - val_acc: 0.5000\n",
      "Epoch 15/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7705 - acc: 0.5926 - val_loss: 0.8898 - val_acc: 0.5000\n",
      "Epoch 16/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7583 - acc: 0.5926 - val_loss: 0.8898 - val_acc: 0.2500\n",
      "Epoch 17/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7368 - acc: 0.6667 - val_loss: 0.9055 - val_acc: 0.2500\n",
      "Epoch 18/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7199 - acc: 0.6667 - val_loss: 0.9379 - val_acc: 0.2500\n",
      "Epoch 19/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7168 - acc: 0.6296 - val_loss: 0.9071 - val_acc: 0.2500\n",
      "Epoch 20/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.7148 - acc: 0.5185 - val_loss: 0.8945 - val_acc: 0.5000\n",
      "Epoch 21/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7074 - acc: 0.4444 - val_loss: 0.9157 - val_acc: 0.5000\n",
      "Epoch 22/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.7024 - acc: 0.5185 - val_loss: 0.9170 - val_acc: 0.5000\n",
      "Epoch 23/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.6987 - acc: 0.5556 - val_loss: 0.8594 - val_acc: 0.5000\n",
      "Epoch 24/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6867 - acc: 0.4444 - val_loss: 0.8290 - val_acc: 0.5000\n",
      "Epoch 25/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6788 - acc: 0.4815 - val_loss: 0.8161 - val_acc: 0.5000\n",
      "Epoch 26/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6692 - acc: 0.4815 - val_loss: 0.8064 - val_acc: 0.5000\n",
      "Epoch 27/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.6479 - acc: 0.5556 - val_loss: 0.8267 - val_acc: 0.2500\n",
      "Epoch 28/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6334 - acc: 0.5185 - val_loss: 0.8827 - val_acc: 0.2500\n",
      "Epoch 29/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6352 - acc: 0.5556 - val_loss: 0.8744 - val_acc: 0.2500\n",
      "Epoch 30/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.6294 - acc: 0.5556 - val_loss: 0.8436 - val_acc: 0.2500\n",
      "Epoch 31/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6342 - acc: 0.5185 - val_loss: 0.8332 - val_acc: 0.2500\n",
      "Epoch 32/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6241 - acc: 0.5185 - val_loss: 0.8162 - val_acc: 0.2500\n",
      "Epoch 33/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6181 - acc: 0.5556 - val_loss: 0.8035 - val_acc: 0.2500\n",
      "Epoch 34/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6196 - acc: 0.5556 - val_loss: 0.8022 - val_acc: 0.2500\n",
      "Epoch 35/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6149 - acc: 0.5556 - val_loss: 0.7992 - val_acc: 0.2500\n",
      "Epoch 36/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.6188 - acc: 0.5556 - val_loss: 0.7955 - val_acc: 0.2500\n",
      "Epoch 37/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6130 - acc: 0.5926 - val_loss: 0.7894 - val_acc: 0.5000\n",
      "Epoch 38/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6126 - acc: 0.5926 - val_loss: 0.7814 - val_acc: 0.5000\n",
      "Epoch 39/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6123 - acc: 0.5556 - val_loss: 0.7761 - val_acc: 0.5000\n",
      "Epoch 40/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.6120 - acc: 0.5556 - val_loss: 0.7683 - val_acc: 0.5000\n",
      "Epoch 41/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6080 - acc: 0.7037 - val_loss: 0.7782 - val_acc: 0.5000\n",
      "Epoch 42/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6103 - acc: 0.7407 - val_loss: 0.7769 - val_acc: 0.5000\n",
      "Epoch 43/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6077 - acc: 0.6296 - val_loss: 0.7935 - val_acc: 0.5000\n",
      "Epoch 44/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6136 - acc: 0.5926 - val_loss: 0.8132 - val_acc: 0.5000\n",
      "Epoch 45/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.6124 - acc: 0.6296 - val_loss: 0.7886 - val_acc: 0.5000\n",
      "Epoch 46/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.6063 - acc: 0.7037 - val_loss: 0.7522 - val_acc: 0.5000\n",
      "Epoch 47/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6045 - acc: 0.7407 - val_loss: 0.7410 - val_acc: 0.5000\n",
      "Epoch 48/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6026 - acc: 0.6296 - val_loss: 0.7421 - val_acc: 0.5000\n",
      "Epoch 49/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6012 - acc: 0.6667 - val_loss: 0.7489 - val_acc: 0.5000\n",
      "Epoch 50/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6017 - acc: 0.7407 - val_loss: 0.7615 - val_acc: 0.5000\n",
      "Epoch 51/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5988 - acc: 0.6667 - val_loss: 0.7638 - val_acc: 0.5000\n",
      "Epoch 52/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5993 - acc: 0.5926 - val_loss: 0.7500 - val_acc: 0.5000\n",
      "Epoch 53/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.6004 - acc: 0.5556 - val_loss: 0.7419 - val_acc: 0.5000\n",
      "Epoch 54/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5958 - acc: 0.6667 - val_loss: 0.7434 - val_acc: 0.5000\n",
      "Epoch 55/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5962 - acc: 0.7407 - val_loss: 0.7538 - val_acc: 0.5000\n",
      "Epoch 56/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5926 - acc: 0.7037 - val_loss: 0.7498 - val_acc: 0.5000\n",
      "Epoch 57/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5918 - acc: 0.7037 - val_loss: 0.7440 - val_acc: 0.5000\n",
      "Epoch 58/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5939 - acc: 0.7037 - val_loss: 0.7626 - val_acc: 0.2500\n",
      "Epoch 59/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5939 - acc: 0.6667 - val_loss: 0.7382 - val_acc: 0.5000\n",
      "Epoch 60/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5990 - acc: 0.6296 - val_loss: 0.7326 - val_acc: 0.5000\n",
      "Epoch 61/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5958 - acc: 0.6296 - val_loss: 0.7403 - val_acc: 0.5000\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5978 - acc: 0.7407 - val_loss: 0.7381 - val_acc: 0.5000\n",
      "Epoch 63/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5937 - acc: 0.7407 - val_loss: 0.7340 - val_acc: 0.5000\n",
      "Epoch 64/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5964 - acc: 0.6667 - val_loss: 0.7360 - val_acc: 0.5000\n",
      "Epoch 65/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5943 - acc: 0.5926 - val_loss: 0.7541 - val_acc: 0.2500\n",
      "Epoch 66/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5859 - acc: 0.6667 - val_loss: 0.7600 - val_acc: 0.2500\n",
      "Epoch 67/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5907 - acc: 0.6667 - val_loss: 0.7238 - val_acc: 0.2500\n",
      "Epoch 68/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5921 - acc: 0.5926 - val_loss: 0.7182 - val_acc: 0.2500\n",
      "Epoch 69/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5943 - acc: 0.6296 - val_loss: 0.7401 - val_acc: 0.2500\n",
      "Epoch 70/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5844 - acc: 0.6667 - val_loss: 0.7606 - val_acc: 0.2500\n",
      "Epoch 71/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5991 - acc: 0.6667 - val_loss: 0.7364 - val_acc: 0.5000\n",
      "Epoch 72/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5925 - acc: 0.6667 - val_loss: 0.7227 - val_acc: 0.5000\n",
      "Epoch 73/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6009 - acc: 0.5556 - val_loss: 0.7259 - val_acc: 0.5000\n",
      "Epoch 74/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5914 - acc: 0.6667 - val_loss: 0.7342 - val_acc: 0.5000\n",
      "Epoch 75/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5835 - acc: 0.7037 - val_loss: 0.7179 - val_acc: 0.2500\n",
      "Epoch 76/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5778 - acc: 0.6667 - val_loss: 0.7080 - val_acc: 0.2500\n",
      "Epoch 77/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5796 - acc: 0.5556 - val_loss: 0.7058 - val_acc: 0.2500\n",
      "Epoch 78/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5801 - acc: 0.5556 - val_loss: 0.7036 - val_acc: 0.2500\n",
      "Epoch 79/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5775 - acc: 0.5556 - val_loss: 0.7079 - val_acc: 0.2500\n",
      "Epoch 80/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5756 - acc: 0.6667 - val_loss: 0.7067 - val_acc: 0.2500\n",
      "Epoch 81/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5746 - acc: 0.6667 - val_loss: 0.7203 - val_acc: 0.2500\n",
      "Epoch 82/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5733 - acc: 0.6667 - val_loss: 0.7290 - val_acc: 0.2500\n",
      "Epoch 83/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5735 - acc: 0.6667 - val_loss: 0.7078 - val_acc: 0.2500\n",
      "Epoch 84/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5737 - acc: 0.6667 - val_loss: 0.6982 - val_acc: 0.2500\n",
      "Epoch 85/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5769 - acc: 0.6667 - val_loss: 0.7003 - val_acc: 0.2500\n",
      "Epoch 86/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5741 - acc: 0.6667 - val_loss: 0.7133 - val_acc: 0.2500\n",
      "Epoch 87/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5718 - acc: 0.6667 - val_loss: 0.7197 - val_acc: 0.2500\n",
      "Epoch 88/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5748 - acc: 0.6667 - val_loss: 0.7300 - val_acc: 0.2500\n",
      "Epoch 89/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5733 - acc: 0.6667 - val_loss: 0.7192 - val_acc: 0.2500\n",
      "Epoch 90/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5737 - acc: 0.6667 - val_loss: 0.7203 - val_acc: 0.2500\n",
      "Epoch 91/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5736 - acc: 0.6667 - val_loss: 0.7259 - val_acc: 0.2500\n",
      "Epoch 92/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5729 - acc: 0.6667 - val_loss: 0.7289 - val_acc: 0.2500\n",
      "Epoch 93/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5712 - acc: 0.6667 - val_loss: 0.7287 - val_acc: 0.2500\n",
      "Epoch 94/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5742 - acc: 0.6667 - val_loss: 0.7053 - val_acc: 0.2500\n",
      "Epoch 95/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5729 - acc: 0.6667 - val_loss: 0.7101 - val_acc: 0.2500\n",
      "Epoch 96/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5710 - acc: 0.6667 - val_loss: 0.7214 - val_acc: 0.2500\n",
      "Epoch 97/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5706 - acc: 0.6667 - val_loss: 0.7196 - val_acc: 0.2500\n",
      "Epoch 98/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5703 - acc: 0.6667 - val_loss: 0.7153 - val_acc: 0.2500\n",
      "Epoch 99/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5695 - acc: 0.6667 - val_loss: 0.7158 - val_acc: 0.2500\n",
      "Epoch 100/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5696 - acc: 0.6667 - val_loss: 0.7114 - val_acc: 0.2500\n",
      "Epoch 101/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5693 - acc: 0.6667 - val_loss: 0.7153 - val_acc: 0.2500\n",
      "Epoch 102/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5698 - acc: 0.6667 - val_loss: 0.7104 - val_acc: 0.2500\n",
      "Epoch 103/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5711 - acc: 0.6667 - val_loss: 0.7232 - val_acc: 0.2500\n",
      "Epoch 104/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5699 - acc: 0.6667 - val_loss: 0.7175 - val_acc: 0.2500\n",
      "Epoch 105/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5690 - acc: 0.6667 - val_loss: 0.7019 - val_acc: 0.2500\n",
      "Epoch 106/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5714 - acc: 0.6667 - val_loss: 0.7163 - val_acc: 0.2500\n",
      "Epoch 107/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5681 - acc: 0.6667 - val_loss: 0.7379 - val_acc: 0.2500\n",
      "Epoch 108/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5745 - acc: 0.6667 - val_loss: 0.7205 - val_acc: 0.2500\n",
      "Epoch 109/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5702 - acc: 0.6667 - val_loss: 0.7149 - val_acc: 0.2500\n",
      "Epoch 110/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5702 - acc: 0.6667 - val_loss: 0.7170 - val_acc: 0.2500\n",
      "Epoch 111/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5724 - acc: 0.6667 - val_loss: 0.7113 - val_acc: 0.2500\n",
      "Epoch 112/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5693 - acc: 0.6667 - val_loss: 0.7236 - val_acc: 0.2500\n",
      "Epoch 113/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5695 - acc: 0.6296 - val_loss: 0.7497 - val_acc: 0.2500\n",
      "Epoch 114/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5727 - acc: 0.6667 - val_loss: 0.7673 - val_acc: 0.2500\n",
      "Epoch 115/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5794 - acc: 0.6667 - val_loss: 0.7324 - val_acc: 0.2500\n",
      "Epoch 116/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5700 - acc: 0.6667 - val_loss: 0.7006 - val_acc: 0.2500\n",
      "Epoch 117/1000\n",
      "27/27 [==============================] - 0s 648us/step - loss: 0.5729 - acc: 0.7037 - val_loss: 0.7016 - val_acc: 0.2500\n",
      "Epoch 118/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5743 - acc: 0.6667 - val_loss: 0.7052 - val_acc: 0.2500\n",
      "Epoch 119/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5776 - acc: 0.6667 - val_loss: 0.7108 - val_acc: 0.2500\n",
      "Epoch 120/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5700 - acc: 0.6667 - val_loss: 0.7148 - val_acc: 0.2500\n",
      "Epoch 121/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5690 - acc: 0.6667 - val_loss: 0.7185 - val_acc: 0.2500\n",
      "Epoch 122/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5695 - acc: 0.6667 - val_loss: 0.7170 - val_acc: 0.2500\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5672 - acc: 0.6667 - val_loss: 0.7148 - val_acc: 0.2500\n",
      "Epoch 124/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5665 - acc: 0.6667 - val_loss: 0.7117 - val_acc: 0.2500\n",
      "Epoch 125/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5661 - acc: 0.6667 - val_loss: 0.7371 - val_acc: 0.2500\n",
      "Epoch 126/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5679 - acc: 0.6667 - val_loss: 0.7321 - val_acc: 0.2500\n",
      "Epoch 127/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5675 - acc: 0.6667 - val_loss: 0.7259 - val_acc: 0.2500\n",
      "Epoch 128/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5646 - acc: 0.6667 - val_loss: 0.7330 - val_acc: 0.2500\n",
      "Epoch 129/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5657 - acc: 0.6667 - val_loss: 0.7158 - val_acc: 0.2500\n",
      "Epoch 130/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5645 - acc: 0.6667 - val_loss: 0.7028 - val_acc: 0.2500\n",
      "Epoch 131/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5771 - acc: 0.6296 - val_loss: 0.7064 - val_acc: 0.2500\n",
      "Epoch 132/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5748 - acc: 0.6667 - val_loss: 0.7247 - val_acc: 0.2500\n",
      "Epoch 133/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5673 - acc: 0.6667 - val_loss: 0.7380 - val_acc: 0.2500\n",
      "Epoch 134/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5700 - acc: 0.6667 - val_loss: 0.7233 - val_acc: 0.2500\n",
      "Epoch 135/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5635 - acc: 0.6667 - val_loss: 0.7178 - val_acc: 0.2500\n",
      "Epoch 136/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5652 - acc: 0.6667 - val_loss: 0.7242 - val_acc: 0.2500\n",
      "Epoch 137/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5638 - acc: 0.6667 - val_loss: 0.7335 - val_acc: 0.2500\n",
      "Epoch 138/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5631 - acc: 0.6667 - val_loss: 0.7296 - val_acc: 0.2500\n",
      "Epoch 139/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5620 - acc: 0.6667 - val_loss: 0.7269 - val_acc: 0.2500\n",
      "Epoch 140/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5631 - acc: 0.6667 - val_loss: 0.7131 - val_acc: 0.2500\n",
      "Epoch 141/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5615 - acc: 0.6667 - val_loss: 0.7196 - val_acc: 0.2500\n",
      "Epoch 142/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5618 - acc: 0.6667 - val_loss: 0.7111 - val_acc: 0.2500\n",
      "Epoch 143/1000\n",
      "27/27 [==============================] - 0s 648us/step - loss: 0.5609 - acc: 0.6667 - val_loss: 0.7081 - val_acc: 0.2500\n",
      "Epoch 144/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5628 - acc: 0.6667 - val_loss: 0.7228 - val_acc: 0.2500\n",
      "Epoch 145/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5595 - acc: 0.6667 - val_loss: 0.7311 - val_acc: 0.2500\n",
      "Epoch 146/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5609 - acc: 0.6667 - val_loss: 0.7221 - val_acc: 0.2500\n",
      "Epoch 147/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5617 - acc: 0.6667 - val_loss: 0.7137 - val_acc: 0.2500\n",
      "Epoch 148/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5622 - acc: 0.6667 - val_loss: 0.7195 - val_acc: 0.2500\n",
      "Epoch 149/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5597 - acc: 0.6667 - val_loss: 0.7259 - val_acc: 0.2500\n",
      "Epoch 150/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5594 - acc: 0.6667 - val_loss: 0.7405 - val_acc: 0.2500\n",
      "Epoch 151/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5607 - acc: 0.6667 - val_loss: 0.7273 - val_acc: 0.2500\n",
      "Epoch 152/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5619 - acc: 0.6667 - val_loss: 0.7337 - val_acc: 0.2500\n",
      "Epoch 153/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5646 - acc: 0.6667 - val_loss: 0.7264 - val_acc: 0.2500\n",
      "Epoch 154/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5647 - acc: 0.6667 - val_loss: 0.6941 - val_acc: 0.2500\n",
      "Epoch 155/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5721 - acc: 0.6296 - val_loss: 0.6928 - val_acc: 0.2500\n",
      "Epoch 156/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5674 - acc: 0.6667 - val_loss: 0.7454 - val_acc: 0.2500\n",
      "Epoch 157/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5657 - acc: 0.6667 - val_loss: 0.7612 - val_acc: 0.2500\n",
      "Epoch 158/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5686 - acc: 0.6667 - val_loss: 0.7245 - val_acc: 0.2500\n",
      "Epoch 159/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5663 - acc: 0.7037 - val_loss: 0.7073 - val_acc: 0.2500\n",
      "Epoch 160/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5654 - acc: 0.6667 - val_loss: 0.7283 - val_acc: 0.2500\n",
      "Epoch 161/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5621 - acc: 0.6667 - val_loss: 0.7325 - val_acc: 0.2500\n",
      "Epoch 162/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5631 - acc: 0.6667 - val_loss: 0.7271 - val_acc: 0.2500\n",
      "Epoch 163/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5604 - acc: 0.6667 - val_loss: 0.7445 - val_acc: 0.2500\n",
      "Epoch 164/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5598 - acc: 0.6667 - val_loss: 0.7519 - val_acc: 0.2500\n",
      "Epoch 165/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5648 - acc: 0.6667 - val_loss: 0.7288 - val_acc: 0.2500\n",
      "Epoch 166/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5575 - acc: 0.6667 - val_loss: 0.7118 - val_acc: 0.2500\n",
      "Epoch 167/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5608 - acc: 0.6667 - val_loss: 0.7247 - val_acc: 0.2500\n",
      "Epoch 168/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5623 - acc: 0.6667 - val_loss: 0.7427 - val_acc: 0.2500\n",
      "Epoch 169/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5613 - acc: 0.6667 - val_loss: 0.7383 - val_acc: 0.2500\n",
      "Epoch 170/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5584 - acc: 0.6667 - val_loss: 0.7244 - val_acc: 0.2500\n",
      "Epoch 171/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5596 - acc: 0.6667 - val_loss: 0.7215 - val_acc: 0.2500\n",
      "Epoch 172/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5563 - acc: 0.6667 - val_loss: 0.7176 - val_acc: 0.2500\n",
      "Epoch 173/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5624 - acc: 0.6667 - val_loss: 0.7140 - val_acc: 0.2500\n",
      "Epoch 174/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5578 - acc: 0.6667 - val_loss: 0.7093 - val_acc: 0.2500\n",
      "Epoch 175/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5575 - acc: 0.6667 - val_loss: 0.7283 - val_acc: 0.2500\n",
      "Epoch 176/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5614 - acc: 0.6667 - val_loss: 0.7488 - val_acc: 0.2500\n",
      "Epoch 177/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5620 - acc: 0.6667 - val_loss: 0.7298 - val_acc: 0.2500\n",
      "Epoch 178/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5622 - acc: 0.6667 - val_loss: 0.7341 - val_acc: 0.2500\n",
      "Epoch 179/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5604 - acc: 0.6667 - val_loss: 0.7251 - val_acc: 0.2500\n",
      "Epoch 180/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5575 - acc: 0.6667 - val_loss: 0.7111 - val_acc: 0.2500\n",
      "Epoch 181/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5569 - acc: 0.6667 - val_loss: 0.7219 - val_acc: 0.2500\n",
      "Epoch 182/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5562 - acc: 0.6667 - val_loss: 0.7396 - val_acc: 0.2500\n",
      "Epoch 183/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5569 - acc: 0.6667 - val_loss: 0.7278 - val_acc: 0.2500\n",
      "Epoch 184/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5565 - acc: 0.6667 - val_loss: 0.7380 - val_acc: 0.2500\n",
      "Epoch 185/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5594 - acc: 0.6667 - val_loss: 0.7167 - val_acc: 0.2500\n",
      "Epoch 186/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5539 - acc: 0.6667 - val_loss: 0.7224 - val_acc: 0.2500\n",
      "Epoch 187/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5537 - acc: 0.6667 - val_loss: 0.7324 - val_acc: 0.2500\n",
      "Epoch 188/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5572 - acc: 0.6667 - val_loss: 0.7206 - val_acc: 0.2500\n",
      "Epoch 189/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5560 - acc: 0.6667 - val_loss: 0.7223 - val_acc: 0.2500\n",
      "Epoch 190/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5566 - acc: 0.6667 - val_loss: 0.7256 - val_acc: 0.2500\n",
      "Epoch 191/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5568 - acc: 0.6667 - val_loss: 0.7146 - val_acc: 0.2500\n",
      "Epoch 192/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5544 - acc: 0.6667 - val_loss: 0.7013 - val_acc: 0.2500\n",
      "Epoch 193/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5606 - acc: 0.6667 - val_loss: 0.7310 - val_acc: 0.2500\n",
      "Epoch 194/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5577 - acc: 0.6667 - val_loss: 0.7437 - val_acc: 0.2500\n",
      "Epoch 195/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5575 - acc: 0.6667 - val_loss: 0.7179 - val_acc: 0.2500\n",
      "Epoch 196/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5534 - acc: 0.6667 - val_loss: 0.7257 - val_acc: 0.2500\n",
      "Epoch 197/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5590 - acc: 0.6667 - val_loss: 0.7123 - val_acc: 0.2500\n",
      "Epoch 198/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5564 - acc: 0.6667 - val_loss: 0.7376 - val_acc: 0.2500\n",
      "Epoch 199/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5547 - acc: 0.6667 - val_loss: 0.7451 - val_acc: 0.2500\n",
      "Epoch 200/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5567 - acc: 0.6667 - val_loss: 0.7144 - val_acc: 0.2500\n",
      "Epoch 201/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5561 - acc: 0.6667 - val_loss: 0.7196 - val_acc: 0.2500\n",
      "Epoch 202/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5543 - acc: 0.6667 - val_loss: 0.7348 - val_acc: 0.2500\n",
      "Epoch 203/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5574 - acc: 0.6667 - val_loss: 0.7306 - val_acc: 0.2500\n",
      "Epoch 204/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5582 - acc: 0.6667 - val_loss: 0.7225 - val_acc: 0.2500\n",
      "Epoch 205/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5550 - acc: 0.6667 - val_loss: 0.7319 - val_acc: 0.2500\n",
      "Epoch 206/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5564 - acc: 0.6667 - val_loss: 0.7107 - val_acc: 0.2500\n",
      "Epoch 207/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5566 - acc: 0.6667 - val_loss: 0.7300 - val_acc: 0.2500\n",
      "Epoch 208/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5568 - acc: 0.6667 - val_loss: 0.7618 - val_acc: 0.2500\n",
      "Epoch 209/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5678 - acc: 0.6667 - val_loss: 0.7405 - val_acc: 0.2500\n",
      "Epoch 210/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5582 - acc: 0.6667 - val_loss: 0.7052 - val_acc: 0.2500\n",
      "Epoch 211/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5606 - acc: 0.6667 - val_loss: 0.7121 - val_acc: 0.2500\n",
      "Epoch 212/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5569 - acc: 0.6667 - val_loss: 0.7307 - val_acc: 0.2500\n",
      "Epoch 213/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5544 - acc: 0.6667 - val_loss: 0.7339 - val_acc: 0.2500\n",
      "Epoch 214/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5592 - acc: 0.6667 - val_loss: 0.7405 - val_acc: 0.2500\n",
      "Epoch 215/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5548 - acc: 0.6667 - val_loss: 0.7294 - val_acc: 0.2500\n",
      "Epoch 216/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5535 - acc: 0.6667 - val_loss: 0.7078 - val_acc: 0.2500\n",
      "Epoch 217/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5558 - acc: 0.6667 - val_loss: 0.7151 - val_acc: 0.2500\n",
      "Epoch 218/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5548 - acc: 0.6667 - val_loss: 0.7235 - val_acc: 0.2500\n",
      "Epoch 219/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5556 - acc: 0.6667 - val_loss: 0.7139 - val_acc: 0.2500\n",
      "Epoch 220/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5541 - acc: 0.6667 - val_loss: 0.7402 - val_acc: 0.2500\n",
      "Epoch 221/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5559 - acc: 0.6667 - val_loss: 0.7320 - val_acc: 0.2500\n",
      "Epoch 222/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5515 - acc: 0.6667 - val_loss: 0.7210 - val_acc: 0.2500\n",
      "Epoch 223/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5549 - acc: 0.6667 - val_loss: 0.7088 - val_acc: 0.2500\n",
      "Epoch 224/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5555 - acc: 0.6667 - val_loss: 0.7045 - val_acc: 0.2500\n",
      "Epoch 225/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5579 - acc: 0.6667 - val_loss: 0.7346 - val_acc: 0.2500\n",
      "Epoch 226/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5560 - acc: 0.6667 - val_loss: 0.7497 - val_acc: 0.2500\n",
      "Epoch 227/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5567 - acc: 0.6667 - val_loss: 0.7298 - val_acc: 0.2500\n",
      "Epoch 228/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5599 - acc: 0.6667 - val_loss: 0.7133 - val_acc: 0.2500\n",
      "Epoch 229/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5620 - acc: 0.5556 - val_loss: 0.7248 - val_acc: 0.2500\n",
      "Epoch 230/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5569 - acc: 0.6667 - val_loss: 0.7483 - val_acc: 0.2500\n",
      "Epoch 231/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5613 - acc: 0.6667 - val_loss: 0.7525 - val_acc: 0.2500\n",
      "Epoch 232/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5599 - acc: 0.6667 - val_loss: 0.7255 - val_acc: 0.2500\n",
      "Epoch 233/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5546 - acc: 0.6296 - val_loss: 0.7088 - val_acc: 0.2500\n",
      "Epoch 234/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5572 - acc: 0.6296 - val_loss: 0.7442 - val_acc: 0.2500\n",
      "Epoch 235/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5542 - acc: 0.6667 - val_loss: 0.7582 - val_acc: 0.2500\n",
      "Epoch 236/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5595 - acc: 0.6667 - val_loss: 0.7324 - val_acc: 0.2500\n",
      "Epoch 237/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5525 - acc: 0.6667 - val_loss: 0.7116 - val_acc: 0.2500\n",
      "Epoch 238/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5563 - acc: 0.6667 - val_loss: 0.7238 - val_acc: 0.2500\n",
      "Epoch 239/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5588 - acc: 0.6667 - val_loss: 0.7388 - val_acc: 0.2500\n",
      "Epoch 240/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5564 - acc: 0.6667 - val_loss: 0.7291 - val_acc: 0.2500\n",
      "Epoch 241/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5506 - acc: 0.6667 - val_loss: 0.7199 - val_acc: 0.2500\n",
      "Epoch 242/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5581 - acc: 0.5556 - val_loss: 0.7359 - val_acc: 0.2500\n",
      "Epoch 243/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5539 - acc: 0.6667 - val_loss: 0.7570 - val_acc: 0.2500\n",
      "Epoch 244/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5584 - acc: 0.6667 - val_loss: 0.7204 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5563 - acc: 0.6667 - val_loss: 0.7140 - val_acc: 0.2500\n",
      "Epoch 246/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5586 - acc: 0.6667 - val_loss: 0.7382 - val_acc: 0.2500\n",
      "Epoch 247/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5565 - acc: 0.6667 - val_loss: 0.7518 - val_acc: 0.2500\n",
      "Epoch 248/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5562 - acc: 0.6667 - val_loss: 0.7459 - val_acc: 0.2500\n",
      "Epoch 249/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5537 - acc: 0.6667 - val_loss: 0.7507 - val_acc: 0.2500\n",
      "Epoch 250/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5561 - acc: 0.6667 - val_loss: 0.7388 - val_acc: 0.2500\n",
      "Epoch 251/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5562 - acc: 0.6667 - val_loss: 0.7297 - val_acc: 0.2500\n",
      "Epoch 252/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5524 - acc: 0.6667 - val_loss: 0.7297 - val_acc: 0.2500\n",
      "Epoch 253/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5544 - acc: 0.6667 - val_loss: 0.7317 - val_acc: 0.2500\n",
      "Epoch 254/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5519 - acc: 0.6667 - val_loss: 0.7278 - val_acc: 0.2500\n",
      "Epoch 255/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5531 - acc: 0.6667 - val_loss: 0.7331 - val_acc: 0.2500\n",
      "Epoch 256/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5526 - acc: 0.6667 - val_loss: 0.7438 - val_acc: 0.2500\n",
      "Epoch 257/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5510 - acc: 0.6667 - val_loss: 0.7304 - val_acc: 0.2500\n",
      "Epoch 258/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5497 - acc: 0.6667 - val_loss: 0.7195 - val_acc: 0.2500\n",
      "Epoch 259/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5543 - acc: 0.6667 - val_loss: 0.7380 - val_acc: 0.2500\n",
      "Epoch 260/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5505 - acc: 0.6667 - val_loss: 0.7549 - val_acc: 0.2500\n",
      "Epoch 261/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5539 - acc: 0.6667 - val_loss: 0.7387 - val_acc: 0.2500\n",
      "Epoch 262/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5548 - acc: 0.6296 - val_loss: 0.7175 - val_acc: 0.2500\n",
      "Epoch 263/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5617 - acc: 0.6296 - val_loss: 0.7390 - val_acc: 0.2500\n",
      "Epoch 264/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5526 - acc: 0.6667 - val_loss: 0.7702 - val_acc: 0.2500\n",
      "Epoch 265/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5605 - acc: 0.6667 - val_loss: 0.7424 - val_acc: 0.2500\n",
      "Epoch 266/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5551 - acc: 0.6667 - val_loss: 0.7214 - val_acc: 0.2500\n",
      "Epoch 267/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5579 - acc: 0.6667 - val_loss: 0.7462 - val_acc: 0.2500\n",
      "Epoch 268/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5549 - acc: 0.6667 - val_loss: 0.7573 - val_acc: 0.2500\n",
      "Epoch 269/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5512 - acc: 0.6667 - val_loss: 0.7433 - val_acc: 0.2500\n",
      "Epoch 270/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5527 - acc: 0.6667 - val_loss: 0.7410 - val_acc: 0.2500\n",
      "Epoch 271/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5499 - acc: 0.6667 - val_loss: 0.7434 - val_acc: 0.2500\n",
      "Epoch 272/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5524 - acc: 0.6667 - val_loss: 0.7460 - val_acc: 0.2500\n",
      "Epoch 273/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5535 - acc: 0.6667 - val_loss: 0.7319 - val_acc: 0.2500\n",
      "Epoch 274/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5495 - acc: 0.6667 - val_loss: 0.7258 - val_acc: 0.2500\n",
      "Epoch 275/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5513 - acc: 0.6667 - val_loss: 0.7542 - val_acc: 0.2500\n",
      "Epoch 276/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5558 - acc: 0.6667 - val_loss: 0.7426 - val_acc: 0.2500\n",
      "Epoch 277/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5558 - acc: 0.6667 - val_loss: 0.7254 - val_acc: 0.2500\n",
      "Epoch 278/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5607 - acc: 0.6667 - val_loss: 0.7362 - val_acc: 0.2500\n",
      "Epoch 279/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5553 - acc: 0.6667 - val_loss: 0.7364 - val_acc: 0.2500\n",
      "Epoch 280/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5551 - acc: 0.6667 - val_loss: 0.7207 - val_acc: 0.2500\n",
      "Epoch 281/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5557 - acc: 0.6667 - val_loss: 0.7346 - val_acc: 0.2500\n",
      "Epoch 282/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5545 - acc: 0.6296 - val_loss: 0.7739 - val_acc: 0.2500\n",
      "Epoch 283/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5632 - acc: 0.6667 - val_loss: 0.7614 - val_acc: 0.2500\n",
      "Epoch 284/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5547 - acc: 0.6667 - val_loss: 0.7269 - val_acc: 0.2500\n",
      "Epoch 285/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5569 - acc: 0.6667 - val_loss: 0.7378 - val_acc: 0.2500\n",
      "Epoch 286/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5522 - acc: 0.6667 - val_loss: 0.7544 - val_acc: 0.2500\n",
      "Epoch 287/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5561 - acc: 0.6667 - val_loss: 0.7481 - val_acc: 0.2500\n",
      "Epoch 288/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5541 - acc: 0.6667 - val_loss: 0.7203 - val_acc: 0.2500\n",
      "Epoch 289/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5683 - acc: 0.6296 - val_loss: 0.7163 - val_acc: 0.2500\n",
      "Epoch 290/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5564 - acc: 0.6296 - val_loss: 0.7576 - val_acc: 0.2500\n",
      "Epoch 291/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5632 - acc: 0.6667 - val_loss: 0.7585 - val_acc: 0.2500\n",
      "Epoch 292/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5673 - acc: 0.6667 - val_loss: 0.7323 - val_acc: 0.2500\n",
      "Epoch 293/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5635 - acc: 0.6667 - val_loss: 0.7211 - val_acc: 0.2500\n",
      "Epoch 294/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5590 - acc: 0.7407 - val_loss: 0.7536 - val_acc: 0.2500\n",
      "Epoch 295/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5529 - acc: 0.6667 - val_loss: 0.7811 - val_acc: 0.2500\n",
      "Epoch 296/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5652 - acc: 0.6667 - val_loss: 0.7662 - val_acc: 0.2500\n",
      "Epoch 297/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5556 - acc: 0.6667 - val_loss: 0.7335 - val_acc: 0.2500\n",
      "Epoch 298/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5586 - acc: 0.6296 - val_loss: 0.7324 - val_acc: 0.2500\n",
      "Epoch 299/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5587 - acc: 0.5926 - val_loss: 0.7696 - val_acc: 0.2500\n",
      "Epoch 300/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5555 - acc: 0.6667 - val_loss: 0.7757 - val_acc: 0.2500\n",
      "Epoch 301/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5559 - acc: 0.6667 - val_loss: 0.7408 - val_acc: 0.2500\n",
      "Epoch 302/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5526 - acc: 0.6667 - val_loss: 0.7382 - val_acc: 0.2500\n",
      "Epoch 303/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5578 - acc: 0.6667 - val_loss: 0.7414 - val_acc: 0.2500\n",
      "Epoch 304/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5540 - acc: 0.6667 - val_loss: 0.7471 - val_acc: 0.2500\n",
      "Epoch 305/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5503 - acc: 0.6667 - val_loss: 0.7604 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5538 - acc: 0.6667 - val_loss: 0.7425 - val_acc: 0.2500\n",
      "Epoch 307/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5488 - acc: 0.6667 - val_loss: 0.7450 - val_acc: 0.2500\n",
      "Epoch 308/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5531 - acc: 0.6667 - val_loss: 0.7310 - val_acc: 0.2500\n",
      "Epoch 309/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5476 - acc: 0.6667 - val_loss: 0.7469 - val_acc: 0.2500\n",
      "Epoch 310/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5485 - acc: 0.6667 - val_loss: 0.7488 - val_acc: 0.2500\n",
      "Epoch 311/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5484 - acc: 0.6667 - val_loss: 0.7298 - val_acc: 0.2500\n",
      "Epoch 312/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5522 - acc: 0.7037 - val_loss: 0.7393 - val_acc: 0.2500\n",
      "Epoch 313/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5479 - acc: 0.6667 - val_loss: 0.7639 - val_acc: 0.2500\n",
      "Epoch 314/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5520 - acc: 0.6667 - val_loss: 0.7614 - val_acc: 0.2500\n",
      "Epoch 315/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5478 - acc: 0.6667 - val_loss: 0.7424 - val_acc: 0.2500\n",
      "Epoch 316/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5505 - acc: 0.6667 - val_loss: 0.7528 - val_acc: 0.2500\n",
      "Epoch 317/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5497 - acc: 0.6667 - val_loss: 0.7666 - val_acc: 0.2500\n",
      "Epoch 318/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5530 - acc: 0.6667 - val_loss: 0.7555 - val_acc: 0.2500\n",
      "Epoch 319/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5493 - acc: 0.6667 - val_loss: 0.7430 - val_acc: 0.2500\n",
      "Epoch 320/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5506 - acc: 0.6667 - val_loss: 0.7613 - val_acc: 0.2500\n",
      "Epoch 321/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5483 - acc: 0.6667 - val_loss: 0.7535 - val_acc: 0.2500\n",
      "Epoch 322/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5482 - acc: 0.6667 - val_loss: 0.7374 - val_acc: 0.2500\n",
      "Epoch 323/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5488 - acc: 0.6667 - val_loss: 0.7527 - val_acc: 0.2500\n",
      "Epoch 324/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5548 - acc: 0.6667 - val_loss: 0.7462 - val_acc: 0.2500\n",
      "Epoch 325/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5477 - acc: 0.6667 - val_loss: 0.7256 - val_acc: 0.2500\n",
      "Epoch 326/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5573 - acc: 0.6667 - val_loss: 0.7409 - val_acc: 0.2500\n",
      "Epoch 327/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5473 - acc: 0.6667 - val_loss: 0.7535 - val_acc: 0.2500\n",
      "Epoch 328/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5521 - acc: 0.6667 - val_loss: 0.7216 - val_acc: 0.2500\n",
      "Epoch 329/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5541 - acc: 0.6667 - val_loss: 0.7300 - val_acc: 0.2500\n",
      "Epoch 330/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5488 - acc: 0.6667 - val_loss: 0.7537 - val_acc: 0.2500\n",
      "Epoch 331/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5485 - acc: 0.6667 - val_loss: 0.7469 - val_acc: 0.2500\n",
      "Epoch 332/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5461 - acc: 0.6667 - val_loss: 0.7365 - val_acc: 0.2500\n",
      "Epoch 333/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5484 - acc: 0.6667 - val_loss: 0.7395 - val_acc: 0.2500\n",
      "Epoch 334/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5476 - acc: 0.6667 - val_loss: 0.7455 - val_acc: 0.2500\n",
      "Epoch 335/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5447 - acc: 0.6667 - val_loss: 0.7598 - val_acc: 0.2500\n",
      "Epoch 336/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5505 - acc: 0.6667 - val_loss: 0.7499 - val_acc: 0.2500\n",
      "Epoch 337/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5469 - acc: 0.6667 - val_loss: 0.7435 - val_acc: 0.2500\n",
      "Epoch 338/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5488 - acc: 0.6667 - val_loss: 0.7455 - val_acc: 0.2500\n",
      "Epoch 339/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5469 - acc: 0.6667 - val_loss: 0.7374 - val_acc: 0.2500\n",
      "Epoch 340/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5497 - acc: 0.6296 - val_loss: 0.7469 - val_acc: 0.2500\n",
      "Epoch 341/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5542 - acc: 0.5926 - val_loss: 0.7525 - val_acc: 0.2500\n",
      "Epoch 342/1000\n",
      "27/27 [==============================] - 0s 648us/step - loss: 0.5478 - acc: 0.6667 - val_loss: 0.7439 - val_acc: 0.2500\n",
      "Epoch 343/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5469 - acc: 0.6667 - val_loss: 0.7459 - val_acc: 0.2500\n",
      "Epoch 344/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5453 - acc: 0.6667 - val_loss: 0.7451 - val_acc: 0.2500\n",
      "Epoch 345/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5484 - acc: 0.6296 - val_loss: 0.7364 - val_acc: 0.2500\n",
      "Epoch 346/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5475 - acc: 0.6667 - val_loss: 0.7446 - val_acc: 0.2500\n",
      "Epoch 347/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5449 - acc: 0.6667 - val_loss: 0.7438 - val_acc: 0.2500\n",
      "Epoch 348/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5449 - acc: 0.6667 - val_loss: 0.7495 - val_acc: 0.2500\n",
      "Epoch 349/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5449 - acc: 0.6667 - val_loss: 0.7292 - val_acc: 0.2500\n",
      "Epoch 350/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5512 - acc: 0.6667 - val_loss: 0.7232 - val_acc: 0.2500\n",
      "Epoch 351/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5513 - acc: 0.7037 - val_loss: 0.7600 - val_acc: 0.2500\n",
      "Epoch 352/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5540 - acc: 0.6667 - val_loss: 0.7531 - val_acc: 0.2500\n",
      "Epoch 353/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5507 - acc: 0.6667 - val_loss: 0.7227 - val_acc: 0.2500\n",
      "Epoch 354/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5582 - acc: 0.6667 - val_loss: 0.7347 - val_acc: 0.2500\n",
      "Epoch 355/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5481 - acc: 0.6667 - val_loss: 0.7595 - val_acc: 0.2500\n",
      "Epoch 356/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5539 - acc: 0.6667 - val_loss: 0.7388 - val_acc: 0.2500\n",
      "Epoch 357/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5478 - acc: 0.6667 - val_loss: 0.7491 - val_acc: 0.2500\n",
      "Epoch 358/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5516 - acc: 0.6667 - val_loss: 0.7541 - val_acc: 0.2500\n",
      "Epoch 359/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5499 - acc: 0.6667 - val_loss: 0.7309 - val_acc: 0.2500\n",
      "Epoch 360/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5491 - acc: 0.6667 - val_loss: 0.7525 - val_acc: 0.2500\n",
      "Epoch 361/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5498 - acc: 0.6667 - val_loss: 0.7489 - val_acc: 0.2500\n",
      "Epoch 362/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5465 - acc: 0.6667 - val_loss: 0.7437 - val_acc: 0.2500\n",
      "Epoch 363/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5496 - acc: 0.6667 - val_loss: 0.7618 - val_acc: 0.2500\n",
      "Epoch 364/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5501 - acc: 0.6667 - val_loss: 0.7566 - val_acc: 0.2500\n",
      "Epoch 365/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5466 - acc: 0.6667 - val_loss: 0.7377 - val_acc: 0.2500\n",
      "Epoch 366/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5491 - acc: 0.6296 - val_loss: 0.7454 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5502 - acc: 0.6667 - val_loss: 0.7606 - val_acc: 0.2500\n",
      "Epoch 368/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5539 - acc: 0.6667 - val_loss: 0.7376 - val_acc: 0.2500\n",
      "Epoch 369/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5506 - acc: 0.6667 - val_loss: 0.7226 - val_acc: 0.2500\n",
      "Epoch 370/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5587 - acc: 0.7407 - val_loss: 0.7535 - val_acc: 0.2500\n",
      "Epoch 371/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5500 - acc: 0.6667 - val_loss: 0.7538 - val_acc: 0.2500\n",
      "Epoch 372/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5523 - acc: 0.6667 - val_loss: 0.7308 - val_acc: 0.2500\n",
      "Epoch 373/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5515 - acc: 0.7407 - val_loss: 0.7397 - val_acc: 0.2500\n",
      "Epoch 374/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5490 - acc: 0.6667 - val_loss: 0.7677 - val_acc: 0.2500\n",
      "Epoch 375/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5559 - acc: 0.6667 - val_loss: 0.7390 - val_acc: 0.2500\n",
      "Epoch 376/1000\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.5525 - acc: 0.6667 - val_loss: 0.7233 - val_acc: 0.2500\n",
      "Epoch 377/1000\n",
      "27/27 [==============================] - 0s 670us/step - loss: 0.5602 - acc: 0.6667 - val_loss: 0.7375 - val_acc: 0.2500\n",
      "Epoch 378/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5516 - acc: 0.6667 - val_loss: 0.7633 - val_acc: 0.2500\n",
      "Epoch 379/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5535 - acc: 0.6667 - val_loss: 0.7543 - val_acc: 0.2500\n",
      "Epoch 380/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5540 - acc: 0.6667 - val_loss: 0.7448 - val_acc: 0.2500\n",
      "Epoch 381/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5450 - acc: 0.6667 - val_loss: 0.7425 - val_acc: 0.2500\n",
      "Epoch 382/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5511 - acc: 0.6667 - val_loss: 0.7420 - val_acc: 0.2500\n",
      "Epoch 383/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5477 - acc: 0.6667 - val_loss: 0.7456 - val_acc: 0.2500\n",
      "Epoch 384/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5526 - acc: 0.6667 - val_loss: 0.7568 - val_acc: 0.2500\n",
      "Epoch 385/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5485 - acc: 0.6667 - val_loss: 0.7390 - val_acc: 0.2500\n",
      "Epoch 386/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5497 - acc: 0.6667 - val_loss: 0.7453 - val_acc: 0.2500\n",
      "Epoch 387/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5451 - acc: 0.6667 - val_loss: 0.7604 - val_acc: 0.2500\n",
      "Epoch 388/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5532 - acc: 0.6667 - val_loss: 0.7418 - val_acc: 0.2500\n",
      "Epoch 389/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5483 - acc: 0.6667 - val_loss: 0.7351 - val_acc: 0.2500\n",
      "Epoch 390/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5502 - acc: 0.6667 - val_loss: 0.7497 - val_acc: 0.2500\n",
      "Epoch 391/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5491 - acc: 0.6667 - val_loss: 0.7651 - val_acc: 0.2500\n",
      "Epoch 392/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5528 - acc: 0.6667 - val_loss: 0.7529 - val_acc: 0.2500\n",
      "Epoch 393/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5467 - acc: 0.6667 - val_loss: 0.7486 - val_acc: 0.2500\n",
      "Epoch 394/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5477 - acc: 0.6667 - val_loss: 0.7448 - val_acc: 0.2500\n",
      "Epoch 395/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5443 - acc: 0.6667 - val_loss: 0.7500 - val_acc: 0.2500\n",
      "Epoch 396/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5438 - acc: 0.6667 - val_loss: 0.7489 - val_acc: 0.2500\n",
      "Epoch 397/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5459 - acc: 0.6667 - val_loss: 0.7588 - val_acc: 0.2500\n",
      "Epoch 398/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5455 - acc: 0.6667 - val_loss: 0.7530 - val_acc: 0.2500\n",
      "Epoch 399/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5463 - acc: 0.6667 - val_loss: 0.7487 - val_acc: 0.2500\n",
      "Epoch 400/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5477 - acc: 0.6667 - val_loss: 0.7478 - val_acc: 0.2500\n",
      "Epoch 401/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5459 - acc: 0.6667 - val_loss: 0.7601 - val_acc: 0.2500\n",
      "Epoch 402/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5476 - acc: 0.6667 - val_loss: 0.7630 - val_acc: 0.2500\n",
      "Epoch 403/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5516 - acc: 0.6667 - val_loss: 0.7357 - val_acc: 0.2500\n",
      "Epoch 404/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5479 - acc: 0.6667 - val_loss: 0.7419 - val_acc: 0.2500\n",
      "Epoch 405/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5424 - acc: 0.6667 - val_loss: 0.7478 - val_acc: 0.2500\n",
      "Epoch 406/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5476 - acc: 0.6667 - val_loss: 0.7339 - val_acc: 0.2500\n",
      "Epoch 407/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5445 - acc: 0.6667 - val_loss: 0.7475 - val_acc: 0.2500\n",
      "Epoch 408/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5488 - acc: 0.6667 - val_loss: 0.7268 - val_acc: 0.2500\n",
      "Epoch 409/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5480 - acc: 0.6667 - val_loss: 0.7245 - val_acc: 0.2500\n",
      "Epoch 410/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5472 - acc: 0.6667 - val_loss: 0.7545 - val_acc: 0.2500\n",
      "Epoch 411/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5515 - acc: 0.6667 - val_loss: 0.7496 - val_acc: 0.2500\n",
      "Epoch 412/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5478 - acc: 0.6667 - val_loss: 0.7283 - val_acc: 0.2500\n",
      "Epoch 413/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5536 - acc: 0.6667 - val_loss: 0.7524 - val_acc: 0.2500\n",
      "Epoch 414/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5559 - acc: 0.6667 - val_loss: 0.7649 - val_acc: 0.2500\n",
      "Epoch 415/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5509 - acc: 0.6667 - val_loss: 0.7333 - val_acc: 0.2500\n",
      "Epoch 416/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5619 - acc: 0.7407 - val_loss: 0.7339 - val_acc: 0.2500\n",
      "Epoch 417/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5618 - acc: 0.6667 - val_loss: 0.7682 - val_acc: 0.2500\n",
      "Epoch 418/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5574 - acc: 0.6667 - val_loss: 0.7829 - val_acc: 0.2500\n",
      "Epoch 419/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5663 - acc: 0.6667 - val_loss: 0.7618 - val_acc: 0.2500\n",
      "Epoch 420/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5589 - acc: 0.6667 - val_loss: 0.7450 - val_acc: 0.2500\n",
      "Epoch 421/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5480 - acc: 0.6667 - val_loss: 0.7473 - val_acc: 0.2500\n",
      "Epoch 422/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5526 - acc: 0.7407 - val_loss: 0.7472 - val_acc: 0.2500\n",
      "Epoch 423/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5470 - acc: 0.6667 - val_loss: 0.7686 - val_acc: 0.2500\n",
      "Epoch 424/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5562 - acc: 0.6667 - val_loss: 0.7493 - val_acc: 0.2500\n",
      "Epoch 425/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5503 - acc: 0.6667 - val_loss: 0.7429 - val_acc: 0.2500\n",
      "Epoch 426/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5488 - acc: 0.6667 - val_loss: 0.7640 - val_acc: 0.2500\n",
      "Epoch 427/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5492 - acc: 0.6667 - val_loss: 0.7515 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5475 - acc: 0.6667 - val_loss: 0.7423 - val_acc: 0.2500\n",
      "Epoch 429/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5495 - acc: 0.6667 - val_loss: 0.7608 - val_acc: 0.2500\n",
      "Epoch 430/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5474 - acc: 0.6667 - val_loss: 0.7663 - val_acc: 0.2500\n",
      "Epoch 431/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5483 - acc: 0.6667 - val_loss: 0.7396 - val_acc: 0.2500\n",
      "Epoch 432/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5526 - acc: 0.6296 - val_loss: 0.7485 - val_acc: 0.2500\n",
      "Epoch 433/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5489 - acc: 0.6667 - val_loss: 0.7617 - val_acc: 0.2500\n",
      "Epoch 434/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5458 - acc: 0.6667 - val_loss: 0.7574 - val_acc: 0.2500\n",
      "Epoch 435/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5464 - acc: 0.6667 - val_loss: 0.7562 - val_acc: 0.2500\n",
      "Epoch 436/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5487 - acc: 0.6667 - val_loss: 0.7573 - val_acc: 0.2500\n",
      "Epoch 437/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5502 - acc: 0.6667 - val_loss: 0.7703 - val_acc: 0.2500\n",
      "Epoch 438/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5516 - acc: 0.6667 - val_loss: 0.7425 - val_acc: 0.2500\n",
      "Epoch 439/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5553 - acc: 0.6296 - val_loss: 0.7419 - val_acc: 0.2500\n",
      "Epoch 440/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5559 - acc: 0.6296 - val_loss: 0.7809 - val_acc: 0.2500\n",
      "Epoch 441/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5581 - acc: 0.6667 - val_loss: 0.7905 - val_acc: 0.2500\n",
      "Epoch 442/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5613 - acc: 0.6667 - val_loss: 0.7635 - val_acc: 0.2500\n",
      "Epoch 443/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5476 - acc: 0.6667 - val_loss: 0.7308 - val_acc: 0.2500\n",
      "Epoch 444/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5631 - acc: 0.5556 - val_loss: 0.7366 - val_acc: 0.2500\n",
      "Epoch 445/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5554 - acc: 0.6667 - val_loss: 0.7740 - val_acc: 0.2500\n",
      "Epoch 446/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5533 - acc: 0.6667 - val_loss: 0.7784 - val_acc: 0.2500\n",
      "Epoch 447/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5549 - acc: 0.6667 - val_loss: 0.7561 - val_acc: 0.2500\n",
      "Epoch 448/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5529 - acc: 0.6667 - val_loss: 0.7554 - val_acc: 0.2500\n",
      "Epoch 449/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5481 - acc: 0.6667 - val_loss: 0.7700 - val_acc: 0.2500\n",
      "Epoch 450/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5489 - acc: 0.6667 - val_loss: 0.7411 - val_acc: 0.2500\n",
      "Epoch 451/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5537 - acc: 0.5926 - val_loss: 0.7389 - val_acc: 0.2500\n",
      "Epoch 452/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5525 - acc: 0.5926 - val_loss: 0.7587 - val_acc: 0.2500\n",
      "Epoch 453/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5467 - acc: 0.6667 - val_loss: 0.7535 - val_acc: 0.2500\n",
      "Epoch 454/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5463 - acc: 0.6667 - val_loss: 0.7512 - val_acc: 0.2500\n",
      "Epoch 455/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5444 - acc: 0.6667 - val_loss: 0.7586 - val_acc: 0.2500\n",
      "Epoch 456/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5444 - acc: 0.6667 - val_loss: 0.7454 - val_acc: 0.2500\n",
      "Epoch 457/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5485 - acc: 0.6667 - val_loss: 0.7673 - val_acc: 0.2500\n",
      "Epoch 458/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5502 - acc: 0.6667 - val_loss: 0.7580 - val_acc: 0.2500\n",
      "Epoch 459/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5452 - acc: 0.6667 - val_loss: 0.7344 - val_acc: 0.2500\n",
      "Epoch 460/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5568 - acc: 0.6296 - val_loss: 0.7575 - val_acc: 0.2500\n",
      "Epoch 461/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5485 - acc: 0.6667 - val_loss: 0.7707 - val_acc: 0.2500\n",
      "Epoch 462/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5497 - acc: 0.6667 - val_loss: 0.7403 - val_acc: 0.2500\n",
      "Epoch 463/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5519 - acc: 0.6667 - val_loss: 0.7440 - val_acc: 0.2500\n",
      "Epoch 464/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5489 - acc: 0.6667 - val_loss: 0.7725 - val_acc: 0.2500\n",
      "Epoch 465/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5530 - acc: 0.6667 - val_loss: 0.7590 - val_acc: 0.2500\n",
      "Epoch 466/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5461 - acc: 0.6667 - val_loss: 0.7436 - val_acc: 0.2500\n",
      "Epoch 467/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5536 - acc: 0.6667 - val_loss: 0.7513 - val_acc: 0.2500\n",
      "Epoch 468/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5448 - acc: 0.6667 - val_loss: 0.7558 - val_acc: 0.2500\n",
      "Epoch 469/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5503 - acc: 0.6667 - val_loss: 0.7526 - val_acc: 0.2500\n",
      "Epoch 470/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5462 - acc: 0.6667 - val_loss: 0.7493 - val_acc: 0.2500\n",
      "Epoch 471/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5541 - acc: 0.6667 - val_loss: 0.7573 - val_acc: 0.2500\n",
      "Epoch 472/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5511 - acc: 0.6667 - val_loss: 0.7670 - val_acc: 0.2500\n",
      "Epoch 473/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5515 - acc: 0.6667 - val_loss: 0.7504 - val_acc: 0.2500\n",
      "Epoch 474/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5511 - acc: 0.6667 - val_loss: 0.7412 - val_acc: 0.2500\n",
      "Epoch 475/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5517 - acc: 0.6667 - val_loss: 0.7638 - val_acc: 0.2500\n",
      "Epoch 476/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5497 - acc: 0.6667 - val_loss: 0.7735 - val_acc: 0.2500\n",
      "Epoch 477/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5501 - acc: 0.6667 - val_loss: 0.7551 - val_acc: 0.2500\n",
      "Epoch 478/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5484 - acc: 0.6667 - val_loss: 0.7545 - val_acc: 0.2500\n",
      "Epoch 479/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5463 - acc: 0.6667 - val_loss: 0.7599 - val_acc: 0.2500\n",
      "Epoch 480/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5446 - acc: 0.6667 - val_loss: 0.7516 - val_acc: 0.2500\n",
      "Epoch 481/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5440 - acc: 0.6667 - val_loss: 0.7506 - val_acc: 0.2500\n",
      "Epoch 482/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5488 - acc: 0.6667 - val_loss: 0.7497 - val_acc: 0.2500\n",
      "Epoch 483/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5448 - acc: 0.6667 - val_loss: 0.7465 - val_acc: 0.2500\n",
      "Epoch 484/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5447 - acc: 0.6667 - val_loss: 0.7546 - val_acc: 0.2500\n",
      "Epoch 485/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5445 - acc: 0.6667 - val_loss: 0.7433 - val_acc: 0.2500\n",
      "Epoch 486/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5456 - acc: 0.6667 - val_loss: 0.7537 - val_acc: 0.2500\n",
      "Epoch 487/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5438 - acc: 0.6667 - val_loss: 0.7463 - val_acc: 0.2500\n",
      "Epoch 488/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5438 - acc: 0.6667 - val_loss: 0.7483 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5427 - acc: 0.6667 - val_loss: 0.7435 - val_acc: 0.2500\n",
      "Epoch 490/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5441 - acc: 0.6667 - val_loss: 0.7518 - val_acc: 0.2500\n",
      "Epoch 491/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5434 - acc: 0.6667 - val_loss: 0.7423 - val_acc: 0.2500\n",
      "Epoch 492/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5462 - acc: 0.6667 - val_loss: 0.7560 - val_acc: 0.2500\n",
      "Epoch 493/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5456 - acc: 0.6667 - val_loss: 0.7563 - val_acc: 0.2500\n",
      "Epoch 494/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5446 - acc: 0.6667 - val_loss: 0.7463 - val_acc: 0.2500\n",
      "Epoch 495/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5452 - acc: 0.6667 - val_loss: 0.7496 - val_acc: 0.2500\n",
      "Epoch 496/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5456 - acc: 0.6667 - val_loss: 0.7440 - val_acc: 0.2500\n",
      "Epoch 497/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5515 - acc: 0.6667 - val_loss: 0.7403 - val_acc: 0.2500\n",
      "Epoch 498/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5510 - acc: 0.6667 - val_loss: 0.7527 - val_acc: 0.2500\n",
      "Epoch 499/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5475 - acc: 0.6667 - val_loss: 0.7633 - val_acc: 0.2500\n",
      "Epoch 500/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5511 - acc: 0.6667 - val_loss: 0.7430 - val_acc: 0.2500\n",
      "Epoch 501/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5489 - acc: 0.6667 - val_loss: 0.7515 - val_acc: 0.2500\n",
      "Epoch 502/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5487 - acc: 0.6667 - val_loss: 0.7563 - val_acc: 0.2500\n",
      "Epoch 503/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5470 - acc: 0.6667 - val_loss: 0.7320 - val_acc: 0.2500\n",
      "Epoch 504/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5496 - acc: 0.6667 - val_loss: 0.7363 - val_acc: 0.2500\n",
      "Epoch 505/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5449 - acc: 0.6667 - val_loss: 0.7487 - val_acc: 0.2500\n",
      "Epoch 506/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5447 - acc: 0.6667 - val_loss: 0.7444 - val_acc: 0.2500\n",
      "Epoch 507/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5431 - acc: 0.6667 - val_loss: 0.7550 - val_acc: 0.2500\n",
      "Epoch 508/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5451 - acc: 0.6667 - val_loss: 0.7469 - val_acc: 0.2500\n",
      "Epoch 509/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5457 - acc: 0.6667 - val_loss: 0.7609 - val_acc: 0.2500\n",
      "Epoch 510/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5483 - acc: 0.6667 - val_loss: 0.7465 - val_acc: 0.2500\n",
      "Epoch 511/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5478 - acc: 0.6667 - val_loss: 0.7437 - val_acc: 0.2500\n",
      "Epoch 512/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5466 - acc: 0.6667 - val_loss: 0.7605 - val_acc: 0.2500\n",
      "Epoch 513/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5454 - acc: 0.6667 - val_loss: 0.7323 - val_acc: 0.2500\n",
      "Epoch 514/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5548 - acc: 0.6667 - val_loss: 0.7375 - val_acc: 0.2500\n",
      "Epoch 515/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5492 - acc: 0.6667 - val_loss: 0.7728 - val_acc: 0.2500\n",
      "Epoch 516/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5545 - acc: 0.6667 - val_loss: 0.7633 - val_acc: 0.2500\n",
      "Epoch 517/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5487 - acc: 0.6667 - val_loss: 0.7414 - val_acc: 0.2500\n",
      "Epoch 518/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5488 - acc: 0.6667 - val_loss: 0.7570 - val_acc: 0.2500\n",
      "Epoch 519/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5440 - acc: 0.6667 - val_loss: 0.7503 - val_acc: 0.2500\n",
      "Epoch 520/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5448 - acc: 0.6667 - val_loss: 0.7613 - val_acc: 0.2500\n",
      "Epoch 521/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5464 - acc: 0.6667 - val_loss: 0.7520 - val_acc: 0.2500\n",
      "Epoch 522/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5439 - acc: 0.6667 - val_loss: 0.7478 - val_acc: 0.2500\n",
      "Epoch 523/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5464 - acc: 0.6667 - val_loss: 0.7582 - val_acc: 0.2500\n",
      "Epoch 524/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5481 - acc: 0.6667 - val_loss: 0.7508 - val_acc: 0.2500\n",
      "Epoch 525/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5460 - acc: 0.6667 - val_loss: 0.7410 - val_acc: 0.2500\n",
      "Epoch 526/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5479 - acc: 0.6667 - val_loss: 0.7459 - val_acc: 0.2500\n",
      "Epoch 527/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5461 - acc: 0.6667 - val_loss: 0.7563 - val_acc: 0.2500\n",
      "Epoch 528/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5482 - acc: 0.6667 - val_loss: 0.7474 - val_acc: 0.2500\n",
      "Epoch 529/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5512 - acc: 0.6667 - val_loss: 0.7422 - val_acc: 0.2500\n",
      "Epoch 530/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5492 - acc: 0.6667 - val_loss: 0.7598 - val_acc: 0.2500\n",
      "Epoch 531/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5465 - acc: 0.6667 - val_loss: 0.7471 - val_acc: 0.2500\n",
      "Epoch 532/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5520 - acc: 0.6667 - val_loss: 0.7412 - val_acc: 0.2500\n",
      "Epoch 533/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5522 - acc: 0.6667 - val_loss: 0.7563 - val_acc: 0.2500\n",
      "Epoch 534/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5468 - acc: 0.6667 - val_loss: 0.7594 - val_acc: 0.2500\n",
      "Epoch 535/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5479 - acc: 0.6667 - val_loss: 0.7358 - val_acc: 0.2500\n",
      "Epoch 536/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5471 - acc: 0.6667 - val_loss: 0.7412 - val_acc: 0.2500\n",
      "Epoch 537/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5451 - acc: 0.6667 - val_loss: 0.7442 - val_acc: 0.2500\n",
      "Epoch 538/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5456 - acc: 0.6667 - val_loss: 0.7515 - val_acc: 0.2500\n",
      "Epoch 539/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5451 - acc: 0.6667 - val_loss: 0.7353 - val_acc: 0.2500\n",
      "Epoch 540/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5490 - acc: 0.6667 - val_loss: 0.7369 - val_acc: 0.2500\n",
      "Epoch 541/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5456 - acc: 0.6667 - val_loss: 0.7620 - val_acc: 0.2500\n",
      "Epoch 542/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5501 - acc: 0.6667 - val_loss: 0.7510 - val_acc: 0.2500\n",
      "Epoch 543/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5471 - acc: 0.6667 - val_loss: 0.7344 - val_acc: 0.2500\n",
      "Epoch 544/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5511 - acc: 0.6667 - val_loss: 0.7627 - val_acc: 0.2500\n",
      "Epoch 545/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5508 - acc: 0.6667 - val_loss: 0.7636 - val_acc: 0.2500\n",
      "Epoch 546/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5492 - acc: 0.6667 - val_loss: 0.7347 - val_acc: 0.2500\n",
      "Epoch 547/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5506 - acc: 0.6667 - val_loss: 0.7488 - val_acc: 0.2500\n",
      "Epoch 548/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5471 - acc: 0.6667 - val_loss: 0.7719 - val_acc: 0.2500\n",
      "Epoch 549/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5544 - acc: 0.6667 - val_loss: 0.7524 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5509 - acc: 0.6667 - val_loss: 0.7397 - val_acc: 0.2500\n",
      "Epoch 551/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5530 - acc: 0.6667 - val_loss: 0.7653 - val_acc: 0.2500\n",
      "Epoch 552/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5497 - acc: 0.6667 - val_loss: 0.7735 - val_acc: 0.2500\n",
      "Epoch 553/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5524 - acc: 0.6667 - val_loss: 0.7490 - val_acc: 0.2500\n",
      "Epoch 554/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5494 - acc: 0.6667 - val_loss: 0.7479 - val_acc: 0.2500\n",
      "Epoch 555/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5472 - acc: 0.6667 - val_loss: 0.7603 - val_acc: 0.2500\n",
      "Epoch 556/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5461 - acc: 0.6667 - val_loss: 0.7503 - val_acc: 0.2500\n",
      "Epoch 557/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5470 - acc: 0.6667 - val_loss: 0.7494 - val_acc: 0.2500\n",
      "Epoch 558/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5441 - acc: 0.6667 - val_loss: 0.7475 - val_acc: 0.2500\n",
      "Epoch 559/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5471 - acc: 0.6667 - val_loss: 0.7421 - val_acc: 0.2500\n",
      "Epoch 560/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5442 - acc: 0.6667 - val_loss: 0.7534 - val_acc: 0.2500\n",
      "Epoch 561/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5459 - acc: 0.6667 - val_loss: 0.7395 - val_acc: 0.2500\n",
      "Epoch 562/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5447 - acc: 0.6667 - val_loss: 0.7479 - val_acc: 0.2500\n",
      "Epoch 563/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5461 - acc: 0.6667 - val_loss: 0.7497 - val_acc: 0.2500\n",
      "Epoch 564/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5455 - acc: 0.6667 - val_loss: 0.7396 - val_acc: 0.2500\n",
      "Epoch 565/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5463 - acc: 0.6667 - val_loss: 0.7573 - val_acc: 0.2500\n",
      "Epoch 566/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5485 - acc: 0.6667 - val_loss: 0.7441 - val_acc: 0.2500\n",
      "Epoch 567/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5441 - acc: 0.6667 - val_loss: 0.7391 - val_acc: 0.2500\n",
      "Epoch 568/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5467 - acc: 0.6667 - val_loss: 0.7464 - val_acc: 0.2500\n",
      "Epoch 569/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5445 - acc: 0.6667 - val_loss: 0.7253 - val_acc: 0.2500\n",
      "Epoch 570/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5531 - acc: 0.6667 - val_loss: 0.7331 - val_acc: 0.2500\n",
      "Epoch 571/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5502 - acc: 0.6667 - val_loss: 0.7673 - val_acc: 0.2500\n",
      "Epoch 572/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5545 - acc: 0.6667 - val_loss: 0.7659 - val_acc: 0.2500\n",
      "Epoch 573/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5543 - acc: 0.6667 - val_loss: 0.7487 - val_acc: 0.2500\n",
      "Epoch 574/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5512 - acc: 0.6667 - val_loss: 0.7444 - val_acc: 0.2500\n",
      "Epoch 575/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5479 - acc: 0.6667 - val_loss: 0.7484 - val_acc: 0.2500\n",
      "Epoch 576/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5518 - acc: 0.6667 - val_loss: 0.7490 - val_acc: 0.2500\n",
      "Epoch 577/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5456 - acc: 0.6667 - val_loss: 0.7524 - val_acc: 0.2500\n",
      "Epoch 578/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5516 - acc: 0.6667 - val_loss: 0.7620 - val_acc: 0.2500\n",
      "Epoch 579/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5526 - acc: 0.6667 - val_loss: 0.7460 - val_acc: 0.2500\n",
      "Epoch 580/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5510 - acc: 0.6667 - val_loss: 0.7302 - val_acc: 0.2500\n",
      "Epoch 581/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5556 - acc: 0.6667 - val_loss: 0.7387 - val_acc: 0.2500\n",
      "Epoch 582/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5548 - acc: 0.6667 - val_loss: 0.7623 - val_acc: 0.2500\n",
      "Epoch 583/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5552 - acc: 0.6667 - val_loss: 0.7621 - val_acc: 0.2500\n",
      "Epoch 584/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5499 - acc: 0.6667 - val_loss: 0.7436 - val_acc: 0.2500\n",
      "Epoch 585/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5472 - acc: 0.6667 - val_loss: 0.7618 - val_acc: 0.2500\n",
      "Epoch 586/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5504 - acc: 0.6667 - val_loss: 0.7590 - val_acc: 0.2500\n",
      "Epoch 587/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5508 - acc: 0.6667 - val_loss: 0.7458 - val_acc: 0.2500\n",
      "Epoch 588/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5461 - acc: 0.6667 - val_loss: 0.7449 - val_acc: 0.2500\n",
      "Epoch 589/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5439 - acc: 0.6667 - val_loss: 0.7552 - val_acc: 0.2500\n",
      "Epoch 590/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5488 - acc: 0.6667 - val_loss: 0.7444 - val_acc: 0.2500\n",
      "Epoch 591/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5459 - acc: 0.6667 - val_loss: 0.7453 - val_acc: 0.2500\n",
      "Epoch 592/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5454 - acc: 0.6667 - val_loss: 0.7476 - val_acc: 0.2500\n",
      "Epoch 593/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5426 - acc: 0.6667 - val_loss: 0.7392 - val_acc: 0.2500\n",
      "Epoch 594/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5450 - acc: 0.6667 - val_loss: 0.7588 - val_acc: 0.2500\n",
      "Epoch 595/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5480 - acc: 0.6667 - val_loss: 0.7451 - val_acc: 0.2500\n",
      "Epoch 596/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5438 - acc: 0.6667 - val_loss: 0.7519 - val_acc: 0.2500\n",
      "Epoch 597/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5456 - acc: 0.6667 - val_loss: 0.7456 - val_acc: 0.2500\n",
      "Epoch 598/1000\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5429 - acc: 0.6667 - val_loss: 0.7401 - val_acc: 0.2500\n",
      "Epoch 599/1000\n",
      "27/27 [==============================] - 0s 648us/step - loss: 0.5449 - acc: 0.6667 - val_loss: 0.7534 - val_acc: 0.2500\n",
      "Epoch 600/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5467 - acc: 0.6667 - val_loss: 0.7424 - val_acc: 0.2500\n",
      "Epoch 601/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5444 - acc: 0.6667 - val_loss: 0.7397 - val_acc: 0.2500\n",
      "Epoch 602/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5454 - acc: 0.6667 - val_loss: 0.7513 - val_acc: 0.2500\n",
      "Epoch 603/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5451 - acc: 0.6667 - val_loss: 0.7354 - val_acc: 0.2500\n",
      "Epoch 604/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5486 - acc: 0.6667 - val_loss: 0.7547 - val_acc: 0.2500\n",
      "Epoch 605/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5465 - acc: 0.6667 - val_loss: 0.7557 - val_acc: 0.2500\n",
      "Epoch 606/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5450 - acc: 0.6667 - val_loss: 0.7391 - val_acc: 0.2500\n",
      "Epoch 607/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5508 - acc: 0.6667 - val_loss: 0.7447 - val_acc: 0.2500\n",
      "Epoch 608/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5464 - acc: 0.6667 - val_loss: 0.7567 - val_acc: 0.2500\n",
      "Epoch 609/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5495 - acc: 0.6667 - val_loss: 0.7477 - val_acc: 0.2500\n",
      "Epoch 610/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5481 - acc: 0.6667 - val_loss: 0.7477 - val_acc: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5469 - acc: 0.6667 - val_loss: 0.7682 - val_acc: 0.2500\n",
      "Epoch 612/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5551 - acc: 0.6667 - val_loss: 0.7640 - val_acc: 0.2500\n",
      "Epoch 613/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5507 - acc: 0.6667 - val_loss: 0.7281 - val_acc: 0.2500\n",
      "Epoch 614/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5545 - acc: 0.6667 - val_loss: 0.7245 - val_acc: 0.2500\n",
      "Epoch 615/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5570 - acc: 0.6667 - val_loss: 0.7418 - val_acc: 0.2500\n",
      "Epoch 616/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5559 - acc: 0.6667 - val_loss: 0.7561 - val_acc: 0.2500\n",
      "Epoch 617/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5470 - acc: 0.6667 - val_loss: 0.7529 - val_acc: 0.2500\n",
      "Epoch 618/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5529 - acc: 0.6667 - val_loss: 0.7394 - val_acc: 0.2500\n",
      "Epoch 619/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5524 - acc: 0.7407 - val_loss: 0.7524 - val_acc: 0.2500\n",
      "Epoch 620/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5493 - acc: 0.6667 - val_loss: 0.7543 - val_acc: 0.2500\n",
      "Epoch 621/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5530 - acc: 0.6667 - val_loss: 0.7487 - val_acc: 0.2500\n",
      "Epoch 622/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5443 - acc: 0.6667 - val_loss: 0.7438 - val_acc: 0.2500\n",
      "Epoch 623/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5471 - acc: 0.6667 - val_loss: 0.7500 - val_acc: 0.2500\n",
      "Epoch 624/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5453 - acc: 0.6667 - val_loss: 0.7548 - val_acc: 0.2500\n",
      "Epoch 625/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5452 - acc: 0.6667 - val_loss: 0.7418 - val_acc: 0.2500\n",
      "Epoch 626/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5476 - acc: 0.6667 - val_loss: 0.7557 - val_acc: 0.2500\n",
      "Epoch 627/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5459 - acc: 0.6667 - val_loss: 0.7523 - val_acc: 0.2500\n",
      "Epoch 628/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5478 - acc: 0.6667 - val_loss: 0.7438 - val_acc: 0.2500\n",
      "Epoch 629/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5458 - acc: 0.6667 - val_loss: 0.7415 - val_acc: 0.2500\n",
      "Epoch 630/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5467 - acc: 0.6667 - val_loss: 0.7652 - val_acc: 0.2500\n",
      "Epoch 631/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5531 - acc: 0.6667 - val_loss: 0.7584 - val_acc: 0.2500\n",
      "Epoch 632/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5505 - acc: 0.6667 - val_loss: 0.7490 - val_acc: 0.2500\n",
      "Epoch 633/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5442 - acc: 0.6667 - val_loss: 0.7293 - val_acc: 0.2500\n",
      "Epoch 634/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5517 - acc: 0.6667 - val_loss: 0.7299 - val_acc: 0.2500\n",
      "Epoch 635/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5510 - acc: 0.6667 - val_loss: 0.7501 - val_acc: 0.2500\n",
      "Epoch 636/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5511 - acc: 0.6667 - val_loss: 0.7711 - val_acc: 0.2500\n",
      "Epoch 637/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5565 - acc: 0.6667 - val_loss: 0.7615 - val_acc: 0.2500\n",
      "Epoch 638/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5502 - acc: 0.6667 - val_loss: 0.7314 - val_acc: 0.2500\n",
      "Epoch 639/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5513 - acc: 0.6296 - val_loss: 0.7357 - val_acc: 0.2500\n",
      "Epoch 640/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5484 - acc: 0.6296 - val_loss: 0.7620 - val_acc: 0.2500\n",
      "Epoch 641/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5498 - acc: 0.6667 - val_loss: 0.7514 - val_acc: 0.2500\n",
      "Epoch 642/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5465 - acc: 0.6667 - val_loss: 0.7344 - val_acc: 0.2500\n",
      "Epoch 643/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5561 - acc: 0.6667 - val_loss: 0.7436 - val_acc: 0.2500\n",
      "Epoch 644/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5477 - acc: 0.6667 - val_loss: 0.7646 - val_acc: 0.2500\n",
      "Epoch 645/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5471 - acc: 0.6667 - val_loss: 0.7426 - val_acc: 0.2500\n",
      "Epoch 646/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5503 - acc: 0.6667 - val_loss: 0.7443 - val_acc: 0.2500\n",
      "Epoch 647/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5484 - acc: 0.6667 - val_loss: 0.7680 - val_acc: 0.2500\n",
      "Epoch 648/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5477 - acc: 0.6667 - val_loss: 0.7566 - val_acc: 0.2500\n",
      "Epoch 649/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5440 - acc: 0.6667 - val_loss: 0.7493 - val_acc: 0.2500\n",
      "Epoch 650/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5451 - acc: 0.6667 - val_loss: 0.7666 - val_acc: 0.2500\n",
      "Epoch 651/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5487 - acc: 0.6667 - val_loss: 0.7581 - val_acc: 0.2500\n",
      "Epoch 652/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5451 - acc: 0.6667 - val_loss: 0.7506 - val_acc: 0.2500\n",
      "Epoch 653/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5454 - acc: 0.6667 - val_loss: 0.7620 - val_acc: 0.2500\n",
      "Epoch 654/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5450 - acc: 0.6667 - val_loss: 0.7519 - val_acc: 0.2500\n",
      "Epoch 655/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5455 - acc: 0.6667 - val_loss: 0.7574 - val_acc: 0.2500\n",
      "Epoch 656/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5430 - acc: 0.6667 - val_loss: 0.7577 - val_acc: 0.2500\n",
      "Epoch 657/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5448 - acc: 0.6667 - val_loss: 0.7511 - val_acc: 0.2500\n",
      "Epoch 658/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5445 - acc: 0.6667 - val_loss: 0.7616 - val_acc: 0.2500\n",
      "Epoch 659/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5449 - acc: 0.6667 - val_loss: 0.7427 - val_acc: 0.2500\n",
      "Epoch 660/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5470 - acc: 0.6667 - val_loss: 0.7512 - val_acc: 0.2500\n",
      "Epoch 661/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5440 - acc: 0.6667 - val_loss: 0.7601 - val_acc: 0.2500\n",
      "Epoch 662/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5470 - acc: 0.6667 - val_loss: 0.7477 - val_acc: 0.2500\n",
      "Epoch 663/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5449 - acc: 0.6667 - val_loss: 0.7468 - val_acc: 0.2500\n",
      "Epoch 664/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5489 - acc: 0.6667 - val_loss: 0.7630 - val_acc: 0.2500\n",
      "Epoch 665/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5490 - acc: 0.6667 - val_loss: 0.7507 - val_acc: 0.2500\n",
      "Epoch 666/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5478 - acc: 0.6667 - val_loss: 0.7536 - val_acc: 0.2500\n",
      "Epoch 667/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5509 - acc: 0.6667 - val_loss: 0.7512 - val_acc: 0.2500\n",
      "Epoch 668/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5480 - acc: 0.6667 - val_loss: 0.7465 - val_acc: 0.2500\n",
      "Epoch 669/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5436 - acc: 0.6667 - val_loss: 0.7497 - val_acc: 0.2500\n",
      "Epoch 670/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5463 - acc: 0.6667 - val_loss: 0.7456 - val_acc: 0.5000\n",
      "Epoch 671/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5469 - acc: 0.7037 - val_loss: 0.7445 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5449 - acc: 0.7037 - val_loss: 0.7429 - val_acc: 0.5000\n",
      "Epoch 673/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5443 - acc: 0.7037 - val_loss: 0.7555 - val_acc: 0.2500\n",
      "Epoch 674/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5462 - acc: 0.6667 - val_loss: 0.7494 - val_acc: 0.2500\n",
      "Epoch 675/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5437 - acc: 0.6667 - val_loss: 0.7572 - val_acc: 0.2500\n",
      "Epoch 676/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5480 - acc: 0.6667 - val_loss: 0.7470 - val_acc: 0.2500\n",
      "Epoch 677/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5448 - acc: 0.6667 - val_loss: 0.7491 - val_acc: 0.2500\n",
      "Epoch 678/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5467 - acc: 0.6667 - val_loss: 0.7567 - val_acc: 0.2500\n",
      "Epoch 679/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5476 - acc: 0.6667 - val_loss: 0.7416 - val_acc: 0.2500\n",
      "Epoch 680/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5480 - acc: 0.6667 - val_loss: 0.7394 - val_acc: 0.2500\n",
      "Epoch 681/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5485 - acc: 0.6667 - val_loss: 0.7526 - val_acc: 0.2500\n",
      "Epoch 682/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5461 - acc: 0.6667 - val_loss: 0.7549 - val_acc: 0.5000\n",
      "Epoch 683/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5456 - acc: 0.7037 - val_loss: 0.7468 - val_acc: 0.5000\n",
      "Epoch 684/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5450 - acc: 0.7037 - val_loss: 0.7504 - val_acc: 0.5000\n",
      "Epoch 685/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5426 - acc: 0.7037 - val_loss: 0.7547 - val_acc: 0.5000\n",
      "Epoch 686/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5442 - acc: 0.7037 - val_loss: 0.7439 - val_acc: 0.5000\n",
      "Epoch 687/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5464 - acc: 0.7037 - val_loss: 0.7403 - val_acc: 0.2500\n",
      "Epoch 688/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5468 - acc: 0.6667 - val_loss: 0.7537 - val_acc: 0.2500\n",
      "Epoch 689/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5438 - acc: 0.6667 - val_loss: 0.7434 - val_acc: 0.2500\n",
      "Epoch 690/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5449 - acc: 0.6667 - val_loss: 0.7515 - val_acc: 0.2500\n",
      "Epoch 691/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5479 - acc: 0.6667 - val_loss: 0.7490 - val_acc: 0.2500\n",
      "Epoch 692/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5458 - acc: 0.6667 - val_loss: 0.7428 - val_acc: 0.5000\n",
      "Epoch 693/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5440 - acc: 0.7037 - val_loss: 0.7536 - val_acc: 0.2500\n",
      "Epoch 694/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5442 - acc: 0.6667 - val_loss: 0.7444 - val_acc: 0.2500\n",
      "Epoch 695/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5444 - acc: 0.6667 - val_loss: 0.7492 - val_acc: 0.2500\n",
      "Epoch 696/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5438 - acc: 0.6667 - val_loss: 0.7493 - val_acc: 0.2500\n",
      "Epoch 697/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5438 - acc: 0.6667 - val_loss: 0.7356 - val_acc: 0.2500\n",
      "Epoch 698/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5505 - acc: 0.6667 - val_loss: 0.7355 - val_acc: 0.2500\n",
      "Epoch 699/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5477 - acc: 0.6667 - val_loss: 0.7407 - val_acc: 0.2500\n",
      "Epoch 700/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5436 - acc: 0.6667 - val_loss: 0.7324 - val_acc: 0.5000\n",
      "Epoch 701/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5453 - acc: 0.7037 - val_loss: 0.7425 - val_acc: 0.5000\n",
      "Epoch 702/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5460 - acc: 0.7037 - val_loss: 0.7472 - val_acc: 0.5000\n",
      "Epoch 703/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5454 - acc: 0.7037 - val_loss: 0.7430 - val_acc: 0.5000\n",
      "Epoch 704/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5448 - acc: 0.7037 - val_loss: 0.7485 - val_acc: 0.5000\n",
      "Epoch 705/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5422 - acc: 0.7037 - val_loss: 0.7433 - val_acc: 0.5000\n",
      "Epoch 706/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5445 - acc: 0.7037 - val_loss: 0.7493 - val_acc: 0.2500\n",
      "Epoch 707/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5425 - acc: 0.6667 - val_loss: 0.7358 - val_acc: 0.5000\n",
      "Epoch 708/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5487 - acc: 0.7037 - val_loss: 0.7343 - val_acc: 0.5000\n",
      "Epoch 709/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5449 - acc: 0.7037 - val_loss: 0.7573 - val_acc: 0.5000\n",
      "Epoch 710/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5483 - acc: 0.7037 - val_loss: 0.7422 - val_acc: 0.5000\n",
      "Epoch 711/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5459 - acc: 0.7037 - val_loss: 0.7378 - val_acc: 0.5000\n",
      "Epoch 712/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5456 - acc: 0.7037 - val_loss: 0.7394 - val_acc: 0.5000\n",
      "Epoch 713/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5430 - acc: 0.7037 - val_loss: 0.7419 - val_acc: 0.5000\n",
      "Epoch 714/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5440 - acc: 0.7037 - val_loss: 0.7485 - val_acc: 0.5000\n",
      "Epoch 715/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5430 - acc: 0.7037 - val_loss: 0.7316 - val_acc: 0.5000\n",
      "Epoch 716/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5477 - acc: 0.7037 - val_loss: 0.7421 - val_acc: 0.5000\n",
      "Epoch 717/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5503 - acc: 0.7037 - val_loss: 0.7557 - val_acc: 0.5000\n",
      "Epoch 718/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5480 - acc: 0.7037 - val_loss: 0.7522 - val_acc: 0.5000\n",
      "Epoch 719/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5483 - acc: 0.7037 - val_loss: 0.7420 - val_acc: 0.5000\n",
      "Epoch 720/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5509 - acc: 0.7037 - val_loss: 0.7493 - val_acc: 0.5000\n",
      "Epoch 721/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5438 - acc: 0.7037 - val_loss: 0.7519 - val_acc: 0.5000\n",
      "Epoch 722/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5461 - acc: 0.7037 - val_loss: 0.7464 - val_acc: 0.2500\n",
      "Epoch 723/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5435 - acc: 0.6667 - val_loss: 0.7472 - val_acc: 0.2500\n",
      "Epoch 724/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5425 - acc: 0.6667 - val_loss: 0.7439 - val_acc: 0.2500\n",
      "Epoch 725/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5453 - acc: 0.6667 - val_loss: 0.7462 - val_acc: 0.2500\n",
      "Epoch 726/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5428 - acc: 0.6667 - val_loss: 0.7451 - val_acc: 0.2500\n",
      "Epoch 727/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5429 - acc: 0.6667 - val_loss: 0.7485 - val_acc: 0.2500\n",
      "Epoch 728/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5448 - acc: 0.6667 - val_loss: 0.7487 - val_acc: 0.5000\n",
      "Epoch 729/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5442 - acc: 0.7037 - val_loss: 0.7402 - val_acc: 0.5000\n",
      "Epoch 730/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5439 - acc: 0.7037 - val_loss: 0.7461 - val_acc: 0.5000\n",
      "Epoch 731/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5442 - acc: 0.7037 - val_loss: 0.7416 - val_acc: 0.5000\n",
      "Epoch 732/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5451 - acc: 0.7037 - val_loss: 0.7403 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 733/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5421 - acc: 0.7037 - val_loss: 0.7465 - val_acc: 0.5000\n",
      "Epoch 734/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5439 - acc: 0.7037 - val_loss: 0.7308 - val_acc: 0.5000\n",
      "Epoch 735/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5453 - acc: 0.7037 - val_loss: 0.7416 - val_acc: 0.5000\n",
      "Epoch 736/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5472 - acc: 0.7037 - val_loss: 0.7491 - val_acc: 0.5000\n",
      "Epoch 737/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5489 - acc: 0.7037 - val_loss: 0.7336 - val_acc: 0.5000\n",
      "Epoch 738/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5515 - acc: 0.7037 - val_loss: 0.7282 - val_acc: 0.5000\n",
      "Epoch 739/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5456 - acc: 0.7037 - val_loss: 0.7482 - val_acc: 0.5000\n",
      "Epoch 740/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5521 - acc: 0.7037 - val_loss: 0.7384 - val_acc: 0.5000\n",
      "Epoch 741/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5473 - acc: 0.7037 - val_loss: 0.7411 - val_acc: 0.5000\n",
      "Epoch 742/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5487 - acc: 0.7037 - val_loss: 0.7500 - val_acc: 0.5000\n",
      "Epoch 743/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5482 - acc: 0.7037 - val_loss: 0.7396 - val_acc: 0.5000\n",
      "Epoch 744/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5457 - acc: 0.7037 - val_loss: 0.7280 - val_acc: 0.5000\n",
      "Epoch 745/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5500 - acc: 0.7037 - val_loss: 0.7350 - val_acc: 0.5000\n",
      "Epoch 746/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5456 - acc: 0.7037 - val_loss: 0.7505 - val_acc: 0.2500\n",
      "Epoch 747/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5463 - acc: 0.6667 - val_loss: 0.7381 - val_acc: 0.5000\n",
      "Epoch 748/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5481 - acc: 0.7407 - val_loss: 0.7269 - val_acc: 0.5000\n",
      "Epoch 749/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5500 - acc: 0.7037 - val_loss: 0.7425 - val_acc: 0.5000\n",
      "Epoch 750/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5462 - acc: 0.7037 - val_loss: 0.7281 - val_acc: 0.5000\n",
      "Epoch 751/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5480 - acc: 0.7037 - val_loss: 0.7386 - val_acc: 0.5000\n",
      "Epoch 752/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5471 - acc: 0.7037 - val_loss: 0.7512 - val_acc: 0.5000\n",
      "Epoch 753/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5468 - acc: 0.7037 - val_loss: 0.7314 - val_acc: 0.5000\n",
      "Epoch 754/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5482 - acc: 0.7037 - val_loss: 0.7367 - val_acc: 0.5000\n",
      "Epoch 755/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5455 - acc: 0.7037 - val_loss: 0.7559 - val_acc: 0.5000\n",
      "Epoch 756/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5448 - acc: 0.7037 - val_loss: 0.7512 - val_acc: 0.5000\n",
      "Epoch 757/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5462 - acc: 0.7037 - val_loss: 0.7404 - val_acc: 0.5000\n",
      "Epoch 758/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5461 - acc: 0.7037 - val_loss: 0.7529 - val_acc: 0.5000\n",
      "Epoch 759/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5428 - acc: 0.7037 - val_loss: 0.7402 - val_acc: 0.5000\n",
      "Epoch 760/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5428 - acc: 0.7037 - val_loss: 0.7375 - val_acc: 0.5000\n",
      "Epoch 761/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5429 - acc: 0.7037 - val_loss: 0.7371 - val_acc: 0.5000\n",
      "Epoch 762/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5417 - acc: 0.7037 - val_loss: 0.7306 - val_acc: 0.5000\n",
      "Epoch 763/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5408 - acc: 0.7407 - val_loss: 0.7185 - val_acc: 0.5000\n",
      "Epoch 764/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5394 - acc: 0.7407 - val_loss: 0.7281 - val_acc: 0.5000\n",
      "Epoch 765/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5420 - acc: 0.7407 - val_loss: 0.7335 - val_acc: 0.5000\n",
      "Epoch 766/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5415 - acc: 0.7407 - val_loss: 0.7228 - val_acc: 0.5000\n",
      "Epoch 767/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5413 - acc: 0.7407 - val_loss: 0.7305 - val_acc: 0.5000\n",
      "Epoch 768/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5451 - acc: 0.7407 - val_loss: 0.7245 - val_acc: 0.5000\n",
      "Epoch 769/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5435 - acc: 0.7407 - val_loss: 0.6887 - val_acc: 0.5000\n",
      "Epoch 770/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5449 - acc: 0.7407 - val_loss: 0.6922 - val_acc: 0.5000\n",
      "Epoch 771/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5462 - acc: 0.7407 - val_loss: 0.7116 - val_acc: 0.5000\n",
      "Epoch 772/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5456 - acc: 0.7407 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 773/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5385 - acc: 0.7407 - val_loss: 0.6771 - val_acc: 0.5000\n",
      "Epoch 774/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5403 - acc: 0.7407 - val_loss: 0.6911 - val_acc: 0.5000\n",
      "Epoch 775/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5417 - acc: 0.7407 - val_loss: 0.7060 - val_acc: 0.5000\n",
      "Epoch 776/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5417 - acc: 0.7407 - val_loss: 0.7016 - val_acc: 0.5000\n",
      "Epoch 777/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5370 - acc: 0.7407 - val_loss: 0.6868 - val_acc: 0.5000\n",
      "Epoch 778/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5362 - acc: 0.7407 - val_loss: 0.6791 - val_acc: 0.5000\n",
      "Epoch 779/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5387 - acc: 0.7037 - val_loss: 0.6676 - val_acc: 0.5000\n",
      "Epoch 780/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5349 - acc: 0.6667 - val_loss: 0.6626 - val_acc: 0.5000\n",
      "Epoch 781/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5310 - acc: 0.7407 - val_loss: 0.6706 - val_acc: 0.5000\n",
      "Epoch 782/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5339 - acc: 0.7407 - val_loss: 0.6717 - val_acc: 0.5000\n",
      "Epoch 783/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5342 - acc: 0.7407 - val_loss: 0.6458 - val_acc: 0.5000\n",
      "Epoch 784/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5339 - acc: 0.7407 - val_loss: 0.6416 - val_acc: 0.5000\n",
      "Epoch 785/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5322 - acc: 0.7407 - val_loss: 0.6675 - val_acc: 0.5000\n",
      "Epoch 786/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5335 - acc: 0.7407 - val_loss: 0.6749 - val_acc: 0.5000\n",
      "Epoch 787/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5365 - acc: 0.6667 - val_loss: 0.6671 - val_acc: 0.5000\n",
      "Epoch 788/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5256 - acc: 0.7407 - val_loss: 0.6438 - val_acc: 0.5000\n",
      "Epoch 789/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5281 - acc: 0.7407 - val_loss: 0.6605 - val_acc: 0.5000\n",
      "Epoch 790/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5306 - acc: 0.7407 - val_loss: 0.6590 - val_acc: 0.5000\n",
      "Epoch 791/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5264 - acc: 0.7407 - val_loss: 0.6610 - val_acc: 0.5000\n",
      "Epoch 792/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5264 - acc: 0.7407 - val_loss: 0.6647 - val_acc: 0.5000\n",
      "Epoch 793/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5267 - acc: 0.7407 - val_loss: 0.6722 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 794/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5246 - acc: 0.7407 - val_loss: 0.6736 - val_acc: 0.5000\n",
      "Epoch 795/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5247 - acc: 0.7407 - val_loss: 0.6803 - val_acc: 0.5000\n",
      "Epoch 796/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5267 - acc: 0.7037 - val_loss: 0.6774 - val_acc: 0.5000\n",
      "Epoch 797/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5216 - acc: 0.7407 - val_loss: 0.6572 - val_acc: 0.5000\n",
      "Epoch 798/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5239 - acc: 0.7407 - val_loss: 0.6612 - val_acc: 0.5000\n",
      "Epoch 799/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5266 - acc: 0.7407 - val_loss: 0.6661 - val_acc: 0.5000\n",
      "Epoch 800/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5249 - acc: 0.7407 - val_loss: 0.6791 - val_acc: 0.5000\n",
      "Epoch 801/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5216 - acc: 0.7407 - val_loss: 0.6796 - val_acc: 0.5000\n",
      "Epoch 802/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5257 - acc: 0.7037 - val_loss: 0.6928 - val_acc: 0.5000\n",
      "Epoch 803/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5259 - acc: 0.7407 - val_loss: 0.6720 - val_acc: 0.5000\n",
      "Epoch 804/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5226 - acc: 0.7407 - val_loss: 0.6539 - val_acc: 0.5000\n",
      "Epoch 805/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5304 - acc: 0.7407 - val_loss: 0.6774 - val_acc: 0.5000\n",
      "Epoch 806/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5300 - acc: 0.7407 - val_loss: 0.6799 - val_acc: 0.5000\n",
      "Epoch 807/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5249 - acc: 0.7407 - val_loss: 0.6829 - val_acc: 0.5000\n",
      "Epoch 808/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5334 - acc: 0.6667 - val_loss: 0.6895 - val_acc: 0.5000\n",
      "Epoch 809/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5241 - acc: 0.7407 - val_loss: 0.6731 - val_acc: 0.5000\n",
      "Epoch 810/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5283 - acc: 0.7407 - val_loss: 0.6672 - val_acc: 0.5000\n",
      "Epoch 811/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5249 - acc: 0.7407 - val_loss: 0.6878 - val_acc: 0.5000\n",
      "Epoch 812/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5308 - acc: 0.7037 - val_loss: 0.6761 - val_acc: 0.5000\n",
      "Epoch 813/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5253 - acc: 0.7407 - val_loss: 0.6700 - val_acc: 0.5000\n",
      "Epoch 814/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5231 - acc: 0.7407 - val_loss: 0.7008 - val_acc: 0.5000\n",
      "Epoch 815/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5266 - acc: 0.7407 - val_loss: 0.7121 - val_acc: 0.5000\n",
      "Epoch 816/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5260 - acc: 0.7407 - val_loss: 0.7042 - val_acc: 0.5000\n",
      "Epoch 817/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5281 - acc: 0.7037 - val_loss: 0.7167 - val_acc: 0.5000\n",
      "Epoch 818/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5266 - acc: 0.7407 - val_loss: 0.7240 - val_acc: 0.5000\n",
      "Epoch 819/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5251 - acc: 0.7407 - val_loss: 0.7049 - val_acc: 0.5000\n",
      "Epoch 820/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5273 - acc: 0.7407 - val_loss: 0.7102 - val_acc: 0.5000\n",
      "Epoch 821/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5255 - acc: 0.7407 - val_loss: 0.7183 - val_acc: 0.5000\n",
      "Epoch 822/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5283 - acc: 0.7407 - val_loss: 0.7007 - val_acc: 0.5000\n",
      "Epoch 823/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5261 - acc: 0.7407 - val_loss: 0.6687 - val_acc: 0.5000\n",
      "Epoch 824/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5246 - acc: 0.7407 - val_loss: 0.6778 - val_acc: 0.5000\n",
      "Epoch 825/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5269 - acc: 0.7407 - val_loss: 0.6917 - val_acc: 0.5000\n",
      "Epoch 826/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5247 - acc: 0.7407 - val_loss: 0.6854 - val_acc: 0.5000\n",
      "Epoch 827/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5262 - acc: 0.7407 - val_loss: 0.6923 - val_acc: 0.5000\n",
      "Epoch 828/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5245 - acc: 0.7407 - val_loss: 0.7218 - val_acc: 0.5000\n",
      "Epoch 829/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5262 - acc: 0.7407 - val_loss: 0.7284 - val_acc: 0.5000\n",
      "Epoch 830/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5250 - acc: 0.7407 - val_loss: 0.7058 - val_acc: 0.5000\n",
      "Epoch 831/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5276 - acc: 0.7407 - val_loss: 0.6955 - val_acc: 0.5000\n",
      "Epoch 832/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5267 - acc: 0.7037 - val_loss: 0.7108 - val_acc: 0.5000\n",
      "Epoch 833/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5253 - acc: 0.7407 - val_loss: 0.7153 - val_acc: 0.5000\n",
      "Epoch 834/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5256 - acc: 0.7407 - val_loss: 0.6886 - val_acc: 0.5000\n",
      "Epoch 835/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5213 - acc: 0.7407 - val_loss: 0.6926 - val_acc: 0.5000\n",
      "Epoch 836/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5208 - acc: 0.7407 - val_loss: 0.7065 - val_acc: 0.5000\n",
      "Epoch 837/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5216 - acc: 0.7407 - val_loss: 0.7033 - val_acc: 0.5000\n",
      "Epoch 838/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5192 - acc: 0.7407 - val_loss: 0.6999 - val_acc: 0.5000\n",
      "Epoch 839/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5175 - acc: 0.7407 - val_loss: 0.7058 - val_acc: 0.5000\n",
      "Epoch 840/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5221 - acc: 0.7407 - val_loss: 0.7023 - val_acc: 0.5000\n",
      "Epoch 841/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5196 - acc: 0.7407 - val_loss: 0.6961 - val_acc: 0.5000\n",
      "Epoch 842/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5218 - acc: 0.7407 - val_loss: 0.7204 - val_acc: 0.5000\n",
      "Epoch 843/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5227 - acc: 0.7407 - val_loss: 0.7269 - val_acc: 0.5000\n",
      "Epoch 844/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5202 - acc: 0.7407 - val_loss: 0.7056 - val_acc: 0.5000\n",
      "Epoch 845/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5218 - acc: 0.7407 - val_loss: 0.7024 - val_acc: 0.5000\n",
      "Epoch 846/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5213 - acc: 0.7407 - val_loss: 0.7080 - val_acc: 0.5000\n",
      "Epoch 847/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5198 - acc: 0.7407 - val_loss: 0.7245 - val_acc: 0.5000\n",
      "Epoch 848/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5162 - acc: 0.7407 - val_loss: 0.7348 - val_acc: 0.5000\n",
      "Epoch 849/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5206 - acc: 0.7407 - val_loss: 0.7412 - val_acc: 0.5000\n",
      "Epoch 850/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5194 - acc: 0.7407 - val_loss: 0.7409 - val_acc: 0.5000\n",
      "Epoch 851/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5200 - acc: 0.7407 - val_loss: 0.7299 - val_acc: 0.5000\n",
      "Epoch 852/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5193 - acc: 0.7407 - val_loss: 0.7286 - val_acc: 0.5000\n",
      "Epoch 853/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5212 - acc: 0.7407 - val_loss: 0.6927 - val_acc: 0.5000\n",
      "Epoch 854/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5206 - acc: 0.7407 - val_loss: 0.6939 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 855/1000\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5173 - acc: 0.700 - 0s 1ms/step - loss: 0.5197 - acc: 0.7407 - val_loss: 0.7181 - val_acc: 0.5000\n",
      "Epoch 856/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5292 - acc: 0.7407 - val_loss: 0.6964 - val_acc: 0.5000\n",
      "Epoch 857/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5225 - acc: 0.7407 - val_loss: 0.6818 - val_acc: 0.5000\n",
      "Epoch 858/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5226 - acc: 0.7407 - val_loss: 0.7130 - val_acc: 0.5000\n",
      "Epoch 859/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5214 - acc: 0.7407 - val_loss: 0.7311 - val_acc: 0.5000\n",
      "Epoch 860/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5256 - acc: 0.7407 - val_loss: 0.7108 - val_acc: 0.5000\n",
      "Epoch 861/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5274 - acc: 0.7037 - val_loss: 0.6946 - val_acc: 0.5000\n",
      "Epoch 862/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5221 - acc: 0.8148 - val_loss: 0.7089 - val_acc: 0.5000\n",
      "Epoch 863/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5235 - acc: 0.7407 - val_loss: 0.7052 - val_acc: 0.5000\n",
      "Epoch 864/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5229 - acc: 0.7407 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 865/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5249 - acc: 0.7407 - val_loss: 0.6974 - val_acc: 0.5000\n",
      "Epoch 866/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5220 - acc: 0.7407 - val_loss: 0.7100 - val_acc: 0.5000\n",
      "Epoch 867/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5178 - acc: 0.7407 - val_loss: 0.7024 - val_acc: 0.5000\n",
      "Epoch 868/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5194 - acc: 0.7407 - val_loss: 0.7133 - val_acc: 0.5000\n",
      "Epoch 869/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5154 - acc: 0.7407 - val_loss: 0.7251 - val_acc: 0.5000\n",
      "Epoch 870/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5186 - acc: 0.7407 - val_loss: 0.7213 - val_acc: 0.5000\n",
      "Epoch 871/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5166 - acc: 0.7407 - val_loss: 0.7106 - val_acc: 0.5000\n",
      "Epoch 872/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5176 - acc: 0.7407 - val_loss: 0.7146 - val_acc: 0.5000\n",
      "Epoch 873/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5210 - acc: 0.7407 - val_loss: 0.7140 - val_acc: 0.5000\n",
      "Epoch 874/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5190 - acc: 0.7407 - val_loss: 0.7204 - val_acc: 0.5000\n",
      "Epoch 875/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5191 - acc: 0.7407 - val_loss: 0.7260 - val_acc: 0.5000\n",
      "Epoch 876/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5194 - acc: 0.7407 - val_loss: 0.7176 - val_acc: 0.5000\n",
      "Epoch 877/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5164 - acc: 0.7407 - val_loss: 0.7177 - val_acc: 0.5000\n",
      "Epoch 878/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5238 - acc: 0.7407 - val_loss: 0.7005 - val_acc: 0.5000\n",
      "Epoch 879/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5225 - acc: 0.7407 - val_loss: 0.7084 - val_acc: 0.5000\n",
      "Epoch 880/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5192 - acc: 0.7407 - val_loss: 0.7493 - val_acc: 0.5000\n",
      "Epoch 881/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5232 - acc: 0.7407 - val_loss: 0.7562 - val_acc: 0.5000\n",
      "Epoch 882/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5247 - acc: 0.7407 - val_loss: 0.7327 - val_acc: 0.5000\n",
      "Epoch 883/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5204 - acc: 0.7407 - val_loss: 0.7148 - val_acc: 0.5000\n",
      "Epoch 884/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5180 - acc: 0.7407 - val_loss: 0.7106 - val_acc: 0.5000\n",
      "Epoch 885/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5244 - acc: 0.7407 - val_loss: 0.7021 - val_acc: 0.5000\n",
      "Epoch 886/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5247 - acc: 0.7407 - val_loss: 0.6965 - val_acc: 0.5000\n",
      "Epoch 887/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5203 - acc: 0.7407 - val_loss: 0.6966 - val_acc: 0.5000\n",
      "Epoch 888/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5207 - acc: 0.7407 - val_loss: 0.7009 - val_acc: 0.5000\n",
      "Epoch 889/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5196 - acc: 0.7407 - val_loss: 0.7142 - val_acc: 0.5000\n",
      "Epoch 890/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5159 - acc: 0.7407 - val_loss: 0.7175 - val_acc: 0.5000\n",
      "Epoch 891/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5200 - acc: 0.7407 - val_loss: 0.7134 - val_acc: 0.5000\n",
      "Epoch 892/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5217 - acc: 0.7407 - val_loss: 0.7177 - val_acc: 0.5000\n",
      "Epoch 893/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5177 - acc: 0.7407 - val_loss: 0.7191 - val_acc: 0.5000\n",
      "Epoch 894/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5211 - acc: 0.7407 - val_loss: 0.7088 - val_acc: 0.5000\n",
      "Epoch 895/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5187 - acc: 0.7407 - val_loss: 0.7093 - val_acc: 0.5000\n",
      "Epoch 896/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5193 - acc: 0.7407 - val_loss: 0.7168 - val_acc: 0.5000\n",
      "Epoch 897/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5187 - acc: 0.7407 - val_loss: 0.6958 - val_acc: 0.5000\n",
      "Epoch 898/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5170 - acc: 0.7407 - val_loss: 0.6954 - val_acc: 0.5000\n",
      "Epoch 899/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5184 - acc: 0.7407 - val_loss: 0.7099 - val_acc: 0.5000\n",
      "Epoch 900/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5217 - acc: 0.7407 - val_loss: 0.7057 - val_acc: 0.5000\n",
      "Epoch 901/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5177 - acc: 0.7407 - val_loss: 0.7111 - val_acc: 0.5000\n",
      "Epoch 902/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5168 - acc: 0.7407 - val_loss: 0.7213 - val_acc: 0.5000\n",
      "Epoch 903/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5172 - acc: 0.7407 - val_loss: 0.7134 - val_acc: 0.5000\n",
      "Epoch 904/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5178 - acc: 0.7407 - val_loss: 0.7167 - val_acc: 0.5000\n",
      "Epoch 905/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5168 - acc: 0.7407 - val_loss: 0.6977 - val_acc: 0.5000\n",
      "Epoch 906/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5173 - acc: 0.7407 - val_loss: 0.6966 - val_acc: 0.5000\n",
      "Epoch 907/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5155 - acc: 0.7407 - val_loss: 0.7043 - val_acc: 0.5000\n",
      "Epoch 908/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5173 - acc: 0.7407 - val_loss: 0.7127 - val_acc: 0.5000\n",
      "Epoch 909/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5170 - acc: 0.7407 - val_loss: 0.7131 - val_acc: 0.5000\n",
      "Epoch 910/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5163 - acc: 0.7407 - val_loss: 0.6985 - val_acc: 0.5000\n",
      "Epoch 911/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5179 - acc: 0.7407 - val_loss: 0.6988 - val_acc: 0.5000\n",
      "Epoch 912/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5188 - acc: 0.7407 - val_loss: 0.7149 - val_acc: 0.5000\n",
      "Epoch 913/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5252 - acc: 0.7407 - val_loss: 0.7024 - val_acc: 0.5000\n",
      "Epoch 914/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5191 - acc: 0.7407 - val_loss: 0.6913 - val_acc: 0.5000\n",
      "Epoch 915/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5225 - acc: 0.7407 - val_loss: 0.7046 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 916/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5173 - acc: 0.7407 - val_loss: 0.7264 - val_acc: 0.5000\n",
      "Epoch 917/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5262 - acc: 0.7407 - val_loss: 0.7153 - val_acc: 0.5000\n",
      "Epoch 918/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5234 - acc: 0.7407 - val_loss: 0.6882 - val_acc: 0.5000\n",
      "Epoch 919/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5224 - acc: 0.7407 - val_loss: 0.6946 - val_acc: 0.5000\n",
      "Epoch 920/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5225 - acc: 0.7407 - val_loss: 0.7241 - val_acc: 0.5000\n",
      "Epoch 921/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5324 - acc: 0.7407 - val_loss: 0.7279 - val_acc: 0.5000\n",
      "Epoch 922/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5235 - acc: 0.7407 - val_loss: 0.7051 - val_acc: 0.5000\n",
      "Epoch 923/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5244 - acc: 0.7037 - val_loss: 0.7059 - val_acc: 0.5000\n",
      "Epoch 924/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5227 - acc: 0.7407 - val_loss: 0.7107 - val_acc: 0.5000\n",
      "Epoch 925/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5195 - acc: 0.7407 - val_loss: 0.7022 - val_acc: 0.5000\n",
      "Epoch 926/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5190 - acc: 0.7407 - val_loss: 0.7081 - val_acc: 0.5000\n",
      "Epoch 927/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5167 - acc: 0.7407 - val_loss: 0.7117 - val_acc: 0.5000\n",
      "Epoch 928/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5163 - acc: 0.7407 - val_loss: 0.6894 - val_acc: 0.5000\n",
      "Epoch 929/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5202 - acc: 0.7407 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 930/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5197 - acc: 0.7407 - val_loss: 0.6985 - val_acc: 0.5000\n",
      "Epoch 931/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5168 - acc: 0.7407 - val_loss: 0.6889 - val_acc: 0.5000\n",
      "Epoch 932/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5212 - acc: 0.7407 - val_loss: 0.6919 - val_acc: 0.5000\n",
      "Epoch 933/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5188 - acc: 0.7407 - val_loss: 0.7202 - val_acc: 0.5000\n",
      "Epoch 934/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5275 - acc: 0.7407 - val_loss: 0.7289 - val_acc: 0.5000\n",
      "Epoch 935/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5280 - acc: 0.7407 - val_loss: 0.7061 - val_acc: 0.5000\n",
      "Epoch 936/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5214 - acc: 0.7407 - val_loss: 0.6904 - val_acc: 0.5000\n",
      "Epoch 937/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5298 - acc: 0.7407 - val_loss: 0.7012 - val_acc: 0.5000\n",
      "Epoch 938/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5195 - acc: 0.7407 - val_loss: 0.7217 - val_acc: 0.5000\n",
      "Epoch 939/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5230 - acc: 0.7407 - val_loss: 0.7126 - val_acc: 0.5000\n",
      "Epoch 940/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5155 - acc: 0.7407 - val_loss: 0.7105 - val_acc: 0.5000\n",
      "Epoch 941/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5180 - acc: 0.7407 - val_loss: 0.7184 - val_acc: 0.5000\n",
      "Epoch 942/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5148 - acc: 0.7407 - val_loss: 0.6990 - val_acc: 0.5000\n",
      "Epoch 943/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5160 - acc: 0.7407 - val_loss: 0.7015 - val_acc: 0.5000\n",
      "Epoch 944/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5197 - acc: 0.7407 - val_loss: 0.6958 - val_acc: 0.5000\n",
      "Epoch 945/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5193 - acc: 0.7407 - val_loss: 0.6832 - val_acc: 0.5000\n",
      "Epoch 946/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5211 - acc: 0.7407 - val_loss: 0.7075 - val_acc: 0.5000\n",
      "Epoch 947/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5236 - acc: 0.7407 - val_loss: 0.7141 - val_acc: 0.5000\n",
      "Epoch 948/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5206 - acc: 0.7407 - val_loss: 0.7046 - val_acc: 0.5000\n",
      "Epoch 949/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5249 - acc: 0.7407 - val_loss: 0.7124 - val_acc: 0.5000\n",
      "Epoch 950/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5257 - acc: 0.7407 - val_loss: 0.7309 - val_acc: 0.5000\n",
      "Epoch 951/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5225 - acc: 0.7407 - val_loss: 0.7226 - val_acc: 0.5000\n",
      "Epoch 952/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5205 - acc: 0.7407 - val_loss: 0.6851 - val_acc: 0.5000\n",
      "Epoch 953/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5246 - acc: 0.7778 - val_loss: 0.6716 - val_acc: 0.5000\n",
      "Epoch 954/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5276 - acc: 0.7407 - val_loss: 0.6900 - val_acc: 0.5000\n",
      "Epoch 955/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5193 - acc: 0.7407 - val_loss: 0.7224 - val_acc: 0.5000\n",
      "Epoch 956/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5284 - acc: 0.7407 - val_loss: 0.7229 - val_acc: 0.5000\n",
      "Epoch 957/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5245 - acc: 0.7407 - val_loss: 0.6959 - val_acc: 0.5000\n",
      "Epoch 958/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5249 - acc: 0.6667 - val_loss: 0.6916 - val_acc: 0.5000\n",
      "Epoch 959/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5250 - acc: 0.6667 - val_loss: 0.7159 - val_acc: 0.5000\n",
      "Epoch 960/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5201 - acc: 0.7407 - val_loss: 0.7145 - val_acc: 0.5000\n",
      "Epoch 961/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5178 - acc: 0.7407 - val_loss: 0.7113 - val_acc: 0.5000\n",
      "Epoch 962/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5158 - acc: 0.7407 - val_loss: 0.7173 - val_acc: 0.5000\n",
      "Epoch 963/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5188 - acc: 0.7407 - val_loss: 0.7071 - val_acc: 0.5000\n",
      "Epoch 964/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5218 - acc: 0.7407 - val_loss: 0.7062 - val_acc: 0.5000\n",
      "Epoch 965/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5151 - acc: 0.7407 - val_loss: 0.7268 - val_acc: 0.5000\n",
      "Epoch 966/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5210 - acc: 0.7407 - val_loss: 0.7274 - val_acc: 0.5000\n",
      "Epoch 967/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5201 - acc: 0.7407 - val_loss: 0.7133 - val_acc: 0.5000\n",
      "Epoch 968/1000\n",
      "27/27 [==============================] - 0s 741us/step - loss: 0.5186 - acc: 0.7407 - val_loss: 0.7154 - val_acc: 0.5000\n",
      "Epoch 969/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5159 - acc: 0.7407 - val_loss: 0.7142 - val_acc: 0.5000\n",
      "Epoch 970/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5150 - acc: 0.7407 - val_loss: 0.7007 - val_acc: 0.5000\n",
      "Epoch 971/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5189 - acc: 0.7407 - val_loss: 0.7081 - val_acc: 0.5000\n",
      "Epoch 972/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5174 - acc: 0.7407 - val_loss: 0.7143 - val_acc: 0.5000\n",
      "Epoch 973/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5158 - acc: 0.7407 - val_loss: 0.7080 - val_acc: 0.5000\n",
      "Epoch 974/1000\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5183 - acc: 0.7407 - val_loss: 0.7126 - val_acc: 0.5000\n",
      "Epoch 975/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5174 - acc: 0.7407 - val_loss: 0.7043 - val_acc: 0.5000\n",
      "Epoch 976/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5142 - acc: 0.7407 - val_loss: 0.7097 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 977/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5180 - acc: 0.7407 - val_loss: 0.7089 - val_acc: 0.5000\n",
      "Epoch 978/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5174 - acc: 0.7407 - val_loss: 0.7068 - val_acc: 0.5000\n",
      "Epoch 979/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5174 - acc: 0.7407 - val_loss: 0.7128 - val_acc: 0.5000\n",
      "Epoch 980/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5175 - acc: 0.7407 - val_loss: 0.7102 - val_acc: 0.5000\n",
      "Epoch 981/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5137 - acc: 0.7407 - val_loss: 0.7073 - val_acc: 0.5000\n",
      "Epoch 982/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5152 - acc: 0.7407 - val_loss: 0.7078 - val_acc: 0.5000\n",
      "Epoch 983/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5156 - acc: 0.7407 - val_loss: 0.7022 - val_acc: 0.5000\n",
      "Epoch 984/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5141 - acc: 0.7407 - val_loss: 0.7082 - val_acc: 0.5000\n",
      "Epoch 985/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5141 - acc: 0.7407 - val_loss: 0.6997 - val_acc: 0.5000\n",
      "Epoch 986/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5159 - acc: 0.7407 - val_loss: 0.7026 - val_acc: 0.5000\n",
      "Epoch 987/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5166 - acc: 0.7407 - val_loss: 0.7099 - val_acc: 0.5000\n",
      "Epoch 988/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5190 - acc: 0.7407 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 989/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5186 - acc: 0.7407 - val_loss: 0.6875 - val_acc: 0.5000\n",
      "Epoch 990/1000\n",
      "27/27 [==============================] - 0s 833us/step - loss: 0.5193 - acc: 0.7407 - val_loss: 0.7142 - val_acc: 0.5000\n",
      "Epoch 991/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5240 - acc: 0.7407 - val_loss: 0.7241 - val_acc: 0.5000\n",
      "Epoch 992/1000\n",
      "27/27 [==============================] - 0s 926us/step - loss: 0.5212 - acc: 0.7407 - val_loss: 0.7143 - val_acc: 0.5000\n",
      "Epoch 993/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5215 - acc: 0.7407 - val_loss: 0.7270 - val_acc: 0.5000\n",
      "Epoch 994/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5195 - acc: 0.7407 - val_loss: 0.7270 - val_acc: 0.5000\n",
      "Epoch 995/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5220 - acc: 0.7407 - val_loss: 0.7153 - val_acc: 0.5000\n",
      "Epoch 996/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5199 - acc: 0.7407 - val_loss: 0.7106 - val_acc: 0.5000\n",
      "Epoch 997/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5186 - acc: 0.7407 - val_loss: 0.7185 - val_acc: 0.5000\n",
      "Epoch 998/1000\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5196 - acc: 0.7407 - val_loss: 0.7053 - val_acc: 0.5000\n",
      "Epoch 999/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5189 - acc: 0.7407 - val_loss: 0.6943 - val_acc: 0.5000\n",
      "Epoch 1000/1000\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5194 - acc: 0.7407 - val_loss: 0.7096 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x327bb588>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Standard model using the top performing parameters from Talos\n",
    "Standard_model = Sequential()\n",
    "Standard_model.add(Dense(8, input_dim=1, activation='relu'))\n",
    "Standard_model.add(Dense(64, activation='relu'))\n",
    "Standard_model.add(Dense(64, activation='relu'))\n",
    "Standard_model.add(Dense(56, activation='relu'))\n",
    "Standard_model.add(Dense(48, activation='relu'))\n",
    "Standard_model.add(Dense(40, activation='relu'))\n",
    "Standard_model.add(Dense(32, activation='relu'))\n",
    "Standard_model.add(Dense(24, activation='relu'))\n",
    "Standard_model.add(Dense(16, activation='relu'))\n",
    "Standard_model.add(Dense(8, activation='relu'))\n",
    "Standard_model.add(Dense(3, activation='linear'))\n",
    "Standard_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "Standard_model.fit(train_features_Standard,\n",
    "                 train_labels_Standard,\n",
    "                 validation_data=(test_features_Standard, test_labels_Standard),\n",
    "                 batch_size=20,\n",
    "                 epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMax prediction on validation data\n",
    "prediction = MinMax_model.predict(validation_features_MinMax)\n",
    "validation_prediction = np.concatenate([prediction, validation_features_MinMax], axis=1)\n",
    "validation = MinMax_scaler.inverse_transform(validation_prediction)[:, 0:3]\n",
    "# compare\n",
    "print('MinMax Validation Prediction:\\n\\n', validation)\n",
    "print('\\nActual Validation:\\n\\n', np_data[27, 0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MinMax_rpm_error = ((np_data[27, 0:3][0] - validation[0][0])/np_data[27, 0:3][0])*100\n",
    "MinMax_feed_error = ((np_data[27, 0:3][1] - validation[0][1])/np_data[27, 0:3][1])*100\n",
    "MinMax_doc_error = ((np_data[27, 0:3][2] - validation[0][2])/np_data[27, 0:3][2])*100\n",
    "MinMax_average_error = (np.absolute(MinMax_rpm_error) + np.absolute(MinMax_feed_error) + np.absolute(MinMax_doc_error)) / 3\n",
    "\n",
    "print('MinMax percent errors:\\n')\n",
    "print('RPM : ', MinMax_rpm_error)\n",
    "print('Feedrate : ', MinMax_feed_error)\n",
    "print('Depth of cut : ', MinMax_doc_error)\n",
    "print('Average : ', MinMax_average_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Validation Prediction:\n",
      "\n",
      " [1132.37382782    0.04839572    0.39623012]\n",
      "\n",
      "Actual Validation:\n",
      "\n",
      " [1100.      0.05    0.4 ]\n"
     ]
    }
   ],
   "source": [
    "# Standard prediction on validation\n",
    "prediction = Standard_model.predict(validation_features_Standard)\n",
    "validation_prediction = np.concatenate([prediction, validation_features_Standard], axis=1)\n",
    "validation = Standard_scaler.inverse_transform(validation_prediction)[:, 0:3]\n",
    "# compare\n",
    "print('Standard Validation Prediction:\\n\\n', validation[0])\n",
    "print('\\nActual Validation:\\n\\n', np_data[27, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard percent errors:\n",
      "\n",
      "RPM :  -2.9430752560530933\n",
      "Feed rate :  3.208554726418067\n",
      "Depth of cut :  0.9424703760523706\n",
      "Average :  2.3647001195078436\n"
     ]
    }
   ],
   "source": [
    "Standard_rpm_error = ((np_data[27, 0:3][0] - validation[0][0])/np_data[27, 0:3][0])*100\n",
    "Standard_feed_error = ((np_data[27, 0:3][1] - validation[0][1])/np_data[27, 0:3][1])*100\n",
    "Standard_doc_error = ((np_data[27, 0:3][2] - validation[0][2])/np_data[27, 0:3][2])*100\n",
    "Standard_average_error = (np.absolute(Standard_rpm_error) + np.absolute(Standard_feed_error) + np.absolute(Standard_doc_error)) / 3\n",
    "\n",
    "print('Standard percent errors:\\n')\n",
    "print('RPM : ', Standard_rpm_error)\n",
    "print('Feed rate : ', Standard_feed_error)\n",
    "print('Depth of cut : ', Standard_doc_error)\n",
    "print('Average : ', Standard_average_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
