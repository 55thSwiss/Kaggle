{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sciencedirect.com/science/article/pii/S2211812814005318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'numpy' from 'C:\\\\Users\\\\MacalusoC\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'>   1.17.0\n",
      "<module 'pandas' from 'C:\\\\Users\\\\MacalusoC\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'>   0.24.2\n",
      "<module 'sklearn' from 'C:\\\\Users\\\\MacalusoC\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\__init__.py'>   0.20.3\n",
      "<module 'keras' from 'C:\\\\Users\\\\MacalusoC\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\keras\\\\__init__.py'>   2.2.4\n",
      "<module 'talos' from 'C:\\\\Users\\\\MacalusoC\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\talos\\\\__init__.py'>   0.6.0\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "%matplotlib inline\n",
    "#import keras\n",
    "from keras.models import Sequential\n",
    "from keras.activations import *\n",
    "from keras.layers import *\n",
    "from keras.losses import *\n",
    "from keras.optimizers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import talos as ta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# suppres NumPy arrays scientific notation and round decimals to three places\n",
    "np.set_printoptions(suppress=True)\n",
    "np.printoptions(precision=3, suppress=True)\n",
    "\n",
    "libraries = [np,\n",
    "             pd,\n",
    "             sklearn,\n",
    "             keras,\n",
    "             ta]\n",
    "for library in libraries:\n",
    "    print(library, ' ', library.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow==1.14.0\n",
      "talos==0.6.0\n",
      "six==1.12.0\n",
      "scikit-learn==0.20.3\n",
      "pandas==0.24.2\n",
      "numpy==1.17.0\n"
     ]
    }
   ],
   "source": [
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "train_data = pd.read_csv('Training_Features_and_Labels.txt', delim_whitespace=True, encoding='ISO-8859-1')\n",
    "train_data.drop(columns=['Sr._No.'], inplace=True)\n",
    "# import validation data\n",
    "test_data = pd.read_csv('Test_Features_and_Labels.txt', delim_whitespace=True, encoding='ISO-8859-1')\n",
    "test_data.drop(columns=['Sr._No.'], inplace=True)\n",
    "# segregate a single row for validation\n",
    "validation_data = test_data.loc[0]\n",
    "test_data = test_data.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      "\n",
      " [[ 306.67    0.36]\n",
      " [ 609.76    0.47]\n",
      " [ 909.28    0.52]\n",
      " [ 582.94    0.8 ]\n",
      " [1158.73    0.9 ]\n",
      " [1727.36    1.1 ]\n",
      " [ 943.34    1.63]\n",
      " [1875.96    1.76]\n",
      " [2797.84    2.17]\n",
      " [ 793.04    0.38]\n",
      " [1577.02    0.48]\n",
      " [2351.92    0.54]\n",
      " [1555.25    0.81]\n",
      " [3092.37    0.82]\n",
      " [4611.35    0.97]\n",
      " [2196.85    1.92]\n",
      " [4366.5     1.91]\n",
      " [6508.93    2.03]\n",
      " [ 875.13    0.29]\n",
      " [1735.95    0.37]\n",
      " [2582.46    0.38]\n",
      " [1745.24    0.82]\n",
      " [3461.88    0.79]\n",
      " [5149.9     1.11]\n",
      " [2549.2     1.75]\n",
      " [5055.49    1.89]\n",
      " [7518.86    1.82]]\n",
      "\n",
      "Training Labels:\n",
      "\n",
      " [[ 280.        0.0508    0.4   ]\n",
      " [ 280.        0.0508    0.8   ]\n",
      " [ 280.        0.0508    1.2   ]\n",
      " [ 280.        0.1016    0.4   ]\n",
      " [ 280.        0.1016    0.8   ]\n",
      " [ 280.        0.1016    1.2   ]\n",
      " [ 280.        0.1524    0.4   ]\n",
      " [ 280.        0.1524    0.8   ]\n",
      " [ 280.        0.1524    1.2   ]\n",
      " [ 710.        0.0508    0.4   ]\n",
      " [ 710.        0.0508    0.8   ]\n",
      " [ 710.        0.0508    1.2   ]\n",
      " [ 710.        0.1016    0.4   ]\n",
      " [ 710.        0.1016    0.8   ]\n",
      " [ 710.        0.1016    1.2   ]\n",
      " [ 710.        0.1524    0.4   ]\n",
      " [ 710.        0.1524    0.8   ]\n",
      " [ 710.        0.1524    1.2   ]\n",
      " [1120.        0.0508    0.4   ]\n",
      " [1120.        0.0508    0.8   ]\n",
      " [1120.        0.0508    1.2   ]\n",
      " [1120.        0.1016    0.4   ]\n",
      " [1120.        0.1016    0.8   ]\n",
      " [1120.        0.1016    1.2   ]\n",
      " [1120.        0.1524    0.4   ]\n",
      " [1120.        0.1524    0.8   ]\n",
      " [1120.        0.1524    1.2   ]]\n"
     ]
    }
   ],
   "source": [
    "# create NumPy arrays of training features and labels\n",
    "train_features = train_data[['MRR(mm3/min)', 'Ra(µm)']].values\n",
    "train_labels = train_data[['Spindle_speed(rpm)', 'Feed_rate(mm/rev)', 'Depth_of_cut(mm)']].values\n",
    "print('Training Features:\\n\\n', train_features)\n",
    "print('\\nTraining Labels:\\n\\n', train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Features:\n",
      "\n",
      " [[2020.44    0.29]\n",
      " [6054.12    1.87]\n",
      " [5329.21    1.54]\n",
      " [5197.29    1.45]]\n",
      "\n",
      "Testing Labels:\n",
      "\n",
      " [[1100.      0.05    0.69]\n",
      " [1095.      0.15    1.2 ]\n",
      " [1097.      0.13    1.14]\n",
      " [1094.      0.12    1.15]]\n"
     ]
    }
   ],
   "source": [
    "# create NumPy arrays of validation features and labels\n",
    "test_features = test_data[['MRR(mm3/min)', 'Ra(µm)']].values\n",
    "test_labels = test_data[['Spindle_speed(rpm)', 'Feed_rate(mm/rev)', 'Depth_of_cut(mm)']].values\n",
    "print('Testing Features:\\n\\n', test_features)\n",
    "print('\\nTesting Labels:\\n\\n', test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Features:\n",
      "\n",
      " [[1106.51    0.21]]\n",
      "\n",
      "Validation Labels:\n",
      "\n",
      " [[1100.      0.05    0.4 ]]\n"
     ]
    }
   ],
   "source": [
    "# create NumPy array for validation data\n",
    "validation_features = validation_data[['MRR(mm3/min)', 'Ra(µm)']].values\n",
    "validation_labels = validation_data[['Spindle_speed(rpm)', 'Feed_rate(mm/rev)', 'Depth_of_cut(mm)']].values\n",
    "\n",
    "# reshape the validation data because it's only one row\n",
    "validation_features = validation_features.reshape(1, -1)\n",
    "validation_labels = validation_labels.reshape(1, -1)\n",
    "\n",
    "print('Validation Features:\\n\\n', validation_features)\n",
    "print('\\nValidation Labels:\\n\\n', validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms features by scaling each feature to a given range, -1 and 1 in this case\n",
    "MinMax_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_features_MinMax = MinMax_scaler.fit_transform(train_features)\n",
    "train_labels_MinMax = MinMax_scaler.fit_transform(train_labels)\n",
    "test_features_MinMax = MinMax_scaler.fit_transform(test_features)\n",
    "test_labels_MinMax = MinMax_scaler.fit_transform(test_labels)\n",
    "validation_features_MinMax = MinMax_scaler.fit_transform(validation_features)\n",
    "validation_labels_MinMax = MinMax_scaler.fit_transform(validation_labels)\n",
    "\n",
    "#MinMax_scaler.inverse_transform(validation_labels_MinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "Standard_scaler = StandardScaler()\n",
    "train_features_Standard = Standard_scaler.fit_transform(train_features)\n",
    "train_labels_Standard = Standard_scaler.fit_transform(train_labels)\n",
    "test_features_Standard = Standard_scaler.fit_transform(test_features)\n",
    "test_labels_Standard = Standard_scaler.fit_transform(test_labels)\n",
    "validation_features_Standard = Standard_scaler.fit_transform(validation_features)\n",
    "validation_labels_Standard = Standard_scaler.fit_transform(validation_labels)\n",
    "\n",
    "# Standard_scaler.inverse_transform(train_features_Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron': [8, 12, 24],\n",
    "    'second_neuron': [36, 48, 62, 84],\n",
    "    'third_neuron': [36, 48, 62, 84],\n",
    "    'fourth_neuron': [8, 12, 24],\n",
    "    'batch_size': [10, 20, 30],\n",
    "    'activation': [relu,\n",
    "                   softmax,\n",
    "                   #selu,\n",
    "                   #softplus,\n",
    "                   #softsign,\n",
    "                   tanh,\n",
    "                   sigmoid,\n",
    "                   #hard_sigmoid,\n",
    "                   #exponential,\n",
    "                   linear],\n",
    "    'optimizer' : [#'SGD',\n",
    "                   #'RMSprop',\n",
    "                   #'Adagrad',\n",
    "                   #'Adadelta',\n",
    "                   'Adam',],\n",
    "                   #'Adamax',\n",
    "                   #'Nadam',],\n",
    "    'loss' : [mean_squared_error,\n",
    "              mean_absolute_error,] \n",
    "              #mean_absolute_percentage_error, \n",
    "              #mean_squared_logarithmic_error,\n",
    "              #squared_hinge,hinge,\n",
    "              #categorical_hinge,\n",
    "              #logcosh,],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMax_ann(train_features, train_labels, test_features, test_labels, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=2, activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['third_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['fourth_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(3, activation=params['activation']))\n",
    "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(train_features_MinMax, train_labels_MinMax,\n",
    "                    epochs=100,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[test_features_MinMax, test_labels_MinMax])\n",
    "    \n",
    "    # model output\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standard_ann(train_features, train_labels, test_features, test_labels, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=2, activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['third_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['fourth_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(3, activation=params['activation']))\n",
    "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(train_features_Standard, train_labels_Standard,\n",
    "                    epochs=100,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[test_features_Standard, test_labels_Standard])\n",
    "    \n",
    "    # model output\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_MinMax = np.concatenate((train_features_MinMax, test_features_MinMax), axis=0)\n",
    "labels_MinMax = np.concatenate((train_labels_MinMax, test_labels_MinMax), axis=0)\n",
    "\n",
    "features_Standard = np.concatenate((train_features_Standard, test_features_Standard), axis=0)\n",
    "labels_Standard = np.concatenate((train_labels_Standard, test_labels_Standard), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the Talos experiment on MinMax data\n",
    "MinMax_t = ta.Scan(features_MinMax, labels_MinMax, \n",
    "            params=p, \n",
    "            model=MinMax_ann,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the Talos experiment on Standard data\n",
    "Standard_t = ta.Scan(features_Standard, labels_Standard, \n",
    "            params=p, \n",
    "            model=Standard_ann,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "round_epochs                                                   100\n",
       "val_loss                                                  0.369342\n",
       "val_acc                                                          1\n",
       "loss                                                      0.452959\n",
       "acc                                                        0.62963\n",
       "activation                   <function relu at 0x000002540B253C80>\n",
       "batch_size                                                      20\n",
       "first_neuron                                                    24\n",
       "fourth_neuron                                                    8\n",
       "loss.1           <function mean_squared_error at 0x000002540B22...\n",
       "optimizer                                                     Adam\n",
       "second_neuron                                                   84\n",
       "third_neuron                                                    84\n",
       "Name: 338, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MinMax.csv')\n",
    "df.loc[338]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 4 samples\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6351 - acc: 0.450 - 2s 81ms/step - loss: 0.6855 - acc: 0.3704 - val_loss: 0.6527 - val_acc: 0.5000\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6795 - acc: 0.600 - 0s 493us/step - loss: 0.6611 - acc: 0.5556 - val_loss: 0.6561 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6675 - acc: 0.550 - 0s 525us/step - loss: 0.6499 - acc: 0.5926 - val_loss: 0.6425 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6394 - acc: 0.550 - 0s 850us/step - loss: 0.6381 - acc: 0.6296 - val_loss: 0.6189 - val_acc: 0.5000\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6067 - acc: 0.650 - 0s 593us/step - loss: 0.6250 - acc: 0.6296 - val_loss: 0.5934 - val_acc: 0.5000\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6587 - acc: 0.550 - 0s 865us/step - loss: 0.6107 - acc: 0.6296 - val_loss: 0.5677 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5675 - acc: 0.650 - 0s 714us/step - loss: 0.5962 - acc: 0.6296 - val_loss: 0.5411 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5751 - acc: 0.600 - 0s 402us/step - loss: 0.5802 - acc: 0.6296 - val_loss: 0.5142 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5646 - acc: 0.500 - 0s 595us/step - loss: 0.5697 - acc: 0.6296 - val_loss: 0.4934 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5717 - acc: 0.750 - 0s 1ms/step - loss: 0.5601 - acc: 0.6296 - val_loss: 0.4780 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5446 - acc: 0.550 - 0s 769us/step - loss: 0.5490 - acc: 0.5926 - val_loss: 0.4701 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5348 - acc: 0.650 - 0s 696us/step - loss: 0.5402 - acc: 0.5926 - val_loss: 0.4656 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5404 - acc: 0.550 - 0s 355us/step - loss: 0.5337 - acc: 0.5926 - val_loss: 0.4529 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5311 - acc: 0.600 - 0s 489us/step - loss: 0.5265 - acc: 0.5926 - val_loss: 0.4314 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5033 - acc: 0.650 - 0s 493us/step - loss: 0.5208 - acc: 0.5926 - val_loss: 0.4126 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5301 - acc: 0.550 - 0s 761us/step - loss: 0.5167 - acc: 0.5926 - val_loss: 0.4046 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4710 - acc: 0.650 - 0s 396us/step - loss: 0.5127 - acc: 0.5926 - val_loss: 0.3983 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5007 - acc: 0.650 - 0s 927us/step - loss: 0.5104 - acc: 0.5926 - val_loss: 0.3944 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5135 - acc: 0.650 - 0s 481us/step - loss: 0.5073 - acc: 0.5926 - val_loss: 0.3914 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4959 - acc: 0.600 - 0s 517us/step - loss: 0.5073 - acc: 0.5926 - val_loss: 0.3931 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4583 - acc: 0.650 - 0s 892us/step - loss: 0.5065 - acc: 0.5926 - val_loss: 0.3990 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5262 - acc: 0.550 - 0s 629us/step - loss: 0.5056 - acc: 0.5926 - val_loss: 0.3958 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4950 - acc: 0.600 - 0s 1ms/step - loss: 0.5035 - acc: 0.5926 - val_loss: 0.3867 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5548 - acc: 0.500 - 0s 833us/step - loss: 0.4999 - acc: 0.5926 - val_loss: 0.3731 - val_acc: 0.5000\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5266 - acc: 0.600 - 0s 1ms/step - loss: 0.4979 - acc: 0.6296 - val_loss: 0.3639 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5281 - acc: 0.600 - 0s 1ms/step - loss: 0.4973 - acc: 0.6667 - val_loss: 0.3598 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4090 - acc: 0.700 - 0s 636us/step - loss: 0.4980 - acc: 0.6296 - val_loss: 0.3634 - val_acc: 0.5000\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5258 - acc: 0.600 - 0s 569us/step - loss: 0.4933 - acc: 0.6667 - val_loss: 0.3814 - val_acc: 0.5000\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4758 - acc: 0.650 - 0s 715us/step - loss: 0.4925 - acc: 0.5926 - val_loss: 0.3861 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4972 - acc: 0.700 - 0s 643us/step - loss: 0.4935 - acc: 0.5926 - val_loss: 0.3862 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5315 - acc: 0.600 - 0s 665us/step - loss: 0.4935 - acc: 0.5926 - val_loss: 0.3863 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4745 - acc: 0.600 - 0s 1ms/step - loss: 0.4919 - acc: 0.5926 - val_loss: 0.3858 - val_acc: 0.5000\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4877 - acc: 0.700 - 0s 2ms/step - loss: 0.4898 - acc: 0.5926 - val_loss: 0.3713 - val_acc: 0.7500\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4329 - acc: 0.750 - 0s 611us/step - loss: 0.4870 - acc: 0.6667 - val_loss: 0.3645 - val_acc: 0.7500\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4178 - acc: 0.700 - 0s 554us/step - loss: 0.4856 - acc: 0.6667 - val_loss: 0.3690 - val_acc: 0.7500\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4871 - acc: 0.750 - 0s 597us/step - loss: 0.4844 - acc: 0.6667 - val_loss: 0.3789 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4723 - acc: 0.750 - 0s 557us/step - loss: 0.4837 - acc: 0.6667 - val_loss: 0.3840 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4483 - acc: 0.700 - 0s 630us/step - loss: 0.4829 - acc: 0.6667 - val_loss: 0.3866 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4705 - acc: 0.700 - 0s 444us/step - loss: 0.4822 - acc: 0.6667 - val_loss: 0.3842 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4355 - acc: 0.700 - 0s 516us/step - loss: 0.4807 - acc: 0.6667 - val_loss: 0.3736 - val_acc: 0.5000\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4687 - acc: 0.650 - 0s 670us/step - loss: 0.4795 - acc: 0.6296 - val_loss: 0.3631 - val_acc: 0.7500\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4781 - acc: 0.600 - 0s 911us/step - loss: 0.4804 - acc: 0.6296 - val_loss: 0.3644 - val_acc: 0.7500\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4646 - acc: 0.550 - 0s 457us/step - loss: 0.4784 - acc: 0.6296 - val_loss: 0.3737 - val_acc: 0.7500\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4764 - acc: 0.650 - 0s 509us/step - loss: 0.4773 - acc: 0.6667 - val_loss: 0.3817 - val_acc: 0.7500\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5310 - acc: 0.650 - 0s 1ms/step - loss: 0.4771 - acc: 0.6667 - val_loss: 0.3834 - val_acc: 0.7500\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5280 - acc: 0.650 - 0s 733us/step - loss: 0.4764 - acc: 0.6667 - val_loss: 0.3801 - val_acc: 0.7500\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4561 - acc: 0.650 - 0s 594us/step - loss: 0.4757 - acc: 0.6667 - val_loss: 0.3699 - val_acc: 0.7500\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - ETA: 0s - loss: 0.5137 - acc: 0.750 - 0s 684us/step - loss: 0.4748 - acc: 0.6667 - val_loss: 0.3579 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5064 - acc: 0.650 - 0s 628us/step - loss: 0.4768 - acc: 0.6296 - val_loss: 0.3569 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5110 - acc: 0.650 - 0s 544us/step - loss: 0.4752 - acc: 0.6296 - val_loss: 0.3654 - val_acc: 0.7500\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4501 - acc: 0.650 - 0s 612us/step - loss: 0.4735 - acc: 0.6667 - val_loss: 0.3744 - val_acc: 0.7500\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4807 - acc: 0.600 - 0s 425us/step - loss: 0.4743 - acc: 0.6667 - val_loss: 0.3792 - val_acc: 0.7500\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5476 - acc: 0.700 - 0s 448us/step - loss: 0.4739 - acc: 0.6667 - val_loss: 0.3768 - val_acc: 0.7500\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4543 - acc: 0.700 - 0s 444us/step - loss: 0.4733 - acc: 0.6667 - val_loss: 0.3736 - val_acc: 0.7500\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4670 - acc: 0.600 - 0s 483us/step - loss: 0.4725 - acc: 0.6296 - val_loss: 0.3715 - val_acc: 0.7500\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4392 - acc: 0.700 - 0s 459us/step - loss: 0.4713 - acc: 0.6296 - val_loss: 0.3732 - val_acc: 0.7500\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4583 - acc: 0.650 - 0s 590us/step - loss: 0.4706 - acc: 0.6296 - val_loss: 0.3764 - val_acc: 0.7500\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4780 - acc: 0.600 - 0s 2ms/step - loss: 0.4707 - acc: 0.6296 - val_loss: 0.3779 - val_acc: 0.7500\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4204 - acc: 0.700 - 0s 780us/step - loss: 0.4705 - acc: 0.6296 - val_loss: 0.3748 - val_acc: 0.7500\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4880 - acc: 0.700 - 0s 951us/step - loss: 0.4692 - acc: 0.6296 - val_loss: 0.3663 - val_acc: 0.7500\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5183 - acc: 0.650 - 0s 1ms/step - loss: 0.4689 - acc: 0.6296 - val_loss: 0.3598 - val_acc: 0.7500\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4999 - acc: 0.600 - 0s 2ms/step - loss: 0.4697 - acc: 0.6296 - val_loss: 0.3644 - val_acc: 0.5000\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4637 - acc: 0.700 - 0s 1ms/step - loss: 0.4681 - acc: 0.6296 - val_loss: 0.3784 - val_acc: 0.5000\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4351 - acc: 0.650 - 0s 2ms/step - loss: 0.4686 - acc: 0.6296 - val_loss: 0.3884 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4355 - acc: 0.550 - 0s 849us/step - loss: 0.4689 - acc: 0.6296 - val_loss: 0.3907 - val_acc: 0.5000\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5142 - acc: 0.700 - 0s 654us/step - loss: 0.4688 - acc: 0.6296 - val_loss: 0.3860 - val_acc: 0.5000\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4605 - acc: 0.700 - 0s 542us/step - loss: 0.4685 - acc: 0.6296 - val_loss: 0.3786 - val_acc: 0.5000\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4582 - acc: 0.600 - 0s 1ms/step - loss: 0.4682 - acc: 0.6296 - val_loss: 0.3742 - val_acc: 0.5000\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4586 - acc: 0.700 - 0s 1ms/step - loss: 0.4679 - acc: 0.6296 - val_loss: 0.3727 - val_acc: 0.7500\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4488 - acc: 0.600 - 0s 658us/step - loss: 0.4679 - acc: 0.6296 - val_loss: 0.3707 - val_acc: 0.7500\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5042 - acc: 0.650 - 0s 465us/step - loss: 0.4674 - acc: 0.6296 - val_loss: 0.3644 - val_acc: 0.7500\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4677 - acc: 0.700 - 0s 381us/step - loss: 0.4667 - acc: 0.6296 - val_loss: 0.3616 - val_acc: 0.7500\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4857 - acc: 0.550 - 0s 359us/step - loss: 0.4668 - acc: 0.6296 - val_loss: 0.3680 - val_acc: 0.7500\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5227 - acc: 0.600 - 0s 451us/step - loss: 0.4669 - acc: 0.6296 - val_loss: 0.3713 - val_acc: 0.5000\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4605 - acc: 0.550 - 0s 361us/step - loss: 0.4661 - acc: 0.6296 - val_loss: 0.3731 - val_acc: 0.5000\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4514 - acc: 0.700 - 0s 532us/step - loss: 0.4661 - acc: 0.6296 - val_loss: 0.3742 - val_acc: 0.5000\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4045 - acc: 0.650 - 0s 403us/step - loss: 0.4656 - acc: 0.6296 - val_loss: 0.3754 - val_acc: 0.5000\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4735 - acc: 0.600 - 0s 658us/step - loss: 0.4657 - acc: 0.6296 - val_loss: 0.3753 - val_acc: 0.7500\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4725 - acc: 0.650 - 0s 701us/step - loss: 0.4656 - acc: 0.6296 - val_loss: 0.3745 - val_acc: 0.7500\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5002 - acc: 0.550 - 0s 1ms/step - loss: 0.4656 - acc: 0.6296 - val_loss: 0.3700 - val_acc: 0.7500\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4715 - acc: 0.600 - 0s 907us/step - loss: 0.4649 - acc: 0.6296 - val_loss: 0.3581 - val_acc: 0.7500\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4363 - acc: 0.600 - 0s 779us/step - loss: 0.4649 - acc: 0.6296 - val_loss: 0.3522 - val_acc: 0.7500\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4641 - acc: 0.600 - 0s 1ms/step - loss: 0.4661 - acc: 0.6296 - val_loss: 0.3569 - val_acc: 0.5000\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4502 - acc: 0.600 - 0s 656us/step - loss: 0.4654 - acc: 0.6296 - val_loss: 0.3743 - val_acc: 0.5000\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5161 - acc: 0.600 - 0s 1ms/step - loss: 0.4660 - acc: 0.6667 - val_loss: 0.3909 - val_acc: 0.5000\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4608 - acc: 0.700 - 0s 949us/step - loss: 0.4662 - acc: 0.6667 - val_loss: 0.3934 - val_acc: 0.5000\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4901 - acc: 0.700 - 0s 1ms/step - loss: 0.4666 - acc: 0.6667 - val_loss: 0.3935 - val_acc: 0.7500\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4109 - acc: 0.700 - 0s 805us/step - loss: 0.4664 - acc: 0.6667 - val_loss: 0.3911 - val_acc: 0.7500\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4536 - acc: 0.600 - 0s 835us/step - loss: 0.4653 - acc: 0.6296 - val_loss: 0.3792 - val_acc: 0.7500\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4755 - acc: 0.600 - 0s 416us/step - loss: 0.4646 - acc: 0.6296 - val_loss: 0.3711 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4853 - acc: 0.650 - 0s 495us/step - loss: 0.4641 - acc: 0.6296 - val_loss: 0.3680 - val_acc: 0.7500\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3863 - acc: 0.600 - 0s 483us/step - loss: 0.4636 - acc: 0.6296 - val_loss: 0.3682 - val_acc: 0.5000\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4397 - acc: 0.650 - 0s 448us/step - loss: 0.4630 - acc: 0.6296 - val_loss: 0.3648 - val_acc: 0.5000\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4518 - acc: 0.600 - 0s 935us/step - loss: 0.4631 - acc: 0.6296 - val_loss: 0.3670 - val_acc: 0.5000\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4875 - acc: 0.650 - 0s 893us/step - loss: 0.4627 - acc: 0.6296 - val_loss: 0.3740 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4820 - acc: 0.700 - 0s 1ms/step - loss: 0.4624 - acc: 0.6296 - val_loss: 0.3783 - val_acc: 0.5000\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4318 - acc: 0.650 - 0s 721us/step - loss: 0.4626 - acc: 0.6296 - val_loss: 0.3782 - val_acc: 0.5000\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4680 - acc: 0.700 - 0s 817us/step - loss: 0.4617 - acc: 0.6296 - val_loss: 0.3678 - val_acc: 0.5000\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4804 - acc: 0.550 - 0s 847us/step - loss: 0.4630 - acc: 0.6296 - val_loss: 0.3663 - val_acc: 0.5000\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4664 - acc: 0.650 - 0s 708us/step - loss: 0.4621 - acc: 0.6296 - val_loss: 0.3795 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2543c8cd668>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the MinMax model\n",
    "MinMax_model = Sequential()\n",
    "MinMax_model.add(Dense(24, input_dim=2, activation='relu'))\n",
    "MinMax_model.add(Dense(84, activation='relu'))\n",
    "MinMax_model.add(Dense(84, activation='relu'))\n",
    "MinMax_model.add(Dense(8, activation='relu'))\n",
    "MinMax_model.add(Dense(3, activation='linear'))\n",
    "MinMax_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "MinMax_model.fit(train_features_MinMax,\n",
    "                 train_labels_MinMax,\n",
    "                 validation_data=(test_features_MinMax, test_labels_MinMax),\n",
    "                 batch_size=20,\n",
    "                 epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "round_epochs                                                   100\n",
       "val_loss                                                   0.53435\n",
       "val_acc                                                          1\n",
       "loss                                                       0.44738\n",
       "acc                                                       0.666667\n",
       "activation                 <function linear at 0x000002540B253F28>\n",
       "batch_size                                                      20\n",
       "first_neuron                                                    24\n",
       "fourth_neuron                                                   12\n",
       "loss.1           <function mean_squared_error at 0x000002540B22...\n",
       "optimizer                                                     Adam\n",
       "second_neuron                                                   84\n",
       "third_neuron                                                    84\n",
       "Name: 26, dtype: object"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Standard.csv')\n",
    "df.loc[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 4 samples\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 1.0344 - acc: 0.300 - 2s 86ms/step - loss: 1.0306 - acc: 0.3333 - val_loss: 0.9941 - val_acc: 0.7500\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.9641 - acc: 0.600 - 0s 658us/step - loss: 0.9926 - acc: 0.6296 - val_loss: 0.9782 - val_acc: 0.7500\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.9169 - acc: 0.650 - 0s 447us/step - loss: 0.9711 - acc: 0.6667 - val_loss: 0.9650 - val_acc: 0.7500\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.9965 - acc: 0.700 - 0s 1ms/step - loss: 0.9582 - acc: 0.6296 - val_loss: 0.9601 - val_acc: 0.7500\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8830 - acc: 0.700 - 0s 488us/step - loss: 0.9473 - acc: 0.6667 - val_loss: 0.9634 - val_acc: 0.7500\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.9165 - acc: 0.750 - 0s 547us/step - loss: 0.9339 - acc: 0.7037 - val_loss: 0.9666 - val_acc: 0.7500\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.9359 - acc: 0.700 - 0s 433us/step - loss: 0.9201 - acc: 0.6667 - val_loss: 0.9756 - val_acc: 0.7500\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.9576 - acc: 0.600 - 0s 590us/step - loss: 0.9055 - acc: 0.6667 - val_loss: 0.9817 - val_acc: 0.7500\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8218 - acc: 0.750 - 0s 502us/step - loss: 0.8963 - acc: 0.6667 - val_loss: 0.9854 - val_acc: 0.7500\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.9561 - acc: 0.650 - 0s 430us/step - loss: 0.8827 - acc: 0.6667 - val_loss: 0.9907 - val_acc: 0.7500\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7949 - acc: 0.700 - 0s 529us/step - loss: 0.8765 - acc: 0.6667 - val_loss: 0.9985 - val_acc: 0.7500\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7913 - acc: 0.600 - 0s 449us/step - loss: 0.8705 - acc: 0.5926 - val_loss: 1.0037 - val_acc: 0.7500\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8957 - acc: 0.550 - 0s 526us/step - loss: 0.8635 - acc: 0.5926 - val_loss: 1.0096 - val_acc: 0.7500\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7908 - acc: 0.600 - 0s 826us/step - loss: 0.8589 - acc: 0.6296 - val_loss: 1.0158 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8346 - acc: 0.550 - 0s 730us/step - loss: 0.8539 - acc: 0.6296 - val_loss: 1.0190 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.9254 - acc: 0.550 - 0s 1ms/step - loss: 0.8507 - acc: 0.6296 - val_loss: 1.0205 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7406 - acc: 0.700 - 0s 948us/step - loss: 0.8473 - acc: 0.6296 - val_loss: 1.0198 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8454 - acc: 0.600 - 0s 1ms/step - loss: 0.8431 - acc: 0.6296 - val_loss: 1.0125 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8026 - acc: 0.650 - 0s 959us/step - loss: 0.8375 - acc: 0.6296 - val_loss: 1.0027 - val_acc: 0.7500\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8489 - acc: 0.650 - 0s 1ms/step - loss: 0.8319 - acc: 0.5926 - val_loss: 0.9933 - val_acc: 0.7500\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.9499 - acc: 0.450 - 0s 644us/step - loss: 0.8268 - acc: 0.5926 - val_loss: 0.9840 - val_acc: 0.7500\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8525 - acc: 0.700 - 0s 962us/step - loss: 0.8216 - acc: 0.6296 - val_loss: 0.9755 - val_acc: 0.7500\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7742 - acc: 0.650 - 0s 1ms/step - loss: 0.8159 - acc: 0.6296 - val_loss: 0.9668 - val_acc: 0.7500\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8394 - acc: 0.600 - 0s 698us/step - loss: 0.8113 - acc: 0.6296 - val_loss: 0.9578 - val_acc: 0.7500\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7411 - acc: 0.600 - 0s 972us/step - loss: 0.8054 - acc: 0.6296 - val_loss: 0.9544 - val_acc: 0.7500\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8024 - acc: 0.650 - 0s 756us/step - loss: 0.8011 - acc: 0.6296 - val_loss: 0.9601 - val_acc: 0.7500\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7930 - acc: 0.550 - 0s 662us/step - loss: 0.7948 - acc: 0.6296 - val_loss: 0.9713 - val_acc: 0.7500\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8213 - acc: 0.600 - 0s 616us/step - loss: 0.7882 - acc: 0.6296 - val_loss: 0.9739 - val_acc: 0.7500\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7835 - acc: 0.650 - 0s 582us/step - loss: 0.7819 - acc: 0.6296 - val_loss: 0.9737 - val_acc: 0.7500\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7599 - acc: 0.550 - 0s 630us/step - loss: 0.7756 - acc: 0.6296 - val_loss: 0.9794 - val_acc: 0.7500\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7960 - acc: 0.550 - 0s 1ms/step - loss: 0.7694 - acc: 0.6296 - val_loss: 0.9892 - val_acc: 0.7500\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7482 - acc: 0.650 - 0s 651us/step - loss: 0.7636 - acc: 0.6296 - val_loss: 0.9993 - val_acc: 0.7500\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7713 - acc: 0.550 - 0s 1ms/step - loss: 0.7570 - acc: 0.6296 - val_loss: 1.0088 - val_acc: 0.7500\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7344 - acc: 0.550 - 0s 1ms/step - loss: 0.7496 - acc: 0.6296 - val_loss: 1.0090 - val_acc: 0.7500\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.8498 - acc: 0.650 - 0s 1ms/step - loss: 0.7422 - acc: 0.6667 - val_loss: 1.0024 - val_acc: 0.7500\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6767 - acc: 0.650 - 0s 863us/step - loss: 0.7351 - acc: 0.6296 - val_loss: 0.9961 - val_acc: 0.7500\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7698 - acc: 0.650 - 0s 827us/step - loss: 0.7269 - acc: 0.6296 - val_loss: 0.9895 - val_acc: 0.7500\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7066 - acc: 0.650 - 0s 815us/step - loss: 0.7167 - acc: 0.6296 - val_loss: 0.9839 - val_acc: 0.7500\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6869 - acc: 0.500 - 0s 932us/step - loss: 0.7079 - acc: 0.5926 - val_loss: 0.9762 - val_acc: 0.7500\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7104 - acc: 0.550 - 0s 839us/step - loss: 0.6959 - acc: 0.6296 - val_loss: 0.9743 - val_acc: 0.7500\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6917 - acc: 0.600 - 0s 696us/step - loss: 0.6901 - acc: 0.5926 - val_loss: 0.9803 - val_acc: 0.7500\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6589 - acc: 0.600 - 0s 855us/step - loss: 0.6921 - acc: 0.5926 - val_loss: 0.9779 - val_acc: 0.7500\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7495 - acc: 0.650 - 0s 834us/step - loss: 0.6881 - acc: 0.6296 - val_loss: 0.9608 - val_acc: 0.7500\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6947 - acc: 0.600 - 0s 891us/step - loss: 0.6859 - acc: 0.6296 - val_loss: 0.9411 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6706 - acc: 0.600 - 0s 976us/step - loss: 0.6833 - acc: 0.6296 - val_loss: 0.9228 - val_acc: 0.7500\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6514 - acc: 0.550 - 0s 830us/step - loss: 0.6801 - acc: 0.6296 - val_loss: 0.9127 - val_acc: 0.7500\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7608 - acc: 0.650 - 0s 1ms/step - loss: 0.6789 - acc: 0.6296 - val_loss: 0.9101 - val_acc: 0.7500\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6937 - acc: 0.700 - 0s 824us/step - loss: 0.6786 - acc: 0.6296 - val_loss: 0.9067 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7320 - acc: 0.600 - 0s 1ms/step - loss: 0.6786 - acc: 0.6667 - val_loss: 0.9076 - val_acc: 0.7500\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.750 - 0s 725us/step - loss: 0.6775 - acc: 0.6667 - val_loss: 0.9136 - val_acc: 0.7500\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6754 - acc: 0.700 - 0s 988us/step - loss: 0.6760 - acc: 0.7037 - val_loss: 0.9198 - val_acc: 0.7500\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6737 - acc: 0.800 - 0s 605us/step - loss: 0.6760 - acc: 0.7037 - val_loss: 0.9247 - val_acc: 0.7500\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6269 - acc: 0.700 - 0s 635us/step - loss: 0.6751 - acc: 0.7037 - val_loss: 0.9251 - val_acc: 0.7500\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6448 - acc: 0.700 - 0s 674us/step - loss: 0.6735 - acc: 0.7037 - val_loss: 0.9208 - val_acc: 0.7500\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6945 - acc: 0.750 - 0s 886us/step - loss: 0.6748 - acc: 0.7037 - val_loss: 0.9186 - val_acc: 0.7500\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7748 - acc: 0.700 - 0s 760us/step - loss: 0.6753 - acc: 0.7037 - val_loss: 0.9217 - val_acc: 0.7500\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6725 - acc: 0.700 - 0s 1ms/step - loss: 0.6756 - acc: 0.7037 - val_loss: 0.9253 - val_acc: 0.7500\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6338 - acc: 0.700 - 0s 908us/step - loss: 0.6756 - acc: 0.7037 - val_loss: 0.9285 - val_acc: 0.7500\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7171 - acc: 0.600 - 0s 672us/step - loss: 0.6737 - acc: 0.7037 - val_loss: 0.9291 - val_acc: 0.7500\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7365 - acc: 0.750 - 0s 777us/step - loss: 0.6716 - acc: 0.7037 - val_loss: 0.9324 - val_acc: 0.7500\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7105 - acc: 0.650 - 0s 821us/step - loss: 0.6708 - acc: 0.7037 - val_loss: 0.9330 - val_acc: 0.7500\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6563 - acc: 0.750 - 0s 1ms/step - loss: 0.6717 - acc: 0.7037 - val_loss: 0.9237 - val_acc: 0.7500\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6016 - acc: 0.750 - 0s 777us/step - loss: 0.6730 - acc: 0.7037 - val_loss: 0.9245 - val_acc: 0.7500\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7149 - acc: 0.700 - 0s 614us/step - loss: 0.6702 - acc: 0.7037 - val_loss: 0.9219 - val_acc: 0.7500\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7309 - acc: 0.700 - 0s 701us/step - loss: 0.6691 - acc: 0.7037 - val_loss: 0.9258 - val_acc: 0.7500\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6583 - acc: 0.800 - 0s 541us/step - loss: 0.6701 - acc: 0.7037 - val_loss: 0.9316 - val_acc: 0.7500\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6736 - acc: 0.700 - 0s 682us/step - loss: 0.6706 - acc: 0.7037 - val_loss: 0.9405 - val_acc: 0.7500\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6983 - acc: 0.700 - 0s 418us/step - loss: 0.6698 - acc: 0.7037 - val_loss: 0.9510 - val_acc: 0.7500\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7173 - acc: 0.650 - 0s 512us/step - loss: 0.6701 - acc: 0.7037 - val_loss: 0.9574 - val_acc: 0.7500\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6503 - acc: 0.750 - 0s 668us/step - loss: 0.6694 - acc: 0.7037 - val_loss: 0.9545 - val_acc: 0.7500\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6552 - acc: 0.650 - 0s 476us/step - loss: 0.6681 - acc: 0.7037 - val_loss: 0.9510 - val_acc: 0.7500\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6970 - acc: 0.650 - 0s 459us/step - loss: 0.6673 - acc: 0.7037 - val_loss: 0.9466 - val_acc: 0.7500\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7073 - acc: 0.700 - 0s 466us/step - loss: 0.6675 - acc: 0.7037 - val_loss: 0.9396 - val_acc: 0.7500\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6994 - acc: 0.700 - 0s 579us/step - loss: 0.6680 - acc: 0.7037 - val_loss: 0.9357 - val_acc: 0.7500\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6580 - acc: 0.650 - 0s 420us/step - loss: 0.6673 - acc: 0.7037 - val_loss: 0.9353 - val_acc: 0.7500\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6937 - acc: 0.700 - 0s 476us/step - loss: 0.6662 - acc: 0.7037 - val_loss: 0.9366 - val_acc: 0.7500\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5388 - acc: 0.750 - 0s 576us/step - loss: 0.6680 - acc: 0.7037 - val_loss: 0.9389 - val_acc: 0.7500\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7060 - acc: 0.650 - 0s 560us/step - loss: 0.6659 - acc: 0.7037 - val_loss: 0.9394 - val_acc: 0.7500\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6130 - acc: 0.700 - 0s 859us/step - loss: 0.6660 - acc: 0.7037 - val_loss: 0.9390 - val_acc: 0.7500\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5984 - acc: 0.700 - 0s 803us/step - loss: 0.6648 - acc: 0.7037 - val_loss: 0.9366 - val_acc: 0.7500\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6703 - acc: 0.700 - 0s 980us/step - loss: 0.6649 - acc: 0.7037 - val_loss: 0.9341 - val_acc: 0.7500\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6410 - acc: 0.650 - 0s 923us/step - loss: 0.6653 - acc: 0.7037 - val_loss: 0.9292 - val_acc: 0.7500\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6829 - acc: 0.650 - 0s 971us/step - loss: 0.6658 - acc: 0.7037 - val_loss: 0.9260 - val_acc: 0.7500\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7189 - acc: 0.600 - 0s 911us/step - loss: 0.6650 - acc: 0.7037 - val_loss: 0.9256 - val_acc: 0.7500\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6012 - acc: 0.800 - 0s 1ms/step - loss: 0.6655 - acc: 0.7037 - val_loss: 0.9291 - val_acc: 0.7500\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6985 - acc: 0.700 - 0s 573us/step - loss: 0.6646 - acc: 0.7037 - val_loss: 0.9317 - val_acc: 0.7500\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7146 - acc: 0.750 - 0s 1ms/step - loss: 0.6637 - acc: 0.7037 - val_loss: 0.9337 - val_acc: 0.7500\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6567 - acc: 0.700 - 0s 981us/step - loss: 0.6644 - acc: 0.7037 - val_loss: 0.9389 - val_acc: 0.7500\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6788 - acc: 0.700 - 0s 921us/step - loss: 0.6643 - acc: 0.7037 - val_loss: 0.9487 - val_acc: 0.7500\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7774 - acc: 0.700 - 0s 867us/step - loss: 0.6635 - acc: 0.7037 - val_loss: 0.9607 - val_acc: 0.7500\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6418 - acc: 0.700 - 0s 905us/step - loss: 0.6640 - acc: 0.7037 - val_loss: 0.9686 - val_acc: 0.7500\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5970 - acc: 0.800 - 0s 885us/step - loss: 0.6624 - acc: 0.7037 - val_loss: 0.9701 - val_acc: 0.7500\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6540 - acc: 0.700 - 0s 981us/step - loss: 0.6622 - acc: 0.7037 - val_loss: 0.9710 - val_acc: 0.7500\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7079 - acc: 0.650 - 0s 882us/step - loss: 0.6619 - acc: 0.7037 - val_loss: 0.9655 - val_acc: 0.7500\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6066 - acc: 0.700 - 0s 1ms/step - loss: 0.6612 - acc: 0.7037 - val_loss: 0.9576 - val_acc: 0.7500\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5835 - acc: 0.850 - 0s 841us/step - loss: 0.6598 - acc: 0.7037 - val_loss: 0.9488 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6757 - acc: 0.700 - 0s 838us/step - loss: 0.6607 - acc: 0.7037 - val_loss: 0.9454 - val_acc: 0.7500\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5824 - acc: 0.750 - 0s 884us/step - loss: 0.6613 - acc: 0.7037 - val_loss: 0.9434 - val_acc: 0.7500\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7126 - acc: 0.700 - 0s 762us/step - loss: 0.6608 - acc: 0.7037 - val_loss: 0.9465 - val_acc: 0.7500\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.7119 - acc: 0.750 - 0s 909us/step - loss: 0.6589 - acc: 0.7037 - val_loss: 0.9579 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2543de90e10>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Standard model\n",
    "Standard_model = Sequential()\n",
    "Standard_model.add(Dense(24, input_dim=2, activation='relu'))\n",
    "Standard_model.add(Dense(84, activation='relu'))\n",
    "Standard_model.add(Dense(84, activation='relu'))\n",
    "Standard_model.add(Dense(12, activation='relu'))\n",
    "Standard_model.add(Dense(3, activation='linear'))\n",
    "Standard_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "Standard_model.fit(train_features_Standard,\n",
    "                   train_labels_Standard,\n",
    "                   validation_data=(test_features_Standard, test_labels_Standard),\n",
    "                   batch_size=20,\n",
    "                   epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax Prediction:\n",
      "\n",
      " [[1100.5513    0.55      0.9   ]]\n",
      "\n",
      "Actual:\n",
      "\n",
      " [[1100.      0.05    0.4 ]]\n"
     ]
    }
   ],
   "source": [
    "# MinMax prediction\n",
    "prediction = MinMax_model.predict(validation_features_MinMax)\n",
    "prediction = MinMax_scaler.inverse_transform(prediction)\n",
    "# compare\n",
    "MinMax_scaler.inverse_transform(validation_labels_MinMax)\n",
    "print('MinMax Prediction:\\n\\n', prediction)\n",
    "print('\\nActual:\\n\\n', MinMax_scaler.inverse_transform(validation_labels_MinMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Prediction:\n",
      "\n",
      " [[1100.2672        0.16419293    0.50217617]]\n",
      "\n",
      "Actual:\n",
      "\n",
      " [[1100.      0.05    0.4 ]]\n"
     ]
    }
   ],
   "source": [
    "# Standard prediction\n",
    "prediction = Standard_model.predict(validation_features_Standard)\n",
    "prediction = Standard_scaler.inverse_transform(prediction)\n",
    "# compare\n",
    "print('Standard Prediction:\\n\\n', prediction)\n",
    "print('\\nActual:\\n\\n', Standard_scaler.inverse_transform(validation_labels_Standard))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
