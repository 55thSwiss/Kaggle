{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sciencedirect.com/science/article/pii/S2211812814005318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x1aa322df278>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dependencies\n",
    "%matplotlib inline\n",
    "#import keras\n",
    "from keras.models import Sequential\n",
    "from keras.activations import *\n",
    "from keras.layers import *\n",
    "from keras.losses import *\n",
    "from keras.optimizers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import talos as ta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# suppres NumPy arrays scientific notation and round decimals to three places\n",
    "np.set_printoptions(suppress=True)\n",
    "np.printoptions(precision=3, suppress=True)\n",
    "\n",
    "#libraries = [np,\n",
    "#             pd,\n",
    "#             sklearn,\n",
    "#             keras,\n",
    "#            ta]\n",
    "#for library in libraries:\n",
    "#    print(library, ' ', library.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "train_data = pd.read_csv('Training_Features_and_Labels.txt', delim_whitespace=True, encoding='ISO-8859-1')\n",
    "train_data.drop(columns=['Sr._No.'], inplace=True)\n",
    "# import validation data\n",
    "test_data = pd.read_csv('Test_Features_and_Labels.txt', delim_whitespace=True, encoding='ISO-8859-1')\n",
    "test_data.drop(columns=['Sr._No.'], inplace=True)\n",
    "# segregate a single row for validation\n",
    "validation_data = test_data.loc[0]\n",
    "test_data = test_data.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      "\n",
      " [[ 306.67    0.36]\n",
      " [ 609.76    0.47]\n",
      " [ 909.28    0.52]\n",
      " [ 582.94    0.8 ]\n",
      " [1158.73    0.9 ]\n",
      " [1727.36    1.1 ]\n",
      " [ 943.34    1.63]\n",
      " [1875.96    1.76]\n",
      " [2797.84    2.17]\n",
      " [ 793.04    0.38]\n",
      " [1577.02    0.48]\n",
      " [2351.92    0.54]\n",
      " [1555.25    0.81]\n",
      " [3092.37    0.82]\n",
      " [4611.35    0.97]\n",
      " [2196.85    1.92]\n",
      " [4366.5     1.91]\n",
      " [6508.93    2.03]\n",
      " [ 875.13    0.29]\n",
      " [1735.95    0.37]\n",
      " [2582.46    0.38]\n",
      " [1745.24    0.82]\n",
      " [3461.88    0.79]\n",
      " [5149.9     1.11]\n",
      " [2549.2     1.75]\n",
      " [5055.49    1.89]\n",
      " [7518.86    1.82]]\n",
      "\n",
      "Training Labels:\n",
      "\n",
      " [[ 280.        0.0508    0.4   ]\n",
      " [ 280.        0.0508    0.8   ]\n",
      " [ 280.        0.0508    1.2   ]\n",
      " [ 280.        0.1016    0.4   ]\n",
      " [ 280.        0.1016    0.8   ]\n",
      " [ 280.        0.1016    1.2   ]\n",
      " [ 280.        0.1524    0.4   ]\n",
      " [ 280.        0.1524    0.8   ]\n",
      " [ 280.        0.1524    1.2   ]\n",
      " [ 710.        0.0508    0.4   ]\n",
      " [ 710.        0.0508    0.8   ]\n",
      " [ 710.        0.0508    1.2   ]\n",
      " [ 710.        0.1016    0.4   ]\n",
      " [ 710.        0.1016    0.8   ]\n",
      " [ 710.        0.1016    1.2   ]\n",
      " [ 710.        0.1524    0.4   ]\n",
      " [ 710.        0.1524    0.8   ]\n",
      " [ 710.        0.1524    1.2   ]\n",
      " [1120.        0.0508    0.4   ]\n",
      " [1120.        0.0508    0.8   ]\n",
      " [1120.        0.0508    1.2   ]\n",
      " [1120.        0.1016    0.4   ]\n",
      " [1120.        0.1016    0.8   ]\n",
      " [1120.        0.1016    1.2   ]\n",
      " [1120.        0.1524    0.4   ]\n",
      " [1120.        0.1524    0.8   ]\n",
      " [1120.        0.1524    1.2   ]]\n"
     ]
    }
   ],
   "source": [
    "# create NumPy arrays of training features and labels\n",
    "train_features = train_data[['MRR(mm3/min)', 'Ra(µm)']].values\n",
    "train_labels = train_data[['Spindle_speed(rpm)', 'Feed_rate(mm/rev)', 'Depth_of_cut(mm)']].values\n",
    "print('Training Features:\\n\\n', train_features)\n",
    "print('\\nTraining Labels:\\n\\n', train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Features:\n",
      "\n",
      " [[2020.44    0.29]\n",
      " [6054.12    1.87]\n",
      " [5329.21    1.54]\n",
      " [5197.29    1.45]]\n",
      "\n",
      "Testing Labels:\n",
      "\n",
      " [[1100.      0.05    0.69]\n",
      " [1095.      0.15    1.2 ]\n",
      " [1097.      0.13    1.14]\n",
      " [1094.      0.12    1.15]]\n"
     ]
    }
   ],
   "source": [
    "# create NumPy arrays of validation features and labels\n",
    "test_features = test_data[['MRR(mm3/min)', 'Ra(µm)']].values\n",
    "test_labels = test_data[['Spindle_speed(rpm)', 'Feed_rate(mm/rev)', 'Depth_of_cut(mm)']].values\n",
    "print('Testing Features:\\n\\n', test_features)\n",
    "print('\\nTesting Labels:\\n\\n', test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Features:\n",
      "\n",
      " [[1106.51    0.21]]\n",
      "\n",
      "Validation Labels:\n",
      "\n",
      " [[1100.      0.05    0.4 ]]\n"
     ]
    }
   ],
   "source": [
    "# create NumPy array for validation data\n",
    "validation_features = validation_data[['MRR(mm3/min)', 'Ra(µm)']].values\n",
    "validation_labels = validation_data[['Spindle_speed(rpm)', 'Feed_rate(mm/rev)', 'Depth_of_cut(mm)']].values\n",
    "\n",
    "# reshape the validation data because it's only one row\n",
    "validation_features = validation_features.reshape(1, -1)\n",
    "validation_labels = validation_labels.reshape(1, -1)\n",
    "\n",
    "print('Validation Features:\\n\\n', validation_features)\n",
    "print('\\nValidation Labels:\\n\\n', validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms features by scaling each feature to a given range, -1 and 1 in this case\n",
    "MinMax_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_features_MinMax = MinMax_scaler.fit_transform(train_features)\n",
    "train_labels_MinMax = MinMax_scaler.fit_transform(train_labels)\n",
    "test_features_MinMax = MinMax_scaler.fit_transform(test_features)\n",
    "test_labels_MinMax = MinMax_scaler.fit_transform(test_labels)\n",
    "validation_features_MinMax = MinMax_scaler.fit_transform(validation_features)\n",
    "validation_labels_MinMax = MinMax_scaler.fit_transform(validation_labels)\n",
    "\n",
    "#MinMax_scaler.inverse_transform(validation_labels_MinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "Standard_scaler = StandardScaler()\n",
    "train_features_Standard = Standard_scaler.fit_transform(train_features)\n",
    "train_labels_Standard = Standard_scaler.fit_transform(train_labels)\n",
    "test_features_Standard = Standard_scaler.fit_transform(test_features)\n",
    "test_labels_Standard = Standard_scaler.fit_transform(test_labels)\n",
    "validation_features_Standard = Standard_scaler.fit_transform(validation_features)\n",
    "validation_labels_Standard = Standard_scaler.fit_transform(validation_labels)\n",
    "\n",
    "# Standard_scaler.inverse_transform(train_features_Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron': [8, 12, 24],\n",
    "    'second_neuron': [36, 48, 62, 84],\n",
    "    'third_neuron': [36, 48, 62, 84],\n",
    "    'fourth_neuron': [8, 12, 24],\n",
    "    'batch_size': [10, 20, 30],\n",
    "    'activation': [relu,\n",
    "                   #softmax,\n",
    "                   #selu,\n",
    "                   #softplus,\n",
    "                   #softsign,\n",
    "                   #tanh,\n",
    "                   #sigmoid,\n",
    "                   #hard_sigmoid,\n",
    "                   #exponential,\n",
    "                   linear],\n",
    "    'optimizer' : [#'SGD',\n",
    "                   #'RMSprop',\n",
    "                   #'Adagrad',\n",
    "                   #'Adadelta',\n",
    "                   'Adam',],\n",
    "                   #'Adamax',\n",
    "                   #'Nadam',],\n",
    "    'loss' : [mean_squared_error,]\n",
    "              #mean_absolute_error,] \n",
    "              #mean_absolute_percentage_error, \n",
    "              #mean_squared_logarithmic_error,\n",
    "              #squared_hinge,hinge,\n",
    "              #categorical_hinge,\n",
    "              #logcosh,],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMax_ann(train_features, train_labels, test_features, test_labels, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=2, activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['third_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['fourth_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(3, activation='linear'))\n",
    "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(train_features_MinMax, train_labels_MinMax,\n",
    "                    epochs=100,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[test_features_MinMax, test_labels_MinMax])\n",
    "    \n",
    "    # model output\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standard_ann(train_features, train_labels, test_features, test_labels, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=2, activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['third_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['fourth_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(3, activation='linear'))\n",
    "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(train_features_Standard, train_labels_Standard,\n",
    "                    epochs=100,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[test_features_Standard, test_labels_Standard])\n",
    "    \n",
    "    # model output\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_MinMax = np.concatenate((train_features_MinMax, test_features_MinMax), axis=0)\n",
    "labels_MinMax = np.concatenate((train_labels_MinMax, test_labels_MinMax), axis=0)\n",
    "\n",
    "features_Standard = np.concatenate((train_features_Standard, test_features_Standard), axis=0)\n",
    "labels_Standard = np.concatenate((train_labels_Standard, test_labels_Standard), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the Talos experiment on MinMax data\n",
    "MinMax_t = ta.Scan(features_MinMax, labels_MinMax, \n",
    "            params=p, \n",
    "            model=MinMax_ann,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run the Talos experiment on Standard data\n",
    "Standard_t = ta.Scan(features_Standard, labels_Standard, \n",
    "            params=p, \n",
    "            model=Standard_ann,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>fourth_neuron</th>\n",
       "      <th>loss.1</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>second_neuron</th>\n",
       "      <th>third_neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.261867</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.275643</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>&lt;function relu at 0x000001AA17107D08&gt;</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.277996</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.264963</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>&lt;function relu at 0x000001AA17107D08&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>36</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.302887</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.452316</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>&lt;function relu at 0x000001AA17107D08&gt;</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs  val_loss  val_acc      loss       acc  \\\n",
       "0           100  0.261867     0.75  0.275643  0.481481   \n",
       "1           100  0.277996     1.00  0.264963  0.518519   \n",
       "2           100  0.302887     0.25  0.452316  0.555556   \n",
       "\n",
       "                              activation  batch_size  first_neuron  \\\n",
       "0  <function relu at 0x000001AA17107D08>          30            24   \n",
       "1  <function relu at 0x000001AA17107D08>          10             8   \n",
       "2  <function relu at 0x000001AA17107D08>          30            12   \n",
       "\n",
       "   fourth_neuron                                             loss.1 optimizer  \\\n",
       "0              8  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "1              8  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "2              8  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "\n",
       "   second_neuron  third_neuron  \n",
       "0             48            48  \n",
       "1             36            84  \n",
       "2             48            48  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MinMax.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 4 samples\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 1s 35ms/step - loss: 0.6807 - acc: 0.2222 - val_loss: 0.8086 - val_acc: 0.5000\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6724 - acc: 0.2222 - val_loss: 0.7912 - val_acc: 0.5000\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.6633 - acc: 0.2222 - val_loss: 0.7727 - val_acc: 0.5000\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6534 - acc: 0.2222 - val_loss: 0.7580 - val_acc: 0.5000\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.6449 - acc: 0.2222 - val_loss: 0.7486 - val_acc: 0.5000\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.6381 - acc: 0.2222 - val_loss: 0.7411 - val_acc: 0.5000\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6321 - acc: 0.2593 - val_loss: 0.7345 - val_acc: 0.5000\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.6263 - acc: 0.2963 - val_loss: 0.7286 - val_acc: 0.5000\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6211 - acc: 0.2963 - val_loss: 0.7234 - val_acc: 0.5000\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6162 - acc: 0.2963 - val_loss: 0.7198 - val_acc: 0.5000\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6116 - acc: 0.2593 - val_loss: 0.7179 - val_acc: 0.5000\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6072 - acc: 0.2963 - val_loss: 0.7175 - val_acc: 0.5000\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.6031 - acc: 0.2963 - val_loss: 0.7176 - val_acc: 0.5000\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5989 - acc: 0.2963 - val_loss: 0.7170 - val_acc: 0.5000\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5951 - acc: 0.2963 - val_loss: 0.7161 - val_acc: 0.2500\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5918 - acc: 0.3333 - val_loss: 0.7159 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5891 - acc: 0.3333 - val_loss: 0.7154 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5870 - acc: 0.3333 - val_loss: 0.7145 - val_acc: 0.2500\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5852 - acc: 0.3704 - val_loss: 0.7133 - val_acc: 0.2500\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5834 - acc: 0.3704 - val_loss: 0.7120 - val_acc: 0.2500\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5815 - acc: 0.4074 - val_loss: 0.7105 - val_acc: 0.2500\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5798 - acc: 0.4074 - val_loss: 0.7101 - val_acc: 0.2500\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5781 - acc: 0.4074 - val_loss: 0.7100 - val_acc: 0.2500\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5766 - acc: 0.4074 - val_loss: 0.7099 - val_acc: 0.2500\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5752 - acc: 0.4074 - val_loss: 0.7096 - val_acc: 0.2500\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5737 - acc: 0.4074 - val_loss: 0.7088 - val_acc: 0.2500\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5723 - acc: 0.4074 - val_loss: 0.7079 - val_acc: 0.2500\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5708 - acc: 0.4074 - val_loss: 0.7068 - val_acc: 0.2500\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5694 - acc: 0.4074 - val_loss: 0.7057 - val_acc: 0.2500\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5679 - acc: 0.4074 - val_loss: 0.7047 - val_acc: 0.2500\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5664 - acc: 0.4074 - val_loss: 0.7038 - val_acc: 0.2500\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5648 - acc: 0.4074 - val_loss: 0.7031 - val_acc: 0.2500\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5631 - acc: 0.4074 - val_loss: 0.7024 - val_acc: 0.2500\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5614 - acc: 0.4074 - val_loss: 0.7013 - val_acc: 0.2500\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5596 - acc: 0.4074 - val_loss: 0.7000 - val_acc: 0.2500\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5578 - acc: 0.4074 - val_loss: 0.6986 - val_acc: 0.2500\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5560 - acc: 0.3704 - val_loss: 0.6974 - val_acc: 0.2500\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5543 - acc: 0.3704 - val_loss: 0.6964 - val_acc: 0.2500\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.5524 - acc: 0.3704 - val_loss: 0.6951 - val_acc: 0.5000\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5504 - acc: 0.3333 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5482 - acc: 0.3333 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5463 - acc: 0.3333 - val_loss: 0.6913 - val_acc: 0.7500\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5443 - acc: 0.3333 - val_loss: 0.6902 - val_acc: 0.7500\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.5421 - acc: 0.3333 - val_loss: 0.6899 - val_acc: 0.7500\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5400 - acc: 0.3333 - val_loss: 0.6903 - val_acc: 0.7500\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5378 - acc: 0.3333 - val_loss: 0.6914 - val_acc: 0.7500\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5353 - acc: 0.3333 - val_loss: 0.6912 - val_acc: 0.7500\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5330 - acc: 0.3333 - val_loss: 0.6896 - val_acc: 0.7500\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5306 - acc: 0.2963 - val_loss: 0.6858 - val_acc: 0.7500\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5281 - acc: 0.2963 - val_loss: 0.6800 - val_acc: 0.7500\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5255 - acc: 0.2963 - val_loss: 0.6732 - val_acc: 0.5000\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5229 - acc: 0.2963 - val_loss: 0.6660 - val_acc: 0.5000\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5203 - acc: 0.2963 - val_loss: 0.6591 - val_acc: 0.5000\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5177 - acc: 0.2963 - val_loss: 0.6531 - val_acc: 0.5000\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5150 - acc: 0.2963 - val_loss: 0.6476 - val_acc: 0.5000\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5123 - acc: 0.2963 - val_loss: 0.6425 - val_acc: 0.5000\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5095 - acc: 0.2963 - val_loss: 0.6374 - val_acc: 0.5000\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5065 - acc: 0.2963 - val_loss: 0.6323 - val_acc: 0.5000\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5036 - acc: 0.2963 - val_loss: 0.6273 - val_acc: 0.5000\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5006 - acc: 0.2963 - val_loss: 0.6214 - val_acc: 0.5000\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4977 - acc: 0.2963 - val_loss: 0.6151 - val_acc: 0.5000\n",
      "Epoch 62/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4948 - acc: 0.2963 - val_loss: 0.6083 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.4917 - acc: 0.2963 - val_loss: 0.6015 - val_acc: 0.5000\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4887 - acc: 0.2963 - val_loss: 0.5947 - val_acc: 0.5000\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4856 - acc: 0.3333 - val_loss: 0.5871 - val_acc: 0.5000\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4826 - acc: 0.3333 - val_loss: 0.5794 - val_acc: 0.5000\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4795 - acc: 0.3333 - val_loss: 0.5717 - val_acc: 0.5000\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.4764 - acc: 0.3333 - val_loss: 0.5644 - val_acc: 0.5000\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4732 - acc: 0.3333 - val_loss: 0.5586 - val_acc: 0.5000\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4700 - acc: 0.3333 - val_loss: 0.5531 - val_acc: 0.5000\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.4668 - acc: 0.3333 - val_loss: 0.5471 - val_acc: 0.5000\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4636 - acc: 0.3333 - val_loss: 0.5417 - val_acc: 0.5000\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4603 - acc: 0.3333 - val_loss: 0.5368 - val_acc: 0.5000\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.4569 - acc: 0.3333 - val_loss: 0.5313 - val_acc: 0.5000\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4537 - acc: 0.3333 - val_loss: 0.5252 - val_acc: 0.5000\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4504 - acc: 0.3333 - val_loss: 0.5185 - val_acc: 0.5000\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4470 - acc: 0.3333 - val_loss: 0.5116 - val_acc: 0.5000\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4437 - acc: 0.3333 - val_loss: 0.5062 - val_acc: 0.5000\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4403 - acc: 0.3333 - val_loss: 0.5022 - val_acc: 0.5000\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4371 - acc: 0.2963 - val_loss: 0.4982 - val_acc: 0.5000\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4337 - acc: 0.2963 - val_loss: 0.4956 - val_acc: 0.5000\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.4302 - acc: 0.2963 - val_loss: 0.4925 - val_acc: 0.5000\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4268 - acc: 0.2963 - val_loss: 0.4902 - val_acc: 0.5000\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4234 - acc: 0.2963 - val_loss: 0.4873 - val_acc: 0.5000\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4200 - acc: 0.2963 - val_loss: 0.4838 - val_acc: 0.5000\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4165 - acc: 0.3333 - val_loss: 0.4816 - val_acc: 0.5000\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4132 - acc: 0.3333 - val_loss: 0.4802 - val_acc: 0.5000\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4098 - acc: 0.3333 - val_loss: 0.4793 - val_acc: 0.5000\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4064 - acc: 0.3333 - val_loss: 0.4775 - val_acc: 0.5000\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4031 - acc: 0.3333 - val_loss: 0.4768 - val_acc: 0.5000\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3997 - acc: 0.2963 - val_loss: 0.4772 - val_acc: 0.5000\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3963 - acc: 0.2963 - val_loss: 0.4777 - val_acc: 0.5000\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3929 - acc: 0.2963 - val_loss: 0.4779 - val_acc: 0.5000\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3897 - acc: 0.2963 - val_loss: 0.4782 - val_acc: 0.5000\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3864 - acc: 0.2963 - val_loss: 0.4785 - val_acc: 0.5000\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3832 - acc: 0.3333 - val_loss: 0.4794 - val_acc: 0.5000\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3798 - acc: 0.3333 - val_loss: 0.4807 - val_acc: 0.5000\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3761 - acc: 0.3333 - val_loss: 0.4777 - val_acc: 0.5000\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3718 - acc: 0.3704 - val_loss: 0.4750 - val_acc: 0.5000\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3670 - acc: 0.3704 - val_loss: 0.4719 - val_acc: 0.5000\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3613 - acc: 0.3704 - val_loss: 0.4692 - val_acc: 0.5000\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3555 - acc: 0.3704 - val_loss: 0.4667 - val_acc: 0.5000\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3497 - acc: 0.3704 - val_loss: 0.4639 - val_acc: 0.5000\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3442 - acc: 0.3704 - val_loss: 0.4609 - val_acc: 0.0000e+00\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3389 - acc: 0.4074 - val_loss: 0.4579 - val_acc: 0.2500\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3336 - acc: 0.4074 - val_loss: 0.4548 - val_acc: 0.2500\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3285 - acc: 0.4074 - val_loss: 0.4526 - val_acc: 0.2500\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3236 - acc: 0.4074 - val_loss: 0.4520 - val_acc: 0.5000\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3188 - acc: 0.4815 - val_loss: 0.4532 - val_acc: 0.5000\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3142 - acc: 0.4444 - val_loss: 0.4553 - val_acc: 0.5000\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3099 - acc: 0.4815 - val_loss: 0.4582 - val_acc: 0.5000\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3060 - acc: 0.4815 - val_loss: 0.4611 - val_acc: 0.5000\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3024 - acc: 0.5185 - val_loss: 0.4615 - val_acc: 0.5000\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2992 - acc: 0.5185 - val_loss: 0.4615 - val_acc: 0.5000\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2963 - acc: 0.5185 - val_loss: 0.4625 - val_acc: 0.5000\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2936 - acc: 0.4815 - val_loss: 0.4641 - val_acc: 0.5000\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2914 - acc: 0.4815 - val_loss: 0.4648 - val_acc: 0.5000\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2892 - acc: 0.4815 - val_loss: 0.4642 - val_acc: 0.5000\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2871 - acc: 0.4815 - val_loss: 0.4653 - val_acc: 0.5000\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2854 - acc: 0.4815 - val_loss: 0.4692 - val_acc: 0.5000\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2836 - acc: 0.4815 - val_loss: 0.4765 - val_acc: 0.5000\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2818 - acc: 0.4815 - val_loss: 0.4862 - val_acc: 0.5000\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2802 - acc: 0.4815 - val_loss: 0.4939 - val_acc: 0.5000\n",
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2786 - acc: 0.4815 - val_loss: 0.4995 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2773 - acc: 0.4815 - val_loss: 0.5023 - val_acc: 0.5000\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2760 - acc: 0.4815 - val_loss: 0.5042 - val_acc: 0.5000\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2748 - acc: 0.4815 - val_loss: 0.5057 - val_acc: 0.5000\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2737 - acc: 0.4815 - val_loss: 0.5078 - val_acc: 0.5000\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2726 - acc: 0.4815 - val_loss: 0.5107 - val_acc: 0.5000\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2717 - acc: 0.4815 - val_loss: 0.5126 - val_acc: 0.5000\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2707 - acc: 0.4815 - val_loss: 0.5135 - val_acc: 0.5000\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2697 - acc: 0.5185 - val_loss: 0.5128 - val_acc: 0.5000\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2686 - acc: 0.5556 - val_loss: 0.5106 - val_acc: 0.5000\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2677 - acc: 0.5556 - val_loss: 0.5089 - val_acc: 0.5000\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2669 - acc: 0.5556 - val_loss: 0.5092 - val_acc: 0.5000\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2659 - acc: 0.5556 - val_loss: 0.5104 - val_acc: 0.5000\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2650 - acc: 0.5556 - val_loss: 0.5110 - val_acc: 0.5000\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2642 - acc: 0.5556 - val_loss: 0.5111 - val_acc: 0.5000\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2633 - acc: 0.5556 - val_loss: 0.5107 - val_acc: 0.5000\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2624 - acc: 0.5556 - val_loss: 0.5120 - val_acc: 0.5000\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2617 - acc: 0.5556 - val_loss: 0.5162 - val_acc: 0.5000\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2609 - acc: 0.5556 - val_loss: 0.5213 - val_acc: 0.5000\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2602 - acc: 0.5556 - val_loss: 0.5252 - val_acc: 0.5000\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2596 - acc: 0.5556 - val_loss: 0.5270 - val_acc: 0.5000\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2590 - acc: 0.5556 - val_loss: 0.5271 - val_acc: 0.5000\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2583 - acc: 0.5556 - val_loss: 0.5255 - val_acc: 0.5000\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2577 - acc: 0.5556 - val_loss: 0.5228 - val_acc: 0.5000\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2571 - acc: 0.5556 - val_loss: 0.5195 - val_acc: 0.5000\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2565 - acc: 0.5556 - val_loss: 0.5178 - val_acc: 0.5000\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2559 - acc: 0.5556 - val_loss: 0.5178 - val_acc: 0.5000\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2553 - acc: 0.5556 - val_loss: 0.5189 - val_acc: 0.5000\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2547 - acc: 0.5556 - val_loss: 0.5214 - val_acc: 0.5000\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2542 - acc: 0.5556 - val_loss: 0.5251 - val_acc: 0.5000\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2535 - acc: 0.5556 - val_loss: 0.5274 - val_acc: 0.5000\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2530 - acc: 0.5926 - val_loss: 0.5278 - val_acc: 0.5000\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2525 - acc: 0.5926 - val_loss: 0.5279 - val_acc: 0.5000\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2519 - acc: 0.5926 - val_loss: 0.5270 - val_acc: 0.5000\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2513 - acc: 0.5926 - val_loss: 0.5257 - val_acc: 0.5000\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2508 - acc: 0.5926 - val_loss: 0.5267 - val_acc: 0.5000\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2503 - acc: 0.5926 - val_loss: 0.5286 - val_acc: 0.5000\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2498 - acc: 0.5926 - val_loss: 0.5305 - val_acc: 0.5000\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2492 - acc: 0.5926 - val_loss: 0.5339 - val_acc: 0.5000\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2486 - acc: 0.5926 - val_loss: 0.5378 - val_acc: 0.5000\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2481 - acc: 0.5926 - val_loss: 0.5416 - val_acc: 0.5000\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2476 - acc: 0.5926 - val_loss: 0.5434 - val_acc: 0.5000\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2471 - acc: 0.5926 - val_loss: 0.5435 - val_acc: 0.5000\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2466 - acc: 0.5926 - val_loss: 0.5441 - val_acc: 0.5000\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2462 - acc: 0.5926 - val_loss: 0.5449 - val_acc: 0.5000\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2458 - acc: 0.5926 - val_loss: 0.5475 - val_acc: 0.5000\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2453 - acc: 0.5926 - val_loss: 0.5497 - val_acc: 0.5000\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2449 - acc: 0.5926 - val_loss: 0.5518 - val_acc: 0.5000\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2444 - acc: 0.5926 - val_loss: 0.5555 - val_acc: 0.5000\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2440 - acc: 0.5926 - val_loss: 0.5581 - val_acc: 0.5000\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2435 - acc: 0.5926 - val_loss: 0.5598 - val_acc: 0.5000\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2431 - acc: 0.5926 - val_loss: 0.5605 - val_acc: 0.5000\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2426 - acc: 0.5926 - val_loss: 0.5612 - val_acc: 0.5000\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2422 - acc: 0.5926 - val_loss: 0.5621 - val_acc: 0.5000\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2417 - acc: 0.5926 - val_loss: 0.5633 - val_acc: 0.5000\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2413 - acc: 0.5926 - val_loss: 0.5659 - val_acc: 0.5000\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2409 - acc: 0.5926 - val_loss: 0.5669 - val_acc: 0.5000\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2405 - acc: 0.5926 - val_loss: 0.5659 - val_acc: 0.5000\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2400 - acc: 0.5926 - val_loss: 0.5645 - val_acc: 0.5000\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2396 - acc: 0.5926 - val_loss: 0.5650 - val_acc: 0.5000\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2391 - acc: 0.5926 - val_loss: 0.5688 - val_acc: 0.5000\n",
      "Epoch 185/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2387 - acc: 0.5926 - val_loss: 0.5718 - val_acc: 0.5000\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2383 - acc: 0.5926 - val_loss: 0.5723 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2378 - acc: 0.5926 - val_loss: 0.5729 - val_acc: 0.5000\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2373 - acc: 0.5926 - val_loss: 0.5758 - val_acc: 0.5000\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2369 - acc: 0.5926 - val_loss: 0.5781 - val_acc: 0.5000\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2365 - acc: 0.5926 - val_loss: 0.5791 - val_acc: 0.5000\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2360 - acc: 0.5926 - val_loss: 0.5784 - val_acc: 0.5000\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2355 - acc: 0.5926 - val_loss: 0.5800 - val_acc: 0.5000\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.2351 - acc: 0.5926 - val_loss: 0.5813 - val_acc: 0.5000\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2346 - acc: 0.5926 - val_loss: 0.5832 - val_acc: 0.5000\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2342 - acc: 0.5926 - val_loss: 0.5856 - val_acc: 0.5000\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2337 - acc: 0.5926 - val_loss: 0.5841 - val_acc: 0.5000\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2333 - acc: 0.5926 - val_loss: 0.5840 - val_acc: 0.5000\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2328 - acc: 0.5926 - val_loss: 0.5842 - val_acc: 0.5000\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2324 - acc: 0.5926 - val_loss: 0.5872 - val_acc: 0.5000\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2319 - acc: 0.5556 - val_loss: 0.5892 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa364e1e80>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the MinMax model\n",
    "MinMax_model = Sequential()\n",
    "MinMax_model.add(Dense(8, input_dim=2, activation='relu'))\n",
    "MinMax_model.add(Dense(48, activation='relu'))\n",
    "MinMax_model.add(Dense(48, activation='relu'))\n",
    "MinMax_model.add(Dense(8, activation='relu'))\n",
    "MinMax_model.add(Dense(3, activation='linear'))\n",
    "MinMax_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "MinMax_model.fit(train_features_MinMax,\n",
    "                 train_labels_MinMax,\n",
    "                 validation_data=(test_features_MinMax, test_labels_MinMax),\n",
    "                 batch_size=30,\n",
    "                 epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>fourth_neuron</th>\n",
       "      <th>loss.1</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>second_neuron</th>\n",
       "      <th>third_neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.386672</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.459910</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>&lt;function relu at 0x000001AA17107D08&gt;</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>48</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.466409</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.401966</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>&lt;function relu at 0x000001AA17107D08&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.511823</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.447284</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>&lt;function linear at 0x000001AA17118048&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs  val_loss  val_acc      loss       acc  \\\n",
       "0           100  0.386672     0.75  0.459910  0.666667   \n",
       "1           100  0.466409     0.75  0.401966  0.777778   \n",
       "2           100  0.511823     0.75  0.447284  0.629630   \n",
       "\n",
       "                                activation  batch_size  first_neuron  \\\n",
       "0    <function relu at 0x000001AA17107D08>          30            24   \n",
       "1    <function relu at 0x000001AA17107D08>          10            12   \n",
       "2  <function linear at 0x000001AA17118048>          20            24   \n",
       "\n",
       "   fourth_neuron                                             loss.1 optimizer  \\\n",
       "0              8  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "1              8  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "2             12  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "\n",
       "   second_neuron  third_neuron  \n",
       "0             48            62  \n",
       "1             84            84  \n",
       "2             36            62  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Standard.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 4 samples\n",
      "Epoch 1/200\n",
      "27/27 [==============================] - 1s 36ms/step - loss: 1.0357 - acc: 0.3704 - val_loss: 0.9832 - val_acc: 0.5000\n",
      "Epoch 2/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 1.0190 - acc: 0.3704 - val_loss: 0.9761 - val_acc: 0.5000\n",
      "Epoch 3/200\n",
      "27/27 [==============================] - 0s 580us/step - loss: 0.9978 - acc: 0.1852 - val_loss: 0.9723 - val_acc: 0.2500\n",
      "Epoch 4/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.9789 - acc: 0.2593 - val_loss: 0.9712 - val_acc: 0.2500\n",
      "Epoch 5/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.9634 - acc: 0.2593 - val_loss: 0.9672 - val_acc: 0.2500\n",
      "Epoch 6/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.9487 - acc: 0.2963 - val_loss: 0.9631 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.9345 - acc: 0.3333 - val_loss: 0.9594 - val_acc: 0.2500\n",
      "Epoch 8/200\n",
      "27/27 [==============================] - 0s 580us/step - loss: 0.9211 - acc: 0.3704 - val_loss: 0.9560 - val_acc: 0.2500\n",
      "Epoch 9/200\n",
      "27/27 [==============================] - 0s 577us/step - loss: 0.9084 - acc: 0.4074 - val_loss: 0.9528 - val_acc: 0.5000\n",
      "Epoch 10/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.8958 - acc: 0.4444 - val_loss: 0.9510 - val_acc: 0.5000\n",
      "Epoch 11/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.8837 - acc: 0.4444 - val_loss: 0.9490 - val_acc: 0.5000\n",
      "Epoch 12/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.8723 - acc: 0.4815 - val_loss: 0.9468 - val_acc: 0.5000\n",
      "Epoch 13/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.8611 - acc: 0.4815 - val_loss: 0.9446 - val_acc: 0.5000\n",
      "Epoch 14/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.8501 - acc: 0.4815 - val_loss: 0.9427 - val_acc: 0.5000\n",
      "Epoch 15/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.8392 - acc: 0.4815 - val_loss: 0.9409 - val_acc: 0.5000\n",
      "Epoch 16/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.8287 - acc: 0.4815 - val_loss: 0.9392 - val_acc: 0.5000\n",
      "Epoch 17/200\n",
      "27/27 [==============================] - 0s 580us/step - loss: 0.8197 - acc: 0.4815 - val_loss: 0.9379 - val_acc: 0.5000\n",
      "Epoch 18/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.8112 - acc: 0.5185 - val_loss: 0.9367 - val_acc: 0.5000\n",
      "Epoch 19/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.8028 - acc: 0.5185 - val_loss: 0.9357 - val_acc: 0.5000\n",
      "Epoch 20/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.7941 - acc: 0.5185 - val_loss: 0.9350 - val_acc: 0.5000\n",
      "Epoch 21/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.7859 - acc: 0.5185 - val_loss: 0.9344 - val_acc: 0.5000\n",
      "Epoch 22/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.7777 - acc: 0.5185 - val_loss: 0.9339 - val_acc: 0.5000\n",
      "Epoch 23/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.7695 - acc: 0.5185 - val_loss: 0.9337 - val_acc: 0.5000\n",
      "Epoch 24/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.7610 - acc: 0.5185 - val_loss: 0.9339 - val_acc: 0.5000\n",
      "Epoch 25/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.7524 - acc: 0.5185 - val_loss: 0.9342 - val_acc: 0.5000\n",
      "Epoch 26/200\n",
      "27/27 [==============================] - 0s 580us/step - loss: 0.7434 - acc: 0.5185 - val_loss: 0.9326 - val_acc: 0.5000\n",
      "Epoch 27/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.7346 - acc: 0.5185 - val_loss: 0.9279 - val_acc: 0.5000\n",
      "Epoch 28/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.7257 - acc: 0.5556 - val_loss: 0.9239 - val_acc: 0.5000\n",
      "Epoch 29/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.7174 - acc: 0.5556 - val_loss: 0.9203 - val_acc: 0.5000\n",
      "Epoch 30/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.7099 - acc: 0.6296 - val_loss: 0.9177 - val_acc: 0.5000\n",
      "Epoch 31/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.7041 - acc: 0.6296 - val_loss: 0.9166 - val_acc: 0.5000\n",
      "Epoch 32/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.6986 - acc: 0.6296 - val_loss: 0.9166 - val_acc: 0.5000\n",
      "Epoch 33/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6928 - acc: 0.6296 - val_loss: 0.9168 - val_acc: 0.5000\n",
      "Epoch 34/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6869 - acc: 0.6296 - val_loss: 0.9172 - val_acc: 0.5000\n",
      "Epoch 35/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6810 - acc: 0.6296 - val_loss: 0.9179 - val_acc: 0.5000\n",
      "Epoch 36/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6752 - acc: 0.6296 - val_loss: 0.9188 - val_acc: 0.5000\n",
      "Epoch 37/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6694 - acc: 0.6296 - val_loss: 0.9197 - val_acc: 0.5000\n",
      "Epoch 38/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6637 - acc: 0.6296 - val_loss: 0.9208 - val_acc: 0.5000\n",
      "Epoch 39/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6581 - acc: 0.6296 - val_loss: 0.9217 - val_acc: 0.5000\n",
      "Epoch 40/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.6527 - acc: 0.6296 - val_loss: 0.9222 - val_acc: 0.5000\n",
      "Epoch 41/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6474 - acc: 0.6296 - val_loss: 0.9223 - val_acc: 0.5000\n",
      "Epoch 42/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.6426 - acc: 0.5926 - val_loss: 0.9214 - val_acc: 0.5000\n",
      "Epoch 43/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6382 - acc: 0.5926 - val_loss: 0.9196 - val_acc: 0.5000\n",
      "Epoch 44/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6338 - acc: 0.5926 - val_loss: 0.9170 - val_acc: 0.5000\n",
      "Epoch 45/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6292 - acc: 0.5926 - val_loss: 0.9137 - val_acc: 0.5000\n",
      "Epoch 46/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6247 - acc: 0.5926 - val_loss: 0.9097 - val_acc: 0.5000\n",
      "Epoch 47/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6203 - acc: 0.5926 - val_loss: 0.9055 - val_acc: 0.5000\n",
      "Epoch 48/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6161 - acc: 0.5926 - val_loss: 0.9017 - val_acc: 0.5000\n",
      "Epoch 49/200\n",
      "27/27 [==============================] - 0s 577us/step - loss: 0.6124 - acc: 0.5926 - val_loss: 0.8984 - val_acc: 0.5000\n",
      "Epoch 50/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6085 - acc: 0.5926 - val_loss: 0.8956 - val_acc: 0.5000\n",
      "Epoch 51/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.6046 - acc: 0.5926 - val_loss: 0.8931 - val_acc: 0.5000\n",
      "Epoch 52/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.6006 - acc: 0.5926 - val_loss: 0.8913 - val_acc: 0.5000\n",
      "Epoch 53/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5964 - acc: 0.5926 - val_loss: 0.8902 - val_acc: 0.5000\n",
      "Epoch 54/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5928 - acc: 0.5926 - val_loss: 0.8890 - val_acc: 0.5000\n",
      "Epoch 55/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5889 - acc: 0.5926 - val_loss: 0.8876 - val_acc: 0.5000\n",
      "Epoch 56/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5850 - acc: 0.5556 - val_loss: 0.8858 - val_acc: 0.5000\n",
      "Epoch 57/200\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5809 - acc: 0.5556 - val_loss: 0.8835 - val_acc: 0.5000\n",
      "Epoch 58/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5768 - acc: 0.5556 - val_loss: 0.8805 - val_acc: 0.5000\n",
      "Epoch 59/200\n",
      "27/27 [==============================] - 0s 577us/step - loss: 0.5727 - acc: 0.5556 - val_loss: 0.8770 - val_acc: 0.5000\n",
      "Epoch 60/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5684 - acc: 0.5926 - val_loss: 0.8732 - val_acc: 0.5000\n",
      "Epoch 61/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5640 - acc: 0.5926 - val_loss: 0.8698 - val_acc: 0.5000\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 0us/step - loss: 0.5601 - acc: 0.5926 - val_loss: 0.8673 - val_acc: 0.5000\n",
      "Epoch 63/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5561 - acc: 0.5926 - val_loss: 0.8659 - val_acc: 0.5000\n",
      "Epoch 64/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5504 - acc: 0.5556 - val_loss: 0.8625 - val_acc: 0.5000\n",
      "Epoch 65/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5430 - acc: 0.5556 - val_loss: 0.8587 - val_acc: 0.5000\n",
      "Epoch 66/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.5349 - acc: 0.5185 - val_loss: 0.8552 - val_acc: 0.5000\n",
      "Epoch 67/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5261 - acc: 0.5556 - val_loss: 0.8519 - val_acc: 0.5000\n",
      "Epoch 68/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.5168 - acc: 0.5556 - val_loss: 0.8483 - val_acc: 0.5000\n",
      "Epoch 69/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.5070 - acc: 0.5185 - val_loss: 0.8443 - val_acc: 0.5000\n",
      "Epoch 70/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4972 - acc: 0.5185 - val_loss: 0.8388 - val_acc: 0.5000\n",
      "Epoch 71/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4874 - acc: 0.5185 - val_loss: 0.8319 - val_acc: 0.5000\n",
      "Epoch 72/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4779 - acc: 0.5185 - val_loss: 0.8239 - val_acc: 0.5000\n",
      "Epoch 73/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.4686 - acc: 0.5556 - val_loss: 0.8154 - val_acc: 0.5000\n",
      "Epoch 74/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4600 - acc: 0.5185 - val_loss: 0.8070 - val_acc: 0.5000\n",
      "Epoch 75/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.4514 - acc: 0.5556 - val_loss: 0.8001 - val_acc: 0.5000\n",
      "Epoch 76/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4442 - acc: 0.5556 - val_loss: 0.7955 - val_acc: 0.5000\n",
      "Epoch 77/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.4375 - acc: 0.5926 - val_loss: 0.7937 - val_acc: 0.5000\n",
      "Epoch 78/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4310 - acc: 0.5926 - val_loss: 0.7949 - val_acc: 0.5000\n",
      "Epoch 79/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.4250 - acc: 0.5926 - val_loss: 0.7977 - val_acc: 0.5000\n",
      "Epoch 80/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4194 - acc: 0.6296 - val_loss: 0.8026 - val_acc: 0.5000\n",
      "Epoch 81/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4144 - acc: 0.6296 - val_loss: 0.8095 - val_acc: 0.5000\n",
      "Epoch 82/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4102 - acc: 0.6296 - val_loss: 0.8176 - val_acc: 0.5000\n",
      "Epoch 83/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4070 - acc: 0.6296 - val_loss: 0.8225 - val_acc: 0.5000\n",
      "Epoch 84/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4045 - acc: 0.6296 - val_loss: 0.8252 - val_acc: 0.5000\n",
      "Epoch 85/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4021 - acc: 0.6296 - val_loss: 0.8262 - val_acc: 0.5000\n",
      "Epoch 86/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.4003 - acc: 0.6296 - val_loss: 0.8285 - val_acc: 0.5000\n",
      "Epoch 87/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3989 - acc: 0.6296 - val_loss: 0.8323 - val_acc: 0.5000\n",
      "Epoch 88/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3977 - acc: 0.6296 - val_loss: 0.8383 - val_acc: 0.5000\n",
      "Epoch 89/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3963 - acc: 0.6296 - val_loss: 0.8456 - val_acc: 0.5000\n",
      "Epoch 90/200\n",
      "27/27 [==============================] - 0s 580us/step - loss: 0.3950 - acc: 0.6296 - val_loss: 0.8538 - val_acc: 0.5000\n",
      "Epoch 91/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3936 - acc: 0.6296 - val_loss: 0.8615 - val_acc: 0.5000\n",
      "Epoch 92/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3923 - acc: 0.6296 - val_loss: 0.8675 - val_acc: 0.5000\n",
      "Epoch 93/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3911 - acc: 0.6296 - val_loss: 0.8702 - val_acc: 0.5000\n",
      "Epoch 94/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3896 - acc: 0.6296 - val_loss: 0.8696 - val_acc: 0.5000\n",
      "Epoch 95/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3880 - acc: 0.6296 - val_loss: 0.8677 - val_acc: 0.5000\n",
      "Epoch 96/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3864 - acc: 0.6296 - val_loss: 0.8657 - val_acc: 0.5000\n",
      "Epoch 97/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3848 - acc: 0.6296 - val_loss: 0.8640 - val_acc: 0.5000\n",
      "Epoch 98/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3832 - acc: 0.6296 - val_loss: 0.8634 - val_acc: 0.5000\n",
      "Epoch 99/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3816 - acc: 0.6296 - val_loss: 0.8637 - val_acc: 0.5000\n",
      "Epoch 100/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3801 - acc: 0.6296 - val_loss: 0.8655 - val_acc: 0.5000\n",
      "Epoch 101/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3787 - acc: 0.6296 - val_loss: 0.8674 - val_acc: 0.5000\n",
      "Epoch 102/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.3774 - acc: 0.6296 - val_loss: 0.8687 - val_acc: 0.5000\n",
      "Epoch 103/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3761 - acc: 0.6296 - val_loss: 0.8690 - val_acc: 0.5000\n",
      "Epoch 104/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3749 - acc: 0.6296 - val_loss: 0.8676 - val_acc: 0.5000\n",
      "Epoch 105/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3737 - acc: 0.6296 - val_loss: 0.8646 - val_acc: 0.5000\n",
      "Epoch 106/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3725 - acc: 0.6296 - val_loss: 0.8613 - val_acc: 0.5000\n",
      "Epoch 107/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3713 - acc: 0.6296 - val_loss: 0.8582 - val_acc: 0.5000\n",
      "Epoch 108/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3702 - acc: 0.6296 - val_loss: 0.8558 - val_acc: 0.5000\n",
      "Epoch 109/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3690 - acc: 0.6296 - val_loss: 0.8547 - val_acc: 0.5000\n",
      "Epoch 110/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3678 - acc: 0.6296 - val_loss: 0.8549 - val_acc: 0.5000\n",
      "Epoch 111/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3666 - acc: 0.6296 - val_loss: 0.8564 - val_acc: 0.5000\n",
      "Epoch 112/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3654 - acc: 0.7037 - val_loss: 0.8575 - val_acc: 0.5000\n",
      "Epoch 113/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3642 - acc: 0.7037 - val_loss: 0.8580 - val_acc: 0.5000\n",
      "Epoch 114/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3631 - acc: 0.7407 - val_loss: 0.8589 - val_acc: 0.5000\n",
      "Epoch 115/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3621 - acc: 0.7407 - val_loss: 0.8600 - val_acc: 0.5000\n",
      "Epoch 116/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3611 - acc: 0.7407 - val_loss: 0.8615 - val_acc: 0.5000\n",
      "Epoch 117/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3603 - acc: 0.7407 - val_loss: 0.8635 - val_acc: 0.5000\n",
      "Epoch 118/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3594 - acc: 0.7407 - val_loss: 0.8659 - val_acc: 0.5000\n",
      "Epoch 119/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3584 - acc: 0.7407 - val_loss: 0.8676 - val_acc: 0.5000\n",
      "Epoch 120/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3575 - acc: 0.7407 - val_loss: 0.8687 - val_acc: 0.5000\n",
      "Epoch 121/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3565 - acc: 0.7407 - val_loss: 0.8710 - val_acc: 0.5000\n",
      "Epoch 122/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3556 - acc: 0.7407 - val_loss: 0.8729 - val_acc: 0.5000\n",
      "Epoch 123/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3545 - acc: 0.7407 - val_loss: 0.8746 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "27/27 [==============================] - 0s 580us/step - loss: 0.3537 - acc: 0.7407 - val_loss: 0.8760 - val_acc: 0.5000\n",
      "Epoch 125/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3528 - acc: 0.7407 - val_loss: 0.8763 - val_acc: 0.5000\n",
      "Epoch 126/200\n",
      "27/27 [==============================] - 0s 577us/step - loss: 0.3519 - acc: 0.7407 - val_loss: 0.8758 - val_acc: 0.5000\n",
      "Epoch 127/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3509 - acc: 0.7407 - val_loss: 0.8763 - val_acc: 0.5000\n",
      "Epoch 128/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3500 - acc: 0.7407 - val_loss: 0.8776 - val_acc: 0.5000\n",
      "Epoch 129/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3491 - acc: 0.7407 - val_loss: 0.8785 - val_acc: 0.5000\n",
      "Epoch 130/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3483 - acc: 0.7407 - val_loss: 0.8807 - val_acc: 0.5000\n",
      "Epoch 131/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3474 - acc: 0.7407 - val_loss: 0.8838 - val_acc: 0.5000\n",
      "Epoch 132/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3465 - acc: 0.7407 - val_loss: 0.8863 - val_acc: 0.5000\n",
      "Epoch 133/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3456 - acc: 0.7407 - val_loss: 0.8879 - val_acc: 0.5000\n",
      "Epoch 134/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3448 - acc: 0.7778 - val_loss: 0.8913 - val_acc: 0.5000\n",
      "Epoch 135/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3439 - acc: 0.7778 - val_loss: 0.8939 - val_acc: 0.5000\n",
      "Epoch 136/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3431 - acc: 0.7778 - val_loss: 0.8962 - val_acc: 0.5000\n",
      "Epoch 137/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3423 - acc: 0.7778 - val_loss: 0.8987 - val_acc: 0.5000\n",
      "Epoch 138/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3416 - acc: 0.7778 - val_loss: 0.9001 - val_acc: 0.5000\n",
      "Epoch 139/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3408 - acc: 0.7778 - val_loss: 0.9010 - val_acc: 0.5000\n",
      "Epoch 140/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3400 - acc: 0.7778 - val_loss: 0.9033 - val_acc: 0.5000\n",
      "Epoch 141/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3392 - acc: 0.7778 - val_loss: 0.9063 - val_acc: 0.5000\n",
      "Epoch 142/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3384 - acc: 0.7778 - val_loss: 0.9096 - val_acc: 0.5000\n",
      "Epoch 143/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3377 - acc: 0.7778 - val_loss: 0.9110 - val_acc: 0.5000\n",
      "Epoch 144/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3369 - acc: 0.7778 - val_loss: 0.9122 - val_acc: 0.5000\n",
      "Epoch 145/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3362 - acc: 0.7778 - val_loss: 0.9139 - val_acc: 0.5000\n",
      "Epoch 146/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3353 - acc: 0.7778 - val_loss: 0.9153 - val_acc: 0.5000\n",
      "Epoch 147/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3345 - acc: 0.7778 - val_loss: 0.9176 - val_acc: 0.5000\n",
      "Epoch 148/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.3337 - acc: 0.7778 - val_loss: 0.9200 - val_acc: 0.5000\n",
      "Epoch 149/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3329 - acc: 0.7778 - val_loss: 0.9233 - val_acc: 0.5000\n",
      "Epoch 150/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3321 - acc: 0.7778 - val_loss: 0.9272 - val_acc: 0.5000\n",
      "Epoch 151/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3313 - acc: 0.7778 - val_loss: 0.9303 - val_acc: 0.5000\n",
      "Epoch 152/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3305 - acc: 0.7778 - val_loss: 0.9340 - val_acc: 0.5000\n",
      "Epoch 153/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3298 - acc: 0.7778 - val_loss: 0.9369 - val_acc: 0.5000\n",
      "Epoch 154/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3291 - acc: 0.7778 - val_loss: 0.9388 - val_acc: 0.5000\n",
      "Epoch 155/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3284 - acc: 0.7778 - val_loss: 0.9403 - val_acc: 0.5000\n",
      "Epoch 156/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3276 - acc: 0.7778 - val_loss: 0.9416 - val_acc: 0.5000\n",
      "Epoch 157/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.3269 - acc: 0.7778 - val_loss: 0.9418 - val_acc: 0.5000\n",
      "Epoch 158/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3261 - acc: 0.7778 - val_loss: 0.9430 - val_acc: 0.5000\n",
      "Epoch 159/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3254 - acc: 0.7778 - val_loss: 0.9448 - val_acc: 0.5000\n",
      "Epoch 160/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3246 - acc: 0.7778 - val_loss: 0.9469 - val_acc: 0.5000\n",
      "Epoch 161/200\n",
      "27/27 [==============================] - 0s 580us/step - loss: 0.3239 - acc: 0.7778 - val_loss: 0.9492 - val_acc: 0.5000\n",
      "Epoch 162/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3232 - acc: 0.7778 - val_loss: 0.9494 - val_acc: 0.5000\n",
      "Epoch 163/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3225 - acc: 0.7778 - val_loss: 0.9494 - val_acc: 0.5000\n",
      "Epoch 164/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3217 - acc: 0.7778 - val_loss: 0.9521 - val_acc: 0.5000\n",
      "Epoch 165/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3209 - acc: 0.7778 - val_loss: 0.9548 - val_acc: 0.5000\n",
      "Epoch 166/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3201 - acc: 0.7778 - val_loss: 0.9566 - val_acc: 0.5000\n",
      "Epoch 167/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3193 - acc: 0.7778 - val_loss: 0.9554 - val_acc: 0.5000\n",
      "Epoch 168/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3185 - acc: 0.7778 - val_loss: 0.9545 - val_acc: 0.5000\n",
      "Epoch 169/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3176 - acc: 0.7778 - val_loss: 0.9554 - val_acc: 0.5000\n",
      "Epoch 170/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.3168 - acc: 0.7778 - val_loss: 0.9584 - val_acc: 0.5000\n",
      "Epoch 171/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3161 - acc: 0.7778 - val_loss: 0.9624 - val_acc: 0.5000\n",
      "Epoch 172/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3154 - acc: 0.7778 - val_loss: 0.9664 - val_acc: 0.5000\n",
      "Epoch 173/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3147 - acc: 0.7778 - val_loss: 0.9706 - val_acc: 0.5000\n",
      "Epoch 174/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3141 - acc: 0.7778 - val_loss: 0.9706 - val_acc: 0.5000\n",
      "Epoch 175/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3134 - acc: 0.7778 - val_loss: 0.9689 - val_acc: 0.5000\n",
      "Epoch 176/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3126 - acc: 0.7778 - val_loss: 0.9672 - val_acc: 0.5000\n",
      "Epoch 177/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3119 - acc: 0.7778 - val_loss: 0.9674 - val_acc: 0.5000\n",
      "Epoch 178/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3111 - acc: 0.7778 - val_loss: 0.9703 - val_acc: 0.5000\n",
      "Epoch 179/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3103 - acc: 0.7778 - val_loss: 0.9749 - val_acc: 0.5000\n",
      "Epoch 180/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3094 - acc: 0.7778 - val_loss: 0.9797 - val_acc: 0.5000\n",
      "Epoch 181/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3086 - acc: 0.7778 - val_loss: 0.9835 - val_acc: 0.5000\n",
      "Epoch 182/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3078 - acc: 0.7778 - val_loss: 0.9850 - val_acc: 0.5000\n",
      "Epoch 183/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3070 - acc: 0.7778 - val_loss: 0.9839 - val_acc: 0.5000\n",
      "Epoch 184/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3061 - acc: 0.7778 - val_loss: 0.9831 - val_acc: 0.5000\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 0us/step - loss: 0.3054 - acc: 0.7778 - val_loss: 0.9836 - val_acc: 0.5000\n",
      "Epoch 186/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.3046 - acc: 0.7778 - val_loss: 0.9861 - val_acc: 0.5000\n",
      "Epoch 187/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3038 - acc: 0.7778 - val_loss: 0.9903 - val_acc: 0.5000\n",
      "Epoch 188/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3030 - acc: 0.7778 - val_loss: 0.9948 - val_acc: 0.5000\n",
      "Epoch 189/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3021 - acc: 0.7778 - val_loss: 0.9996 - val_acc: 0.5000\n",
      "Epoch 190/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.3012 - acc: 0.7778 - val_loss: 1.0016 - val_acc: 0.5000\n",
      "Epoch 191/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.3003 - acc: 0.7778 - val_loss: 1.0020 - val_acc: 0.5000\n",
      "Epoch 192/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2993 - acc: 0.7778 - val_loss: 1.0033 - val_acc: 0.5000\n",
      "Epoch 193/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2984 - acc: 0.7778 - val_loss: 1.0039 - val_acc: 0.5000\n",
      "Epoch 194/200\n",
      "27/27 [==============================] - 0s 579us/step - loss: 0.2973 - acc: 0.7778 - val_loss: 1.0048 - val_acc: 0.5000\n",
      "Epoch 195/200\n",
      "27/27 [==============================] - 0s 580us/step - loss: 0.2962 - acc: 0.7778 - val_loss: 1.0071 - val_acc: 0.5000\n",
      "Epoch 196/200\n",
      "27/27 [==============================] - 0s 578us/step - loss: 0.2951 - acc: 0.7778 - val_loss: 1.0101 - val_acc: 0.5000\n",
      "Epoch 197/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2942 - acc: 0.8148 - val_loss: 1.0120 - val_acc: 0.5000\n",
      "Epoch 198/200\n",
      "27/27 [==============================] - 0s 577us/step - loss: 0.2931 - acc: 0.8148 - val_loss: 1.0151 - val_acc: 0.5000\n",
      "Epoch 199/200\n",
      "27/27 [==============================] - 0s 0us/step - loss: 0.2920 - acc: 0.8148 - val_loss: 1.0159 - val_acc: 0.5000\n",
      "Epoch 200/200\n",
      "27/27 [==============================] - 0s 622us/step - loss: 0.2910 - acc: 0.8519 - val_loss: 1.0223 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa37a9c710>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Standard model\n",
    "Standard_model = Sequential()\n",
    "Standard_model.add(Dense(24, input_dim=2, activation='relu'))\n",
    "Standard_model.add(Dense(48, activation='relu'))\n",
    "Standard_model.add(Dense(62, activation='relu'))\n",
    "Standard_model.add(Dense(8, activation='relu'))\n",
    "Standard_model.add(Dense(3, activation='linear'))\n",
    "Standard_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "Standard_model.fit(train_features_Standard,\n",
    "                   train_labels_Standard,\n",
    "                   validation_data=(test_features_Standard, test_labels_Standard),\n",
    "                   batch_size=30,\n",
    "                   epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax Prediction:\n",
      "\n",
      " [[1100.2433      -0.0981545    0.6096643]]\n",
      "\n",
      "Actual:\n",
      "\n",
      " [[1100.      0.05    0.4 ]]\n"
     ]
    }
   ],
   "source": [
    "# MinMax prediction\n",
    "prediction = MinMax_model.predict(validation_features_MinMax)\n",
    "prediction = MinMax_scaler.inverse_transform(prediction)\n",
    "# compare\n",
    "MinMax_scaler.inverse_transform(validation_labels_MinMax)\n",
    "print('MinMax Prediction:\\n\\n', prediction)\n",
    "print('\\nActual:\\n\\n', MinMax_scaler.inverse_transform(validation_labels_MinMax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Prediction:\n",
      "\n",
      " [[1100.2274        0.21553291    0.4820621 ]]\n",
      "\n",
      "Actual:\n",
      "\n",
      " [[1100.      0.05    0.4 ]]\n"
     ]
    }
   ],
   "source": [
    "# Standard prediction\n",
    "prediction = Standard_model.predict(validation_features_Standard)\n",
    "prediction = Standard_scaler.inverse_transform(prediction)\n",
    "# compare\n",
    "print('Standard Prediction:\\n\\n', prediction)\n",
    "print('\\nActual:\\n\\n', Standard_scaler.inverse_transform(validation_labels_Standard))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
