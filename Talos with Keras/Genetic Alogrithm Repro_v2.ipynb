{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.sciencedirect.com/science/article/pii/S2211812814005318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x1aa1903ba90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dependencies\n",
    "%matplotlib inline\n",
    "#import keras\n",
    "from keras.models import Sequential\n",
    "from keras.activations import *\n",
    "from keras.layers import *\n",
    "from keras.losses import *\n",
    "from keras.optimizers import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import talos as ta\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# suppres NumPy arrays scientific notation and round decimals to three places\n",
    "np.set_printoptions(suppress=True)\n",
    "np.printoptions(precision=3, suppress=True)\n",
    "\n",
    "#libraries = [np,\n",
    "#             pd,\n",
    "#             sklearn,\n",
    "#             keras,\n",
    "#            ta]\n",
    "#for library in libraries:\n",
    "#    print(library, ' ', library.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import training data\n",
    "train_data = pd.read_csv('Training_Features_and_Labels.txt', delim_whitespace=True, encoding='ISO-8859-1')\n",
    "train_data.drop(columns=['Sr._No.'], inplace=True)\n",
    "# import validation data\n",
    "test_data = pd.read_csv('Test_Features_and_Labels.txt', delim_whitespace=True, encoding='ISO-8859-1')\n",
    "test_data.drop(columns=['Sr._No.'], inplace=True)\n",
    "# segregate a single row for validation\n",
    "validation_data = test_data.loc[0]\n",
    "test_data = test_data.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features:\n",
      "\n",
      " [[ 306.67    0.36]\n",
      " [ 609.76    0.47]\n",
      " [ 909.28    0.52]\n",
      " [ 582.94    0.8 ]\n",
      " [1158.73    0.9 ]\n",
      " [1727.36    1.1 ]\n",
      " [ 943.34    1.63]\n",
      " [1875.96    1.76]\n",
      " [2797.84    2.17]\n",
      " [ 793.04    0.38]\n",
      " [1577.02    0.48]\n",
      " [2351.92    0.54]\n",
      " [1555.25    0.81]\n",
      " [3092.37    0.82]\n",
      " [4611.35    0.97]\n",
      " [2196.85    1.92]\n",
      " [4366.5     1.91]\n",
      " [6508.93    2.03]\n",
      " [ 875.13    0.29]\n",
      " [1735.95    0.37]\n",
      " [2582.46    0.38]\n",
      " [1745.24    0.82]\n",
      " [3461.88    0.79]\n",
      " [5149.9     1.11]\n",
      " [2549.2     1.75]\n",
      " [5055.49    1.89]\n",
      " [7518.86    1.82]]\n",
      "\n",
      "Training Labels:\n",
      "\n",
      " [[ 280.        0.0508    0.4   ]\n",
      " [ 280.        0.0508    0.8   ]\n",
      " [ 280.        0.0508    1.2   ]\n",
      " [ 280.        0.1016    0.4   ]\n",
      " [ 280.        0.1016    0.8   ]\n",
      " [ 280.        0.1016    1.2   ]\n",
      " [ 280.        0.1524    0.4   ]\n",
      " [ 280.        0.1524    0.8   ]\n",
      " [ 280.        0.1524    1.2   ]\n",
      " [ 710.        0.0508    0.4   ]\n",
      " [ 710.        0.0508    0.8   ]\n",
      " [ 710.        0.0508    1.2   ]\n",
      " [ 710.        0.1016    0.4   ]\n",
      " [ 710.        0.1016    0.8   ]\n",
      " [ 710.        0.1016    1.2   ]\n",
      " [ 710.        0.1524    0.4   ]\n",
      " [ 710.        0.1524    0.8   ]\n",
      " [ 710.        0.1524    1.2   ]\n",
      " [1120.        0.0508    0.4   ]\n",
      " [1120.        0.0508    0.8   ]\n",
      " [1120.        0.0508    1.2   ]\n",
      " [1120.        0.1016    0.4   ]\n",
      " [1120.        0.1016    0.8   ]\n",
      " [1120.        0.1016    1.2   ]\n",
      " [1120.        0.1524    0.4   ]\n",
      " [1120.        0.1524    0.8   ]\n",
      " [1120.        0.1524    1.2   ]]\n"
     ]
    }
   ],
   "source": [
    "# create NumPy arrays of training features and labels\n",
    "train_features = train_data[['MRR(mm3/min)', 'Ra(µm)']].values\n",
    "train_labels = train_data[['Spindle_speed(rpm)', 'Feed_rate(mm/rev)', 'Depth_of_cut(mm)']].values\n",
    "print('Training Features:\\n\\n', train_features)\n",
    "print('\\nTraining Labels:\\n\\n', train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Features:\n",
      "\n",
      " [[2020.44    0.29]\n",
      " [6054.12    1.87]\n",
      " [5329.21    1.54]\n",
      " [5197.29    1.45]]\n",
      "\n",
      "Testing Labels:\n",
      "\n",
      " [[1100.      0.05    0.69]\n",
      " [1095.      0.15    1.2 ]\n",
      " [1097.      0.13    1.14]\n",
      " [1094.      0.12    1.15]]\n"
     ]
    }
   ],
   "source": [
    "# create NumPy arrays of validation features and labels\n",
    "test_features = test_data[['MRR(mm3/min)', 'Ra(µm)']].values\n",
    "test_labels = test_data[['Spindle_speed(rpm)', 'Feed_rate(mm/rev)', 'Depth_of_cut(mm)']].values\n",
    "print('Testing Features:\\n\\n', test_features)\n",
    "print('\\nTesting Labels:\\n\\n', test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Features:\n",
      "\n",
      " [[1106.51    0.21]]\n",
      "\n",
      "Validation Labels:\n",
      "\n",
      " [[1100.      0.05    0.4 ]]\n"
     ]
    }
   ],
   "source": [
    "# create NumPy array for validation data\n",
    "validation_features = validation_data[['MRR(mm3/min)', 'Ra(µm)']].values\n",
    "validation_labels = validation_data[['Spindle_speed(rpm)', 'Feed_rate(mm/rev)', 'Depth_of_cut(mm)']].values\n",
    "\n",
    "# reshape the validation data because it's only one row\n",
    "validation_features = validation_features.reshape(1, -1)\n",
    "validation_labels = validation_labels.reshape(1, -1)\n",
    "\n",
    "print('Validation Features:\\n\\n', validation_features)\n",
    "print('\\nValidation Labels:\\n\\n', validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms features by scaling each feature to a given range, -1 and 1 in this case\n",
    "MinMax_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_features_MinMax = MinMax_scaler.fit_transform(train_features)\n",
    "train_labels_MinMax = MinMax_scaler.fit_transform(train_labels)\n",
    "test_features_MinMax = MinMax_scaler.fit_transform(test_features)\n",
    "test_labels_MinMax = MinMax_scaler.fit_transform(test_labels)\n",
    "validation_features_MinMax = MinMax_scaler.fit_transform(validation_features)\n",
    "validation_labels_MinMax = MinMax_scaler.fit_transform(validation_labels)\n",
    "\n",
    "#MinMax_scaler.inverse_transform(validation_labels_MinMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "Standard_scaler = StandardScaler()\n",
    "train_features_Standard = Standard_scaler.fit_transform(train_features)\n",
    "train_labels_Standard = Standard_scaler.fit_transform(train_labels)\n",
    "test_features_Standard = Standard_scaler.fit_transform(test_features)\n",
    "test_labels_Standard = Standard_scaler.fit_transform(test_labels)\n",
    "validation_features_Standard = Standard_scaler.fit_transform(validation_features)\n",
    "validation_labels_Standard = Standard_scaler.fit_transform(validation_labels)\n",
    "\n",
    "# Standard_scaler.inverse_transform(train_features_Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {\n",
    "    'first_neuron': [8, 12, 24],\n",
    "    'second_neuron': [36, 48, 62, 84],\n",
    "    'third_neuron': [36, 48, 62, 84],\n",
    "    'fourth_neuron': [8, 12, 24],\n",
    "    'batch_size': [10, 20, 30],\n",
    "    'activation': [relu,\n",
    "                   #softmax,\n",
    "                   #selu,\n",
    "                   #softplus,\n",
    "                   #softsign,\n",
    "                   #tanh,\n",
    "                   #sigmoid,\n",
    "                   #hard_sigmoid,\n",
    "                   #exponential,\n",
    "                   linear],\n",
    "    'optimizer' : [#'SGD',\n",
    "                   #'RMSprop',\n",
    "                   #'Adagrad',\n",
    "                   #'Adadelta',\n",
    "                   'Adam',],\n",
    "                   #'Adamax',\n",
    "                   #'Nadam',],\n",
    "    'loss' : [mean_squared_error,]\n",
    "              #mean_absolute_error,] \n",
    "              #mean_absolute_percentage_error, \n",
    "              #mean_squared_logarithmic_error,\n",
    "              #squared_hinge,hinge,\n",
    "              #categorical_hinge,\n",
    "              #logcosh,],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMax_ann(train_features, train_labels, test_features, test_labels, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=2, activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['third_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['fourth_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(3, activation='linear'))\n",
    "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(train_features_MinMax, train_labels_MinMax,\n",
    "                    epochs=100,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[test_features_MinMax, test_labels_MinMax])\n",
    "    \n",
    "    # model output\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standard_ann(train_features, train_labels, test_features, test_labels, params):\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    model = Sequential()\n",
    "    model.add(Dense(params['first_neuron'], input_dim=2, activation=params['activation']))\n",
    "    model.add(Dense(params['second_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['third_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(params['fourth_neuron'], activation=params['activation']))\n",
    "    model.add(Dense(3, activation='linear'))\n",
    "    model.compile(loss=params['loss'], optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    \n",
    "    # make sure history object is returned by model.fit()\n",
    "    out = model.fit(train_features_Standard, train_labels_Standard,\n",
    "                    epochs=100,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    verbose=0,\n",
    "                    validation_data=[test_features_Standard, test_labels_Standard])\n",
    "    \n",
    "    # model output\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_MinMax = np.concatenate((train_features_MinMax, test_features_MinMax), axis=0)\n",
    "labels_MinMax = np.concatenate((train_labels_MinMax, test_labels_MinMax), axis=0)\n",
    "\n",
    "features_Standard = np.concatenate((train_features_Standard, test_features_Standard), axis=0)\n",
    "labels_Standard = np.concatenate((train_labels_Standard, test_labels_Standard), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/864 [00:00<?, ?it/s]WARNING: Logging before flag parsing goes to stderr.\n",
      "W0820 11:59:33.641922  8964 deprecation_wrapper.py:119] From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0820 11:59:33.683689  8964 deprecation_wrapper.py:119] From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0820 11:59:33.700176  8964 deprecation_wrapper.py:119] From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0820 11:59:33.866790  8964 deprecation_wrapper.py:119] From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0820 11:59:34.106631  8964 deprecation_wrapper.py:119] From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0820 11:59:34.410037  8964 deprecation_wrapper.py:119] From C:\\Users\\MacalusoC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 864/864 [50:15<00:00,  3.06s/it]\n"
     ]
    }
   ],
   "source": [
    "# run the Talos experiment on MinMax data\n",
    "MinMax_t = ta.Scan(features_MinMax, labels_MinMax, \n",
    "            params=p, \n",
    "            model=MinMax_ann,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 864/864 [43:32<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# run the Talos experiment on Standard data\n",
    "Standard_t = ta.Scan(features_Standard, labels_Standard, \n",
    "            params=p, \n",
    "            model=Standard_ann,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 'Adam', <function linear at 0x000001AA17118048>, 36, 10, 36, 8,\n",
       "       0], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use Scan object as input\n",
    "r = ta.Reporting(MinMax_t)\n",
    "# get the best paramaters\n",
    "r.best_params()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 'Adam', <function relu at 0x000001AA17107D08>, 36, 20, 48, 8,\n",
       "       0], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use Scan object as input\n",
    "r = ta.Reporting(Standard_t)\n",
    "# get the best paramaters\n",
    "r.best_params()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>fourth_neuron</th>\n",
       "      <th>loss.1</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>second_neuron</th>\n",
       "      <th>third_neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.261867</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.275643</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>&lt;function relu at 0x000001AA17107D08&gt;</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.277996</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.264963</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>&lt;function relu at 0x000001AA17107D08&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>36</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.302887</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.452316</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>&lt;function relu at 0x000001AA17107D08&gt;</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs  val_loss  val_acc      loss       acc  \\\n",
       "0           100  0.261867     0.75  0.275643  0.481481   \n",
       "1           100  0.277996     1.00  0.264963  0.518519   \n",
       "2           100  0.302887     0.25  0.452316  0.555556   \n",
       "\n",
       "                              activation  batch_size  first_neuron  \\\n",
       "0  <function relu at 0x000001AA17107D08>          30            24   \n",
       "1  <function relu at 0x000001AA17107D08>          10             8   \n",
       "2  <function relu at 0x000001AA17107D08>          30            12   \n",
       "\n",
       "   fourth_neuron                                             loss.1 optimizer  \\\n",
       "0              8  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "1              8  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "2              8  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "\n",
       "   second_neuron  third_neuron  \n",
       "0             48            48  \n",
       "1             36            84  \n",
       "2             48            48  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MinMax.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 4 samples\n",
      "Epoch 1/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5252 - acc: 0.200 - 1s 20ms/step - loss: 0.6438 - acc: 0.2593 - val_loss: 0.6721 - val_acc: 0.2500\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6170 - acc: 0.200 - 0s 0us/step - loss: 0.6279 - acc: 0.3704 - val_loss: 0.6595 - val_acc: 0.2500\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5924 - acc: 0.800 - 0s 0us/step - loss: 0.6166 - acc: 0.6667 - val_loss: 0.6491 - val_acc: 0.2500\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6488 - acc: 0.400 - 0s 579us/step - loss: 0.6060 - acc: 0.5926 - val_loss: 0.6443 - val_acc: 0.2500\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5873 - acc: 0.500 - 0s 1ms/step - loss: 0.5973 - acc: 0.6296 - val_loss: 0.6392 - val_acc: 0.2500\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4805 - acc: 0.700 - 0s 577us/step - loss: 0.5884 - acc: 0.6667 - val_loss: 0.6316 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6652 - acc: 0.800 - 0s 578us/step - loss: 0.5795 - acc: 0.6296 - val_loss: 0.6255 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6283 - acc: 0.500 - 0s 0us/step - loss: 0.5704 - acc: 0.5926 - val_loss: 0.6189 - val_acc: 0.5000\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5803 - acc: 0.700 - 0s 579us/step - loss: 0.5623 - acc: 0.5926 - val_loss: 0.6120 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5717 - acc: 0.600 - 0s 578us/step - loss: 0.5514 - acc: 0.5926 - val_loss: 0.6044 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5692 - acc: 0.600 - 0s 579us/step - loss: 0.5421 - acc: 0.5926 - val_loss: 0.5962 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4810 - acc: 0.600 - 0s 0us/step - loss: 0.5303 - acc: 0.5926 - val_loss: 0.5836 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.5049 - acc: 0.400 - 0s 0us/step - loss: 0.5185 - acc: 0.5926 - val_loss: 0.5718 - val_acc: 0.5000\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.6433 - acc: 0.800 - 0s 0us/step - loss: 0.5086 - acc: 0.5926 - val_loss: 0.5595 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4186 - acc: 0.700 - 0s 580us/step - loss: 0.4952 - acc: 0.5926 - val_loss: 0.5513 - val_acc: 0.5000\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4858 - acc: 0.600 - 0s 577us/step - loss: 0.4825 - acc: 0.5926 - val_loss: 0.5449 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4690 - acc: 0.700 - 0s 579us/step - loss: 0.4683 - acc: 0.5926 - val_loss: 0.5376 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4536 - acc: 0.600 - 0s 578us/step - loss: 0.4547 - acc: 0.5926 - val_loss: 0.5326 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4639 - acc: 0.600 - 0s 579us/step - loss: 0.4395 - acc: 0.5926 - val_loss: 0.5300 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4271 - acc: 0.700 - 0s 0us/step - loss: 0.4251 - acc: 0.5926 - val_loss: 0.5279 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3442 - acc: 0.700 - 0s 0us/step - loss: 0.4094 - acc: 0.5926 - val_loss: 0.5281 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4426 - acc: 0.700 - 0s 0us/step - loss: 0.3940 - acc: 0.6296 - val_loss: 0.5283 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3451 - acc: 0.500 - 0s 578us/step - loss: 0.3807 - acc: 0.6296 - val_loss: 0.5281 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4657 - acc: 0.500 - 0s 579us/step - loss: 0.3656 - acc: 0.6296 - val_loss: 0.5263 - val_acc: 0.5000\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3878 - acc: 0.600 - 0s 578us/step - loss: 0.3516 - acc: 0.6296 - val_loss: 0.5312 - val_acc: 0.5000\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3174 - acc: 0.600 - 0s 579us/step - loss: 0.3400 - acc: 0.6667 - val_loss: 0.5398 - val_acc: 0.5000\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3169 - acc: 0.800 - 0s 578us/step - loss: 0.3288 - acc: 0.6667 - val_loss: 0.5489 - val_acc: 0.5000\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4034 - acc: 0.500 - 0s 579us/step - loss: 0.3171 - acc: 0.6667 - val_loss: 0.5539 - val_acc: 0.5000\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2814 - acc: 0.500 - 0s 579us/step - loss: 0.3114 - acc: 0.6296 - val_loss: 0.5662 - val_acc: 0.5000\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2099 - acc: 0.900 - 0s 579us/step - loss: 0.3018 - acc: 0.5926 - val_loss: 0.5758 - val_acc: 0.5000\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1998 - acc: 0.800 - 0s 579us/step - loss: 0.2967 - acc: 0.5926 - val_loss: 0.5904 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3490 - acc: 0.600 - 0s 579us/step - loss: 0.2913 - acc: 0.6296 - val_loss: 0.6143 - val_acc: 0.5000\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2870 - acc: 0.800 - 0s 578us/step - loss: 0.2858 - acc: 0.6296 - val_loss: 0.6413 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1349 - acc: 0.900 - 0s 578us/step - loss: 0.2873 - acc: 0.6296 - val_loss: 0.6730 - val_acc: 0.5000\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1911 - acc: 0.900 - 0s 579us/step - loss: 0.2812 - acc: 0.6296 - val_loss: 0.6809 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3632 - acc: 0.700 - 0s 0us/step - loss: 0.2787 - acc: 0.6296 - val_loss: 0.6822 - val_acc: 0.5000\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1662 - acc: 0.500 - 0s 0us/step - loss: 0.2765 - acc: 0.6296 - val_loss: 0.6934 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4090 - acc: 0.500 - 0s 579us/step - loss: 0.2755 - acc: 0.6296 - val_loss: 0.7013 - val_acc: 0.5000\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2020 - acc: 0.500 - 0s 0us/step - loss: 0.2741 - acc: 0.6296 - val_loss: 0.7110 - val_acc: 0.5000\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2787 - acc: 0.600 - 0s 578us/step - loss: 0.2713 - acc: 0.6296 - val_loss: 0.7044 - val_acc: 0.5000\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3364 - acc: 0.600 - 0s 0us/step - loss: 0.2696 - acc: 0.6296 - val_loss: 0.7046 - val_acc: 0.5000\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2551 - acc: 0.800 - 0s 0us/step - loss: 0.2688 - acc: 0.6296 - val_loss: 0.7017 - val_acc: 0.5000\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3291 - acc: 0.600 - 0s 0us/step - loss: 0.2675 - acc: 0.6296 - val_loss: 0.6967 - val_acc: 0.5000\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1406 - acc: 0.800 - 0s 579us/step - loss: 0.2668 - acc: 0.6296 - val_loss: 0.6976 - val_acc: 0.5000\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2418 - acc: 0.500 - 0s 0us/step - loss: 0.2663 - acc: 0.6296 - val_loss: 0.6941 - val_acc: 0.5000\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.4566 - acc: 0.300 - 0s 861us/step - loss: 0.2654 - acc: 0.6296 - val_loss: 0.6897 - val_acc: 0.5000\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3222 - acc: 0.700 - 0s 0us/step - loss: 0.2643 - acc: 0.6296 - val_loss: 0.6843 - val_acc: 0.5000\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3160 - acc: 0.700 - 0s 0us/step - loss: 0.2636 - acc: 0.6296 - val_loss: 0.6820 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2611 - acc: 0.600 - 0s 579us/step - loss: 0.2630 - acc: 0.6296 - val_loss: 0.6808 - val_acc: 0.5000\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1822 - acc: 0.400 - 0s 579us/step - loss: 0.2626 - acc: 0.5926 - val_loss: 0.6768 - val_acc: 0.5000\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3071 - acc: 0.400 - 0s 579us/step - loss: 0.2633 - acc: 0.5926 - val_loss: 0.6678 - val_acc: 0.5000\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1316 - acc: 0.800 - 0s 579us/step - loss: 0.2613 - acc: 0.6296 - val_loss: 0.6690 - val_acc: 0.5000\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2955 - acc: 0.500 - 0s 0us/step - loss: 0.2607 - acc: 0.5926 - val_loss: 0.6611 - val_acc: 0.5000\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1268 - acc: 0.500 - 0s 579us/step - loss: 0.2612 - acc: 0.5926 - val_loss: 0.6558 - val_acc: 0.5000\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2552 - acc: 0.400 - 0s 0us/step - loss: 0.2596 - acc: 0.5926 - val_loss: 0.6456 - val_acc: 0.5000\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1952 - acc: 0.600 - 0s 0us/step - loss: 0.2589 - acc: 0.5926 - val_loss: 0.6399 - val_acc: 0.5000\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2275 - acc: 0.700 - 0s 579us/step - loss: 0.2593 - acc: 0.5926 - val_loss: 0.6355 - val_acc: 0.5000\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1850 - acc: 0.700 - 0s 0us/step - loss: 0.2580 - acc: 0.5926 - val_loss: 0.6416 - val_acc: 0.5000\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3233 - acc: 0.500 - 0s 579us/step - loss: 0.2576 - acc: 0.5926 - val_loss: 0.6414 - val_acc: 0.5000\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1876 - acc: 0.600 - 0s 0us/step - loss: 0.2571 - acc: 0.6296 - val_loss: 0.6424 - val_acc: 0.5000\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1529 - acc: 0.700 - 0s 0us/step - loss: 0.2561 - acc: 0.5926 - val_loss: 0.6340 - val_acc: 0.5000\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3761 - acc: 0.700 - 0s 579us/step - loss: 0.2561 - acc: 0.5926 - val_loss: 0.6258 - val_acc: 0.5000\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2370 - acc: 0.600 - 0s 579us/step - loss: 0.2553 - acc: 0.5926 - val_loss: 0.6278 - val_acc: 0.5000\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2160 - acc: 0.600 - 0s 0us/step - loss: 0.2558 - acc: 0.5926 - val_loss: 0.6341 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2181 - acc: 0.700 - 0s 579us/step - loss: 0.2553 - acc: 0.5926 - val_loss: 0.6289 - val_acc: 0.5000\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3171 - acc: 0.300 - 0s 579us/step - loss: 0.2540 - acc: 0.5926 - val_loss: 0.6312 - val_acc: 0.5000\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3478 - acc: 0.300 - 0s 578us/step - loss: 0.2535 - acc: 0.5926 - val_loss: 0.6282 - val_acc: 0.5000\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2765 - acc: 0.400 - 0s 0us/step - loss: 0.2531 - acc: 0.5926 - val_loss: 0.6336 - val_acc: 0.5000\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1760 - acc: 0.500 - 0s 0us/step - loss: 0.2531 - acc: 0.5926 - val_loss: 0.6332 - val_acc: 0.5000\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2749 - acc: 0.600 - 0s 0us/step - loss: 0.2544 - acc: 0.5926 - val_loss: 0.6257 - val_acc: 0.5000\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2007 - acc: 0.600 - 0s 0us/step - loss: 0.2526 - acc: 0.5926 - val_loss: 0.6285 - val_acc: 0.5000\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2832 - acc: 0.600 - 0s 579us/step - loss: 0.2516 - acc: 0.5926 - val_loss: 0.6277 - val_acc: 0.5000\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2454 - acc: 0.700 - 0s 0us/step - loss: 0.2511 - acc: 0.5926 - val_loss: 0.6287 - val_acc: 0.5000\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2794 - acc: 0.800 - 0s 579us/step - loss: 0.2515 - acc: 0.5926 - val_loss: 0.6276 - val_acc: 0.5000\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2781 - acc: 0.500 - 0s 0us/step - loss: 0.2517 - acc: 0.5926 - val_loss: 0.6202 - val_acc: 0.5000\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3109 - acc: 0.400 - 0s 0us/step - loss: 0.2516 - acc: 0.5926 - val_loss: 0.6177 - val_acc: 0.5000\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1632 - acc: 0.400 - 0s 578us/step - loss: 0.2507 - acc: 0.5556 - val_loss: 0.6136 - val_acc: 0.5000\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2765 - acc: 0.600 - 0s 0us/step - loss: 0.2497 - acc: 0.5556 - val_loss: 0.6090 - val_acc: 0.5000\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2335 - acc: 0.700 - 0s 0us/step - loss: 0.2496 - acc: 0.5556 - val_loss: 0.6067 - val_acc: 0.5000\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1044 - acc: 0.600 - 0s 579us/step - loss: 0.2492 - acc: 0.5556 - val_loss: 0.6084 - val_acc: 0.5000\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1898 - acc: 0.700 - 0s 0us/step - loss: 0.2487 - acc: 0.5556 - val_loss: 0.6017 - val_acc: 0.5000\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3249 - acc: 0.400 - 0s 579us/step - loss: 0.2485 - acc: 0.5556 - val_loss: 0.6021 - val_acc: 0.5000\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3480 - acc: 0.300 - 0s 0us/step - loss: 0.2483 - acc: 0.5556 - val_loss: 0.6033 - val_acc: 0.5000\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3107 - acc: 0.600 - 0s 0us/step - loss: 0.2484 - acc: 0.5556 - val_loss: 0.6030 - val_acc: 0.5000\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3041 - acc: 0.300 - 0s 579us/step - loss: 0.2479 - acc: 0.5556 - val_loss: 0.5981 - val_acc: 0.5000\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.3158 - acc: 0.500 - 0s 579us/step - loss: 0.2472 - acc: 0.5556 - val_loss: 0.5904 - val_acc: 0.5000\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1527 - acc: 0.600 - 0s 0us/step - loss: 0.2468 - acc: 0.5556 - val_loss: 0.5876 - val_acc: 0.5000\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2455 - acc: 0.400 - 0s 579us/step - loss: 0.2467 - acc: 0.5556 - val_loss: 0.5849 - val_acc: 0.5000\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2084 - acc: 0.800 - 0s 0us/step - loss: 0.2465 - acc: 0.5926 - val_loss: 0.5891 - val_acc: 0.5000\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1321 - acc: 0.600 - 0s 0us/step - loss: 0.2458 - acc: 0.5926 - val_loss: 0.5880 - val_acc: 0.5000\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1547 - acc: 0.800 - 0s 0us/step - loss: 0.2452 - acc: 0.5926 - val_loss: 0.5815 - val_acc: 0.5000\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2687 - acc: 0.600 - 0s 579us/step - loss: 0.2462 - acc: 0.5926 - val_loss: 0.5800 - val_acc: 0.5000\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2287 - acc: 0.700 - 0s 0us/step - loss: 0.2468 - acc: 0.5926 - val_loss: 0.5895 - val_acc: 0.5000\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2927 - acc: 0.500 - 0s 0us/step - loss: 0.2448 - acc: 0.5926 - val_loss: 0.5932 - val_acc: 0.5000\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1909 - acc: 0.800 - 0s 0us/step - loss: 0.2451 - acc: 0.5926 - val_loss: 0.5958 - val_acc: 0.5000\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2616 - acc: 0.400 - 0s 579us/step - loss: 0.2443 - acc: 0.5926 - val_loss: 0.5944 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1187 - acc: 0.700 - 0s 579us/step - loss: 0.2438 - acc: 0.5556 - val_loss: 0.5926 - val_acc: 0.5000\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1674 - acc: 0.700 - 0s 0us/step - loss: 0.2430 - acc: 0.5556 - val_loss: 0.5892 - val_acc: 0.5000\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.1740 - acc: 0.600 - 0s 0us/step - loss: 0.2440 - acc: 0.5556 - val_loss: 0.5872 - val_acc: 0.5000\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - ETA: 0s - loss: 0.2436 - acc: 0.500 - 0s 579us/step - loss: 0.2428 - acc: 0.5556 - val_loss: 0.5986 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa1be1aef0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the MinMax model\n",
    "MinMax_model = Sequential()\n",
    "MinMax_model.add(Dense(8, input_dim=2, activation='relu'))\n",
    "MinMax_model.add(Dense(36, activation='relu'))\n",
    "MinMax_model.add(Dense(84, activation='relu'))\n",
    "MinMax_model.add(Dense(8, activation='relu'))\n",
    "MinMax_model.add(Dense(3, activation='linear'))\n",
    "MinMax_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "MinMax_model.fit(train_features_MinMax,\n",
    "                 train_labels_MinMax,\n",
    "                 validation_data=(test_features_MinMax, test_labels_MinMax),\n",
    "                 batch_size=10,\n",
    "                 epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_epochs</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>first_neuron</th>\n",
       "      <th>fourth_neuron</th>\n",
       "      <th>loss.1</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>second_neuron</th>\n",
       "      <th>third_neuron</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.386672</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.459910</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>&lt;function relu at 0x000001AA17107D08&gt;</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>48</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.466409</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.401966</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>&lt;function relu at 0x000001AA17107D08&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>0.511823</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.447284</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>&lt;function linear at 0x000001AA17118048&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;function mean_squared_error at 0x000001AA170D...</td>\n",
       "      <td>Adam</td>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   round_epochs  val_loss  val_acc      loss       acc  \\\n",
       "0           100  0.386672     0.75  0.459910  0.666667   \n",
       "1           100  0.466409     0.75  0.401966  0.777778   \n",
       "2           100  0.511823     0.75  0.447284  0.629630   \n",
       "\n",
       "                                activation  batch_size  first_neuron  \\\n",
       "0    <function relu at 0x000001AA17107D08>          30            24   \n",
       "1    <function relu at 0x000001AA17107D08>          10            12   \n",
       "2  <function linear at 0x000001AA17118048>          20            24   \n",
       "\n",
       "   fourth_neuron                                             loss.1 optimizer  \\\n",
       "0              8  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "1              8  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "2             12  <function mean_squared_error at 0x000001AA170D...      Adam   \n",
       "\n",
       "   second_neuron  third_neuron  \n",
       "0             48            62  \n",
       "1             84            84  \n",
       "2             36            62  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Standard.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Standard model\n",
    "Standard_model = Sequential()\n",
    "Standard_model.add(Dense(24, input_dim=2, activation='relu'))\n",
    "Standard_model.add(Dense(84, activation='relu'))\n",
    "Standard_model.add(Dense(84, activation='relu'))\n",
    "Standard_model.add(Dense(12, activation='relu'))\n",
    "Standard_model.add(Dense(3, activation='linear'))\n",
    "Standard_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "Standard_model.fit(train_features_Standard,\n",
    "                   train_labels_Standard,\n",
    "                   validation_data=(test_features_Standard, test_labels_Standard),\n",
    "                   batch_size=20,\n",
    "                   epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMax Prediction:\n",
      "\n",
      " [[1100.296       -0.0317607    0.5831349]]\n",
      "\n",
      "Actual:\n",
      "\n",
      " [[1100.      0.05    0.4 ]]\n"
     ]
    }
   ],
   "source": [
    "# MinMax prediction\n",
    "prediction = MinMax_model.predict(validation_features_MinMax)\n",
    "prediction = MinMax_scaler.inverse_transform(prediction)\n",
    "# compare\n",
    "MinMax_scaler.inverse_transform(validation_labels_MinMax)\n",
    "print('MinMax Prediction:\\n\\n', prediction)\n",
    "print('\\nActual:\\n\\n', MinMax_scaler.inverse_transform(validation_labels_MinMax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard prediction\n",
    "prediction = Standard_model.predict(validation_features_Standard)\n",
    "prediction = Standard_scaler.inverse_transform(prediction)\n",
    "# compare\n",
    "print('Standard Prediction:\\n\\n', prediction)\n",
    "print('\\nActual:\\n\\n', Standard_scaler.inverse_transform(validation_labels_Standard))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
